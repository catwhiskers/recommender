{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-10 23:24:38--  https://tinyurl.com/y3gfnlx2\n",
      "Resolving tinyurl.com (tinyurl.com)... 104.20.138.65, 104.20.139.65, 172.67.1.225\n",
      "Connecting to tinyurl.com (tinyurl.com)|104.20.138.65|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://recommendation-demo-yianc.s3.us-east-1.amazonaws.com/amz-review/amz-review-apparel.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIATLORAEYMTX7JY4ER%2F20200810%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200810T152347Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=e6c35dc78526ddb7cd7e913fa63c5f8a5ad57a39ca556ab68fe010ed58051435 [following]\n",
      "--2020-08-10 23:24:39--  https://recommendation-demo-yianc.s3.us-east-1.amazonaws.com/amz-review/amz-review-apparel.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIATLORAEYMTX7JY4ER%2F20200810%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200810T152347Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=e6c35dc78526ddb7cd7e913fa63c5f8a5ad57a39ca556ab68fe010ed58051435\n",
      "Resolving recommendation-demo-yianc.s3.us-east-1.amazonaws.com (recommendation-demo-yianc.s3.us-east-1.amazonaws.com)... 52.216.97.142\n",
      "Connecting to recommendation-demo-yianc.s3.us-east-1.amazonaws.com (recommendation-demo-yianc.s3.us-east-1.amazonaws.com)|52.216.97.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 621522774 (593M) [text/csv]\n",
      "Saving to: ‘amz-review-apparel.csv’\n",
      "\n",
      "amz-review-apparel. 100%[===================>] 592.73M  1.43MB/s    in 7m 18s  \n",
      "\n",
      "2020-08-10 23:31:57 (1.35 MB/s) - ‘amz-review-apparel.csv’ saved [621522774/621522774]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O amz-review-apparel.csv https://tinyurl.com/y3gfnlx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>cnt</th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id.1</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28563435</td>\n",
       "      <td>13</td>\n",
       "      <td>US</td>\n",
       "      <td>28563435</td>\n",
       "      <td>R2M9YYZ4DLZRMN</td>\n",
       "      <td>B003OQTQ0W</td>\n",
       "      <td>97286984</td>\n",
       "      <td>Carhartt Men's Two-Tone Trifold Wallet</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Outstanding Wallet</td>\n",
       "      <td>I have owned a lot of wallets over the years a...</td>\n",
       "      <td>2013-07-11</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28563435</td>\n",
       "      <td>13</td>\n",
       "      <td>US</td>\n",
       "      <td>28563435</td>\n",
       "      <td>R2DIHSYWNP3FPJ</td>\n",
       "      <td>B0093O17U6</td>\n",
       "      <td>765210786</td>\n",
       "      <td>IH Camouflage Trucker Cap in Mossy Oak Break-U...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Great cap</td>\n",
       "      <td>This is a very nice hat,but i have got another...</td>\n",
       "      <td>2013-05-11</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28563435</td>\n",
       "      <td>13</td>\n",
       "      <td>US</td>\n",
       "      <td>28563435</td>\n",
       "      <td>R36XY86RBEESP6</td>\n",
       "      <td>B0051I6MYY</td>\n",
       "      <td>268391293</td>\n",
       "      <td>IH 5 Panel Trucker Cap with Liquid Metal Logo</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Great hat!!!</td>\n",
       "      <td>This is a great hat and is very well made!! I ...</td>\n",
       "      <td>2013-04-13</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28563435</td>\n",
       "      <td>13</td>\n",
       "      <td>US</td>\n",
       "      <td>28563435</td>\n",
       "      <td>R2X9GLV67VACAN</td>\n",
       "      <td>B005F29FKO</td>\n",
       "      <td>506334102</td>\n",
       "      <td>Carhartt Men's Relaxed Straight Denim Five Poc...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Great pants</td>\n",
       "      <td>I have always been a Wrangler man most of my l...</td>\n",
       "      <td>2012-12-08</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28563435</td>\n",
       "      <td>13</td>\n",
       "      <td>US</td>\n",
       "      <td>28563435</td>\n",
       "      <td>RS4RG84BX2KK5</td>\n",
       "      <td>B004QF0THY</td>\n",
       "      <td>206343191</td>\n",
       "      <td>Dickies Men's 2 Pack Wool Blend Boot Crew Socks</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Very Great socks!!</td>\n",
       "      <td>Wool is the only socks i wear and the only thi...</td>\n",
       "      <td>2012-12-08</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  cnt marketplace  customer_id.1       review_id  product_id  \\\n",
       "0     28563435   13          US       28563435  R2M9YYZ4DLZRMN  B003OQTQ0W   \n",
       "1     28563435   13          US       28563435  R2DIHSYWNP3FPJ  B0093O17U6   \n",
       "2     28563435   13          US       28563435  R36XY86RBEESP6  B0051I6MYY   \n",
       "3     28563435   13          US       28563435  R2X9GLV67VACAN  B005F29FKO   \n",
       "4     28563435   13          US       28563435   RS4RG84BX2KK5  B004QF0THY   \n",
       "\n",
       "   product_parent                                      product_title  \\\n",
       "0        97286984             Carhartt Men's Two-Tone Trifold Wallet   \n",
       "1       765210786  IH Camouflage Trucker Cap in Mossy Oak Break-U...   \n",
       "2       268391293      IH 5 Panel Trucker Cap with Liquid Metal Logo   \n",
       "3       506334102  Carhartt Men's Relaxed Straight Denim Five Poc...   \n",
       "4       206343191    Dickies Men's 2 Pack Wool Blend Boot Crew Socks   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            5              0            0    N                 Y   \n",
       "1            5              0            0    N                 Y   \n",
       "2            5              1            1    N                 Y   \n",
       "3            5              0            0    N                 Y   \n",
       "4            5              0            0    N                 Y   \n",
       "\n",
       "      review_headline                                        review_body  \\\n",
       "0  Outstanding Wallet  I have owned a lot of wallets over the years a...   \n",
       "1           Great cap  This is a very nice hat,but i have got another...   \n",
       "2        Great hat!!!  This is a great hat and is very well made!! I ...   \n",
       "3         Great pants  I have always been a Wrangler man most of my l...   \n",
       "4  Very Great socks!!  Wool is the only socks i wear and the only thi...   \n",
       "\n",
       "  review_date  year  \n",
       "0  2013-07-11  2013  \n",
       "1  2013-05-11  2013  \n",
       "2  2013-04-13  2013  \n",
       "3  2012-12-08  2012  \n",
       "4  2012-12-08  2012  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "user_item = './amz-review-apparel.csv'\n",
    "\n",
    "user_item_df = pd.read_csv(user_item)\n",
    "user_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from preprocessing.amz_datareader import AMZDataReader\n",
    "from preprocessing.factorization_machine_transformer import  FactorizationMachineTransformer\n",
    "\n",
    "\n",
    "user_item = './amz-review-apparel.csv'\n",
    "reader = AMZDataReader()\n",
    "user_item  = reader.read_user_item_rating(user_item)\n",
    "users = {}\n",
    "items = {}\n",
    "train_user_item = user_item[:int(len(user_item)*0.8)]\n",
    "test_user_item = user_item[int(len(user_item)*0.8):]\n",
    "transformer = FactorizationMachineTransformer(users, items, train_user_item)\n",
    "X_train, Y_train, nFeatures, processed = transformer.get_feature_vectors(users, items, train_user_item)\n",
    "X_test, Y_test, nFeatures, processed = transformer.get_feature_vectors(users, items, test_user_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create bucket! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.BytesIO object at 0x140e9bfb0>\n",
      "Output: s3://recommendation-demo-yianc/sagemaker/fm-amz/output\n"
     ]
    }
   ],
   "source": [
    "bucket = 'recommendation-demo-yianc'\n",
    "prefix = 'sagemaker/fm-amz'\n",
    "train_key      = 'train.protobuf'\n",
    "train_prefix   = '{}/{}'.format(prefix, 'train')\n",
    "test_key       = 'test.protobuf'\n",
    "test_prefix    = '{}/{}/'.format(prefix, 'test')\n",
    "output_prefix  = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "\n",
    "def writeDatasetToProtobuf(X, Y, bucket, prefix, key):\n",
    "    import io,boto3\n",
    "    import sagemaker.amazon.common as smac\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_spmatrix_to_sparse_tensor(buf, X, Y)\n",
    "    buf.seek(0)\n",
    "    print(buf)\n",
    "    obj = '{}/{}'.format(prefix, key)\n",
    "    boto3.resource('s3').Bucket(bucket).Object(obj).upload_fileobj(buf)\n",
    "    return 's3://{}/{}'.format(bucket,obj)\n",
    " \n",
    "    \n",
    "train_data = writeDatasetToProtobuf(X_train, Y_train, bucket, train_prefix, train_key)    \n",
    "  \n",
    "print('Output: {}'.format(output_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://recommendation-demo-yianc/sagemaker/fm-amz/train/train.protobuf'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'382416733822.dkr.ecr.us-east-1.amazonaws.com/factorization-machines:1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker \n",
    "\n",
    "container = sagemaker.image_uris.retrieve(framework='factorization-machines', region='us-east-1', version='latest')\n",
    "container \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sagemaker.estimator.Estimator'>\n",
      "2020-08-10 16:07:10 Starting - Starting the training job...\n",
      "2020-08-10 16:07:13 Starting - Launching requested ML instances......\n",
      "2020-08-10 16:08:30 Starting - Preparing the instances for training......\n",
      "2020-08-10 16:10:00 Downloading - Downloading input data\n",
      "2020-08-10 16:10:00 Training - Downloading the training image...\n",
      "2020-08-10 16:10:19 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python2.7/site-packages/pandas/util/nosetester.py:13: DeprecationWarning: Importing from numpy.testing.nosetester is deprecated, import from numpy.testing instead.\n",
      "  from numpy.testing import nosetester\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:21 INFO 140371927496512] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': 1, u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:21 INFO 140371927496512] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'epochs': u'50', u'feature_dim': u'980904', u'mini_batch_size': u'1000', u'predictor_type': u'regressor', u'num_factors': u'64'}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:21 INFO 140371927496512] Final configuration: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': u'50', u'feature_dim': u'980904', u'num_factors': u'64', u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'predictor_type': u'regressor', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:21 WARNING 140371927496512] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:21 INFO 140371927496512] Using default worker.\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:10:21.556] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 6, \"num_examples\": 1, \"num_bytes\": 64000}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:21 INFO 140371927496512] nvidia-smi took: 0.0251898765564 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:21 INFO 140371927496512] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:21 INFO 140371927496512] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:21 INFO 140371927496512] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 35.6450080871582, \"sum\": 35.6450080871582, \"min\": 35.6450080871582}}, \"EndTime\": 1597075821.590353, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597075821.549334}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1597075821.590557, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597075821.590512}\n",
      "\u001b[0m\n",
      "\u001b[34m[16:10:21] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.203343.0/AL2012/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[16:10:21] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.203343.0/AL2012/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=4.35874704259\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=18.9986757813\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=4.17642431641\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:33 INFO 140371927496512] Iter[0] Batch [500]#011Speed: 56890.45 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:33 INFO 140371927496512] #quality_metric: host=algo-1, epoch=0, batch=500 train rmse <loss>=1.36280460382\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:33 INFO 140371927496512] #quality_metric: host=algo-1, epoch=0, batch=500 train mse <loss>=1.85723638819\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:33 INFO 140371927496512] #quality_metric: host=algo-1, epoch=0, batch=500 train absolute_loss <loss>=1.05571819179\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:41 INFO 140371927496512] Iter[0] Batch [1000]#011Speed: 60737.03 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=0, batch=1000 train rmse <loss>=1.25194672619\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=0, batch=1000 train mse <loss>=1.56737060522\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=0, batch=1000 train absolute_loss <loss>=0.982564289897\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:10:46.209] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 22796, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:46 INFO 140371927496512] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=1.23206911316\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:46 INFO 140371927496512] #quality_metric: host=algo-1, epoch=0, train mse <loss>=1.5179942996\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:46 INFO 140371927496512] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=0.970652817336\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 50, \"sum\": 50.0, \"min\": 50}, \"update.time\": {\"count\": 1, \"max\": 24619.08793449402, \"sum\": 24619.08793449402, \"min\": 24619.08793449402}}, \"EndTime\": 1597075846.209893, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597075821.590436}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:46 INFO 140371927496512] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1301, \"sum\": 1301.0, \"min\": 1301}, \"Total Records Seen\": {\"count\": 1, \"max\": 1300471, \"sum\": 1300471.0, \"min\": 1300471}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1597075846.210151, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 0}, \"StartTime\": 1597075821.590769}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:46 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=52782.1891103 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:46 INFO 140371927496512] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=1.24961664043\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:46 INFO 140371927496512] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=1.56154174805\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:46 INFO 140371927496512] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=1.00571838379\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:54 INFO 140371927496512] Iter[1] Batch [500]#011Speed: 59683.83 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=1, batch=500 train rmse <loss>=1.1443500486\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=1, batch=500 train mse <loss>=1.30953703372\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:10:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=1, batch=500 train absolute_loss <loss>=0.919752556411\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/10/2020 16:11:02 INFO 140371927496512] Iter[1] Batch [1000]#011Speed: 60270.78 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=1, batch=1000 train rmse <loss>=1.13156762712\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=1, batch=1000 train mse <loss>=1.28044529476\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=1, batch=1000 train absolute_loss <loss>=0.908872272991\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:11:07.843] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 21630, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=1.13626978956\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=1, train mse <loss>=1.29110903466\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=0.911356152579\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21633.078813552856, \"sum\": 21633.078813552856, \"min\": 21633.078813552856}}, \"EndTime\": 1597075867.844302, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597075846.209982}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:07 INFO 140371927496512] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2601, \"sum\": 2601.0, \"min\": 2601}, \"Total Records Seen\": {\"count\": 1, \"max\": 2599942, \"sum\": 2599942.0, \"min\": 2599942}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1597075867.844559, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 1}, \"StartTime\": 1597075846.211191}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:07 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60067.5146753 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=1.24497691918\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=1.5499675293\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=1.00799810791\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:16 INFO 140371927496512] Iter[2] Batch [500]#011Speed: 60496.27 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:16 INFO 140371927496512] #quality_metric: host=algo-1, epoch=2, batch=500 train rmse <loss>=1.13154913905\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:16 INFO 140371927496512] #quality_metric: host=algo-1, epoch=2, batch=500 train mse <loss>=1.28040345408\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:16 INFO 140371927496512] #quality_metric: host=algo-1, epoch=2, batch=500 train absolute_loss <loss>=0.907525075825\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:24 INFO 140371927496512] Iter[2] Batch [1000]#011Speed: 61110.46 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=2, batch=1000 train rmse <loss>=1.11865732331\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=2, batch=1000 train mse <loss>=1.25139420699\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=2, batch=1000 train absolute_loss <loss>=0.896161555059\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:11:29.209] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 21362, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:29 INFO 140371927496512] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=1.12348122543\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:29 INFO 140371927496512] #quality_metric: host=algo-1, epoch=2, train mse <loss>=1.2622100639\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:29 INFO 140371927496512] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=0.898672640052\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21364.21799659729, \"sum\": 21364.21799659729, \"min\": 21364.21799659729}}, \"EndTime\": 1597075889.209926, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597075867.84438}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:29 INFO 140371927496512] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3901, \"sum\": 3901.0, \"min\": 3901}, \"Total Records Seen\": {\"count\": 1, \"max\": 3899413, \"sum\": 3899413.0, \"min\": 3899413}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1597075889.210186, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 2}, \"StartTime\": 1597075867.845676}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:29 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60823.495634 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:29 INFO 140371927496512] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=1.23872202329\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:29 INFO 140371927496512] #quality_metric: host=algo-1, epoch=3, batch=0 train mse <loss>=1.53443225098\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:29 INFO 140371927496512] #quality_metric: host=algo-1, epoch=3, batch=0 train absolute_loss <loss>=1.00661297607\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:37 INFO 140371927496512] Iter[3] Batch [500]#011Speed: 59975.04 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=3, batch=500 train rmse <loss>=1.11910635246\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=3, batch=500 train mse <loss>=1.25239902812\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=3, batch=500 train absolute_loss <loss>=0.895326280666\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:45 INFO 140371927496512] Iter[3] Batch [1000]#011Speed: 59777.68 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=3, batch=1000 train rmse <loss>=1.10608079651\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=3, batch=1000 train mse <loss>=1.2234147284\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=3, batch=1000 train absolute_loss <loss>=0.883629874337\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:11:50.808] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 21595, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=1.11101390625\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=3, train mse <loss>=1.23435189988\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=3, train absolute_loss <loss>=0.886158050349\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21597.2900390625, \"sum\": 21597.2900390625, \"min\": 21597.2900390625}}, \"EndTime\": 1597075910.80865, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597075889.210008}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:50 INFO 140371927496512] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5201, \"sum\": 5201.0, \"min\": 5201}, \"Total Records Seen\": {\"count\": 1, \"max\": 5198884, \"sum\": 5198884.0, \"min\": 5198884}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1597075910.808864, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 3}, \"StartTime\": 1597075889.211328}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:50 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60167.2429317 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=1.2310706861\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=4, batch=0 train mse <loss>=1.51553503418\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=4, batch=0 train absolute_loss <loss>=1.00204467773\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/10/2020 16:11:59 INFO 140371927496512] Iter[4] Batch [500]#011Speed: 61005.55 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:59 INFO 140371927496512] #quality_metric: host=algo-1, epoch=4, batch=500 train rmse <loss>=1.10731543386\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:59 INFO 140371927496512] #quality_metric: host=algo-1, epoch=4, batch=500 train mse <loss>=1.22614747007\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:11:59 INFO 140371927496512] #quality_metric: host=algo-1, epoch=4, batch=500 train absolute_loss <loss>=0.883896595968\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:07 INFO 140371927496512] Iter[4] Batch [1000]#011Speed: 60641.53 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=4, batch=1000 train rmse <loss>=1.0941937776\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=4, batch=1000 train mse <loss>=1.19726002294\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=4, batch=1000 train absolute_loss <loss>=0.871839779422\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:12:12.144] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 21333, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:12 INFO 140371927496512] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=1.09918460488\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:12 INFO 140371927496512] #quality_metric: host=algo-1, epoch=4, train mse <loss>=1.20820679561\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:12 INFO 140371927496512] #quality_metric: host=algo-1, epoch=4, train absolute_loss <loss>=0.874328821176\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21335.561990737915, \"sum\": 21335.561990737915, \"min\": 21335.561990737915}}, \"EndTime\": 1597075932.145615, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597075910.808729}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:12 INFO 140371927496512] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6501, \"sum\": 6501.0, \"min\": 6501}, \"Total Records Seen\": {\"count\": 1, \"max\": 6498355, \"sum\": 6498355.0, \"min\": 6498355}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1597075932.145872, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 4}, \"StartTime\": 1597075910.810018}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:12 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60905.1071013 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:12 INFO 140371927496512] #quality_metric: host=algo-1, epoch=5, batch=0 train rmse <loss>=1.22290382877\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:12 INFO 140371927496512] #quality_metric: host=algo-1, epoch=5, batch=0 train mse <loss>=1.49549377441\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:12 INFO 140371927496512] #quality_metric: host=algo-1, epoch=5, batch=0 train absolute_loss <loss>=0.99602532959\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:20 INFO 140371927496512] Iter[5] Batch [500]#011Speed: 60943.35 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=5, batch=500 train rmse <loss>=1.0962452098\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=5, batch=500 train mse <loss>=1.20175356002\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=5, batch=500 train absolute_loss <loss>=0.873346645454\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:28 INFO 140371927496512] Iter[5] Batch [1000]#011Speed: 60699.86 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=5, batch=1000 train rmse <loss>=1.08301672069\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=5, batch=1000 train mse <loss>=1.1729252173\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=5, batch=1000 train absolute_loss <loss>=0.860878302484\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:12:33.534] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 21385, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:33 INFO 140371927496512] #quality_metric: host=algo-1, epoch=5, train rmse <loss>=1.08802838342\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:33 INFO 140371927496512] #quality_metric: host=algo-1, epoch=5, train mse <loss>=1.18380576313\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:33 INFO 140371927496512] #quality_metric: host=algo-1, epoch=5, train absolute_loss <loss>=0.863289710036\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21388.12804222107, \"sum\": 21388.12804222107, \"min\": 21388.12804222107}}, \"EndTime\": 1597075953.535241, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597075932.145697}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:33 INFO 140371927496512] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7801, \"sum\": 7801.0, \"min\": 7801}, \"Total Records Seen\": {\"count\": 1, \"max\": 7797826, \"sum\": 7797826.0, \"min\": 7797826}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1597075953.53549, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 5}, \"StartTime\": 1597075932.147076}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:33 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60755.5049875 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:33 INFO 140371927496512] #quality_metric: host=algo-1, epoch=6, batch=0 train rmse <loss>=1.21493910397\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:33 INFO 140371927496512] #quality_metric: host=algo-1, epoch=6, batch=0 train mse <loss>=1.47607702637\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:33 INFO 140371927496512] #quality_metric: host=algo-1, epoch=6, batch=0 train absolute_loss <loss>=0.990114624023\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:41 INFO 140371927496512] Iter[6] Batch [500]#011Speed: 60654.39 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=6, batch=500 train rmse <loss>=1.08585258091\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=6, batch=500 train mse <loss>=1.17907582747\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=6, batch=500 train absolute_loss <loss>=0.86358357857\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:49 INFO 140371927496512] Iter[6] Batch [1000]#011Speed: 61355.38 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:49 INFO 140371927496512] #quality_metric: host=algo-1, epoch=6, batch=1000 train rmse <loss>=1.07249043271\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:49 INFO 140371927496512] #quality_metric: host=algo-1, epoch=6, batch=1000 train mse <loss>=1.15023572826\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:49 INFO 140371927496512] #quality_metric: host=algo-1, epoch=6, batch=1000 train absolute_loss <loss>=0.850678510454\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:12:54.925] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 21387, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=6, train rmse <loss>=1.07749831857\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=6, train mse <loss>=1.16100262653\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=6, train absolute_loss <loss>=0.852992037354\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21389.74094390869, \"sum\": 21389.74094390869, \"min\": 21389.74094390869}}, \"EndTime\": 1597075974.926376, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597075953.535325}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:54 INFO 140371927496512] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 9101, \"sum\": 9101.0, \"min\": 9101}, \"Total Records Seen\": {\"count\": 1, \"max\": 9097297, \"sum\": 9097297.0, \"min\": 9097297}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1597075974.926611, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 6}, \"StartTime\": 1597075953.536601}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:54 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60750.9176872 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=7, batch=0 train rmse <loss>=1.20723193113\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=7, batch=0 train mse <loss>=1.45740893555\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:12:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=7, batch=0 train absolute_loss <loss>=0.984488586426\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/10/2020 16:13:03 INFO 140371927496512] Iter[7] Batch [500]#011Speed: 60312.23 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:03 INFO 140371927496512] #quality_metric: host=algo-1, epoch=7, batch=500 train rmse <loss>=1.07603093351\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:03 INFO 140371927496512] #quality_metric: host=algo-1, epoch=7, batch=500 train mse <loss>=1.15784256987\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:03 INFO 140371927496512] #quality_metric: host=algo-1, epoch=7, batch=500 train absolute_loss <loss>=0.854443522257\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:11 INFO 140371927496512] Iter[7] Batch [1000]#011Speed: 61000.85 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=7, batch=1000 train rmse <loss>=1.06251687786\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=7, batch=1000 train mse <loss>=1.12894211575\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=7, batch=1000 train absolute_loss <loss>=0.841119380071\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:13:16.341] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 21411, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:16 INFO 140371927496512] #quality_metric: host=algo-1, epoch=7, train rmse <loss>=1.06750591449\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:16 INFO 140371927496512] #quality_metric: host=algo-1, epoch=7, train mse <loss>=1.13956887747\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:16 INFO 140371927496512] #quality_metric: host=algo-1, epoch=7, train absolute_loss <loss>=0.84333253925\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21413.90085220337, \"sum\": 21413.90085220337, \"min\": 21413.90085220337}}, \"EndTime\": 1597075996.341763, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597075974.926456}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:16 INFO 140371927496512] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 10401, \"sum\": 10401.0, \"min\": 10401}, \"Total Records Seen\": {\"count\": 1, \"max\": 10396768, \"sum\": 10396768.0, \"min\": 10396768}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1597075996.342018, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 7}, \"StartTime\": 1597075974.927826}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:16 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60682.2695858 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:16 INFO 140371927496512] #quality_metric: host=algo-1, epoch=8, batch=0 train rmse <loss>=1.19974108128\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:16 INFO 140371927496512] #quality_metric: host=algo-1, epoch=8, batch=0 train mse <loss>=1.43937866211\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:16 INFO 140371927496512] #quality_metric: host=algo-1, epoch=8, batch=0 train absolute_loss <loss>=0.97903503418\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:24 INFO 140371927496512] Iter[8] Batch [500]#011Speed: 60777.04 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=8, batch=500 train rmse <loss>=1.06667656492\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=8, batch=500 train mse <loss>=1.13779889416\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=8, batch=500 train absolute_loss <loss>=0.845779708162\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:32 INFO 140371927496512] Iter[8] Batch [1000]#011Speed: 60606.00 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=8, batch=1000 train rmse <loss>=1.05300397934\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=8, batch=1000 train mse <loss>=1.1088173805\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=8, batch=1000 train absolute_loss <loss>=0.832079580149\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:13:37.745] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 21400, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=8, train rmse <loss>=1.05796585411\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=8, train mse <loss>=1.11929174847\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=8, train absolute_loss <loss>=0.834197329571\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21402.761936187744, \"sum\": 21402.761936187744, \"min\": 21402.761936187744}}, \"EndTime\": 1597076017.74598, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597075996.341849}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:37 INFO 140371927496512] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 11701, \"sum\": 11701.0, \"min\": 11701}, \"Total Records Seen\": {\"count\": 1, \"max\": 11696239, \"sum\": 11696239.0, \"min\": 11696239}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1597076017.74624, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 8}, \"StartTime\": 1597075996.343182}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:37 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60713.9276896 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=9, batch=0 train rmse <loss>=1.19243546733\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=9, batch=0 train mse <loss>=1.42190234375\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=9, batch=0 train absolute_loss <loss>=0.973665588379\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:46 INFO 140371927496512] Iter[9] Batch [500]#011Speed: 60455.13 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:46 INFO 140371927496512] #quality_metric: host=algo-1, epoch=9, batch=500 train rmse <loss>=1.05770548072\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:46 INFO 140371927496512] #quality_metric: host=algo-1, epoch=9, batch=500 train mse <loss>=1.11874088395\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:46 INFO 140371927496512] #quality_metric: host=algo-1, epoch=9, batch=500 train absolute_loss <loss>=0.837482697691\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:54 INFO 140371927496512] Iter[9] Batch [1000]#011Speed: 60907.33 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=9, batch=1000 train rmse <loss>=1.04387650122\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=9, batch=1000 train mse <loss>=1.08967814979\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=9, batch=1000 train absolute_loss <loss>=0.82345766343\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:13:59.144] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 21395, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:59 INFO 140371927496512] #quality_metric: host=algo-1, epoch=9, train rmse <loss>=1.04880741257\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:59 INFO 140371927496512] #quality_metric: host=algo-1, epoch=9, train mse <loss>=1.09999698867\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:59 INFO 140371927496512] #quality_metric: host=algo-1, epoch=9, train absolute_loss <loss>=0.825490931021\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21397.266149520874, \"sum\": 21397.266149520874, \"min\": 21397.266149520874}}, \"EndTime\": 1597076039.144722, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076017.746083}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:59 INFO 140371927496512] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 13001, \"sum\": 13001.0, \"min\": 13001}, \"Total Records Seen\": {\"count\": 1, \"max\": 12995710, \"sum\": 12995710.0, \"min\": 12995710}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1597076039.144996, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 9}, \"StartTime\": 1597076017.747421}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:59 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60729.4565121 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:59 INFO 140371927496512] #quality_metric: host=algo-1, epoch=10, batch=0 train rmse <loss>=1.18529184088\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:59 INFO 140371927496512] #quality_metric: host=algo-1, epoch=10, batch=0 train mse <loss>=1.40491674805\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:13:59 INFO 140371927496512] #quality_metric: host=algo-1, epoch=10, batch=0 train absolute_loss <loss>=0.968324523926\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:07 INFO 140371927496512] Iter[10] Batch [500]#011Speed: 59619.69 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=10, batch=500 train rmse <loss>=1.04905251875\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=10, batch=500 train mse <loss>=1.1005111871\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=10, batch=500 train absolute_loss <loss>=0.829469417001\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/10/2020 16:14:15 INFO 140371927496512] Iter[10] Batch [1000]#011Speed: 60432.05 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=10, batch=1000 train rmse <loss>=1.03507495516\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=10, batch=1000 train mse <loss>=1.07138016281\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=10, batch=1000 train absolute_loss <loss>=0.815169242623\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:14:20.718] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 21571, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=10, train rmse <loss>=1.03997401874\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=10, train mse <loss>=1.08154595966\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=10, train absolute_loss <loss>=0.817129299035\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21573.040008544922, \"sum\": 21573.040008544922, \"min\": 21573.040008544922}}, \"EndTime\": 1597076060.719301, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076039.144813}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:20 INFO 140371927496512] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 14301, \"sum\": 14301.0, \"min\": 14301}, \"Total Records Seen\": {\"count\": 1, \"max\": 14295181, \"sum\": 14295181.0, \"min\": 14295181}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}}, \"EndTime\": 1597076060.719611, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 10}, \"StartTime\": 1597076039.146223}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:20 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60234.5796166 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=11, batch=0 train rmse <loss>=1.17829201402\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=11, batch=0 train mse <loss>=1.38837207031\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=11, batch=0 train absolute_loss <loss>=0.963014953613\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:28 INFO 140371927496512] Iter[11] Batch [500]#011Speed: 61009.55 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=11, batch=500 train rmse <loss>=1.04066736098\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=11, batch=500 train mse <loss>=1.08298855621\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=11, batch=500 train absolute_loss <loss>=0.821680566236\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:37 INFO 140371927496512] Iter[11] Batch [1000]#011Speed: 60638.65 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=11, batch=1000 train rmse <loss>=1.02655243472\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=11, batch=1000 train mse <loss>=1.05380990122\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=11, batch=1000 train absolute_loss <loss>=0.807152380395\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:14:42.005] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 21283, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:42 INFO 140371927496512] #quality_metric: host=algo-1, epoch=11, train rmse <loss>=1.03142062657\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:42 INFO 140371927496512] #quality_metric: host=algo-1, epoch=11, train mse <loss>=1.06382850891\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:42 INFO 140371927496512] #quality_metric: host=algo-1, epoch=11, train absolute_loss <loss>=0.8090503479\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21285.663843154907, \"sum\": 21285.663843154907, \"min\": 21285.663843154907}}, \"EndTime\": 1597076082.006475, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076060.719392}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:42 INFO 140371927496512] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 15601, \"sum\": 15601.0, \"min\": 15601}, \"Total Records Seen\": {\"count\": 1, \"max\": 15594652, \"sum\": 15594652.0, \"min\": 15594652}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1597076082.006687, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 11}, \"StartTime\": 1597076060.720774}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:42 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=61048.0818806 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:42 INFO 140371927496512] #quality_metric: host=algo-1, epoch=12, batch=0 train rmse <loss>=1.17142121422\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:42 INFO 140371927496512] #quality_metric: host=algo-1, epoch=12, batch=0 train mse <loss>=1.37222766113\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:42 INFO 140371927496512] #quality_metric: host=algo-1, epoch=12, batch=0 train absolute_loss <loss>=0.957734313965\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:50 INFO 140371927496512] Iter[12] Batch [500]#011Speed: 60854.95 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=12, batch=500 train rmse <loss>=1.03251091257\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=12, batch=500 train mse <loss>=1.06607878457\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=12, batch=500 train absolute_loss <loss>=0.814075445544\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:58 INFO 140371927496512] Iter[12] Batch [1000]#011Speed: 61439.71 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=12, batch=1000 train rmse <loss>=1.01827173146\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=12, batch=1000 train mse <loss>=1.03687731909\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:14:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=12, batch=1000 train absolute_loss <loss>=0.799361077887\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:15:03.322] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 21313, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:03 INFO 140371927496512] #quality_metric: host=algo-1, epoch=12, train rmse <loss>=1.02311119082\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:03 INFO 140371927496512] #quality_metric: host=algo-1, epoch=12, train mse <loss>=1.04675650879\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:03 INFO 140371927496512] #quality_metric: host=algo-1, epoch=12, train absolute_loss <loss>=0.801205937547\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21315.347909927368, \"sum\": 21315.347909927368, \"min\": 21315.347909927368}}, \"EndTime\": 1597076103.32326, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076082.006551}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:03 INFO 140371927496512] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 16901, \"sum\": 16901.0, \"min\": 16901}, \"Total Records Seen\": {\"count\": 1, \"max\": 16894123, \"sum\": 16894123.0, \"min\": 16894123}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 14, \"sum\": 14.0, \"min\": 14}}, \"EndTime\": 1597076103.323467, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 12}, \"StartTime\": 1597076082.007882}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:03 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60963.1214155 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:03 INFO 140371927496512] #quality_metric: host=algo-1, epoch=13, batch=0 train rmse <loss>=1.16466757554\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:03 INFO 140371927496512] #quality_metric: host=algo-1, epoch=13, batch=0 train mse <loss>=1.35645056152\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:03 INFO 140371927496512] #quality_metric: host=algo-1, epoch=13, batch=0 train absolute_loss <loss>=0.952467468262\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/10/2020 16:15:11 INFO 140371927496512] Iter[13] Batch [500]#011Speed: 61190.35 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=13, batch=500 train rmse <loss>=1.02455248957\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=13, batch=500 train mse <loss>=1.04970780387\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=13, batch=500 train absolute_loss <loss>=0.806628182843\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:19 INFO 140371927496512] Iter[13] Batch [1000]#011Speed: 61678.70 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:19 INFO 140371927496512] #quality_metric: host=algo-1, epoch=13, batch=1000 train rmse <loss>=1.01020307899\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:19 INFO 140371927496512] #quality_metric: host=algo-1, epoch=13, batch=1000 train mse <loss>=1.0205102608\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:19 INFO 140371927496512] #quality_metric: host=algo-1, epoch=13, batch=1000 train absolute_loss <loss>=0.791761823565\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:15:24.558] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 21232, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=13, train rmse <loss>=1.01501665578\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=13, train mse <loss>=1.0302588115\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=13, train absolute_loss <loss>=0.793560673359\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21234.740018844604, \"sum\": 21234.740018844604, \"min\": 21234.740018844604}}, \"EndTime\": 1597076124.559511, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076103.323329}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:24 INFO 140371927496512] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 18201, \"sum\": 18201.0, \"min\": 18201}, \"Total Records Seen\": {\"count\": 1, \"max\": 18193594, \"sum\": 18193594.0, \"min\": 18193594}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1597076124.559721, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 13}, \"StartTime\": 1597076103.324736}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:24 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=61194.4673376 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=14, batch=0 train rmse <loss>=1.15802097271\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=14, batch=0 train mse <loss>=1.34101257324\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=14, batch=0 train absolute_loss <loss>=0.947198852539\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:32 INFO 140371927496512] Iter[14] Batch [500]#011Speed: 60646.56 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=14, batch=500 train rmse <loss>=1.01676775306\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=14, batch=500 train mse <loss>=1.03381666367\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=14, batch=500 train absolute_loss <loss>=0.799317177291\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:41 INFO 140371927496512] Iter[14] Batch [1000]#011Speed: 60949.24 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=14, batch=1000 train rmse <loss>=1.0023224418\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=14, batch=1000 train mse <loss>=1.00465027733\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=14, batch=1000 train absolute_loss <loss>=0.78432810244\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:15:46.007] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 21445, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:46 INFO 140371927496512] #quality_metric: host=algo-1, epoch=14, train rmse <loss>=1.00711339809\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:46 INFO 140371927496512] #quality_metric: host=algo-1, epoch=14, train mse <loss>=1.01427739662\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:46 INFO 140371927496512] #quality_metric: host=algo-1, epoch=14, train absolute_loss <loss>=0.786087137639\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21447.461128234863, \"sum\": 21447.461128234863, \"min\": 21447.461128234863}}, \"EndTime\": 1597076146.008448, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076124.559587}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:46 INFO 140371927496512] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 19501, \"sum\": 19501.0, \"min\": 19501}, \"Total Records Seen\": {\"count\": 1, \"max\": 19493065, \"sum\": 19493065.0, \"min\": 19493065}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 16, \"sum\": 16.0, \"min\": 16}}, \"EndTime\": 1597076146.008649, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 14}, \"StartTime\": 1597076124.560955}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:46 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60587.6183266 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:46 INFO 140371927496512] #quality_metric: host=algo-1, epoch=15, batch=0 train rmse <loss>=1.15147324111\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:46 INFO 140371927496512] #quality_metric: host=algo-1, epoch=15, batch=0 train mse <loss>=1.325890625\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:46 INFO 140371927496512] #quality_metric: host=algo-1, epoch=15, batch=0 train absolute_loss <loss>=0.941958129883\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:54 INFO 140371927496512] Iter[15] Batch [500]#011Speed: 60452.70 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=15, batch=500 train rmse <loss>=1.00913724632\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=15, batch=500 train mse <loss>=1.01835798191\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:15:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=15, batch=500 train absolute_loss <loss>=0.792126170632\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:02 INFO 140371927496512] Iter[15] Batch [1000]#011Speed: 60404.65 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=15, batch=1000 train rmse <loss>=0.994610259163\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=15, batch=1000 train mse <loss>=0.989249567632\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=15, batch=1000 train absolute_loss <loss>=0.777040228082\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:16:07.580] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 21569, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=15, train rmse <loss>=0.999382069025\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=15, train mse <loss>=0.998764519888\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=15, train absolute_loss <loss>=0.778764959294\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21571.14601135254, \"sum\": 21571.14601135254, \"min\": 21571.14601135254}}, \"EndTime\": 1597076167.581093, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076146.008518}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:07 INFO 140371927496512] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 20801, \"sum\": 20801.0, \"min\": 20801}, \"Total Records Seen\": {\"count\": 1, \"max\": 20792536, \"sum\": 20792536.0, \"min\": 20792536}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 17, \"sum\": 17.0, \"min\": 17}}, \"EndTime\": 1597076167.581409, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 15}, \"StartTime\": 1597076146.009909}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:07 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60239.8236316 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=16, batch=0 train rmse <loss>=1.14501706839\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=16, batch=0 train mse <loss>=1.31106408691\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=16, batch=0 train absolute_loss <loss>=0.936725158691\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/10/2020 16:16:15 INFO 140371927496512] Iter[16] Batch [500]#011Speed: 60276.13 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=16, batch=500 train rmse <loss>=1.00164524566\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=16, batch=500 train mse <loss>=1.00329319815\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=16, batch=500 train absolute_loss <loss>=0.78504321484\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:24 INFO 140371927496512] Iter[16] Batch [1000]#011Speed: 61071.04 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=16, batch=1000 train rmse <loss>=0.987050466772\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=16, batch=1000 train mse <loss>=0.974268623954\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=16, batch=1000 train absolute_loss <loss>=0.769883394255\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:16:29.003] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 34, \"duration\": 21419, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:29 INFO 140371927496512] #quality_metric: host=algo-1, epoch=16, train rmse <loss>=0.991806686412\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:29 INFO 140371927496512] #quality_metric: host=algo-1, epoch=16, train mse <loss>=0.983680503211\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:29 INFO 140371927496512] #quality_metric: host=algo-1, epoch=16, train absolute_loss <loss>=0.771578597929\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21421.483993530273, \"sum\": 21421.483993530273, \"min\": 21421.483993530273}}, \"EndTime\": 1597076189.004167, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076167.581231}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:29 INFO 140371927496512] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 22101, \"sum\": 22101.0, \"min\": 22101}, \"Total Records Seen\": {\"count\": 1, \"max\": 22092007, \"sum\": 22092007.0, \"min\": 22092007}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 18, \"sum\": 18.0, \"min\": 18}}, \"EndTime\": 1597076189.004429, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 16}, \"StartTime\": 1597076167.582648}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:29 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60660.848775 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:29 INFO 140371927496512] #quality_metric: host=algo-1, epoch=17, batch=0 train rmse <loss>=1.13864656115\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:29 INFO 140371927496512] #quality_metric: host=algo-1, epoch=17, batch=0 train mse <loss>=1.29651599121\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:29 INFO 140371927496512] #quality_metric: host=algo-1, epoch=17, batch=0 train absolute_loss <loss>=0.93150378418\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:37 INFO 140371927496512] Iter[17] Batch [500]#011Speed: 60489.86 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=17, batch=500 train rmse <loss>=0.994278924316\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=17, batch=500 train mse <loss>=0.988590579339\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=17, batch=500 train absolute_loss <loss>=0.778059316548\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:45 INFO 140371927496512] Iter[17] Batch [1000]#011Speed: 60704.40 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=17, batch=1000 train rmse <loss>=0.979629759922\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=17, batch=1000 train mse <loss>=0.959674466525\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=17, batch=1000 train absolute_loss <loss>=0.762845616054\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:16:50.433] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 36, \"duration\": 21426, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=17, train rmse <loss>=0.984373946409\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=17, train mse <loss>=0.968992066369\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=17, train absolute_loss <loss>=0.764514937979\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21428.726196289062, \"sum\": 21428.726196289062, \"min\": 21428.726196289062}}, \"EndTime\": 1597076210.434377, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076189.004249}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:50 INFO 140371927496512] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 23401, \"sum\": 23401.0, \"min\": 23401}, \"Total Records Seen\": {\"count\": 1, \"max\": 23391478, \"sum\": 23391478.0, \"min\": 23391478}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 19, \"sum\": 19.0, \"min\": 19}}, \"EndTime\": 1597076210.434647, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 17}, \"StartTime\": 1597076189.005615}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:50 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60640.3032836 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=18, batch=0 train rmse <loss>=1.13235642759\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=18, batch=0 train mse <loss>=1.2822310791\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=18, batch=0 train absolute_loss <loss>=0.92629486084\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:58 INFO 140371927496512] Iter[18] Batch [500]#011Speed: 60132.18 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=18, batch=500 train rmse <loss>=0.98702776696\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=18, batch=500 train mse <loss>=0.97422381275\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:16:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=18, batch=500 train absolute_loss <loss>=0.771167554539\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:07 INFO 140371927496512] Iter[18] Batch [1000]#011Speed: 60635.54 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=18, batch=1000 train rmse <loss>=0.972337040654\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=18, batch=1000 train mse <loss>=0.945439320628\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=18, batch=1000 train absolute_loss <loss>=0.75591778534\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:17:11.909] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 38, \"duration\": 21472, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=18, train rmse <loss>=0.977072689374\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=18, train mse <loss>=0.954671040321\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=18, train absolute_loss <loss>=0.757565310575\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21474.55096244812, \"sum\": 21474.55096244812, \"min\": 21474.55096244812}}, \"EndTime\": 1597076231.910526, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076210.434467}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:11 INFO 140371927496512] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 24701, \"sum\": 24701.0, \"min\": 24701}, \"Total Records Seen\": {\"count\": 1, \"max\": 24690949, \"sum\": 24690949.0, \"min\": 24690949}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}}, \"EndTime\": 1597076231.910725, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 18}, \"StartTime\": 1597076210.435945}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:11 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60511.2052483 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=19, batch=0 train rmse <loss>=1.1261419985\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=19, batch=0 train mse <loss>=1.26819580078\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=19, batch=0 train absolute_loss <loss>=0.921093444824\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/10/2020 16:17:20 INFO 140371927496512] Iter[19] Batch [500]#011Speed: 60054.44 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=19, batch=500 train rmse <loss>=0.979883027206\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=19, batch=500 train mse <loss>=0.960170747007\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=19, batch=500 train absolute_loss <loss>=0.764363294773\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:28 INFO 140371927496512] Iter[19] Batch [1000]#011Speed: 60827.01 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=19, batch=1000 train rmse <loss>=0.965162969457\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=19, batch=1000 train mse <loss>=0.93153955761\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=19, batch=1000 train absolute_loss <loss>=0.749093065077\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:17:33.448] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 40, \"duration\": 21534, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:33 INFO 140371927496512] #quality_metric: host=algo-1, epoch=19, train rmse <loss>=0.969893489717\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:33 INFO 140371927496512] #quality_metric: host=algo-1, epoch=19, train mse <loss>=0.940693381395\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:33 INFO 140371927496512] #quality_metric: host=algo-1, epoch=19, train absolute_loss <loss>=0.750722757474\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21536.828994750977, \"sum\": 21536.828994750977, \"min\": 21536.828994750977}}, \"EndTime\": 1597076253.448841, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076231.910593}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:33 INFO 140371927496512] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 26001, \"sum\": 26001.0, \"min\": 26001}, \"Total Records Seen\": {\"count\": 1, \"max\": 25990420, \"sum\": 25990420.0, \"min\": 25990420}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 21, \"sum\": 21.0, \"min\": 21}}, \"EndTime\": 1597076253.449089, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 19}, \"StartTime\": 1597076231.911975}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:33 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60335.9932899 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:33 INFO 140371927496512] #quality_metric: host=algo-1, epoch=20, batch=0 train rmse <loss>=1.11999881199\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:33 INFO 140371927496512] #quality_metric: host=algo-1, epoch=20, batch=0 train mse <loss>=1.25439733887\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:33 INFO 140371927496512] #quality_metric: host=algo-1, epoch=20, batch=0 train absolute_loss <loss>=0.915902160645\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:41 INFO 140371927496512] Iter[20] Batch [500]#011Speed: 59963.68 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=20, batch=500 train rmse <loss>=0.972837437357\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=20, batch=500 train mse <loss>=0.946412679524\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=20, batch=500 train absolute_loss <loss>=0.757643554078\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:50 INFO 140371927496512] Iter[20] Batch [1000]#011Speed: 61011.03 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=20, batch=1000 train rmse <loss>=0.958099645173\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=20, batch=1000 train mse <loss>=0.91795493008\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=20, batch=1000 train absolute_loss <loss>=0.742366629098\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:17:54.971] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 42, \"duration\": 21519, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=20, train rmse <loss>=0.962828316559\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=20, train mse <loss>=0.927038367169\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=20, train absolute_loss <loss>=0.743981939744\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21521.646976470947, \"sum\": 21521.646976470947, \"min\": 21521.646976470947}}, \"EndTime\": 1597076274.972069, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076253.448924}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:54 INFO 140371927496512] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 27301, \"sum\": 27301.0, \"min\": 27301}, \"Total Records Seen\": {\"count\": 1, \"max\": 27289891, \"sum\": 27289891.0, \"min\": 27289891}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}}, \"EndTime\": 1597076274.972279, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 20}, \"StartTime\": 1597076253.45039}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:54 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60378.7512756 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:55 INFO 140371927496512] #quality_metric: host=algo-1, epoch=21, batch=0 train rmse <loss>=1.11392382771\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:55 INFO 140371927496512] #quality_metric: host=algo-1, epoch=21, batch=0 train mse <loss>=1.24082629395\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:17:55 INFO 140371927496512] #quality_metric: host=algo-1, epoch=21, batch=0 train absolute_loss <loss>=0.910734130859\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:03 INFO 140371927496512] Iter[21] Batch [500]#011Speed: 59747.28 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:03 INFO 140371927496512] #quality_metric: host=algo-1, epoch=21, batch=500 train rmse <loss>=0.965884851186\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:03 INFO 140371927496512] #quality_metric: host=algo-1, epoch=21, batch=500 train mse <loss>=0.93293354575\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:03 INFO 140371927496512] #quality_metric: host=algo-1, epoch=21, batch=500 train absolute_loss <loss>=0.751005453814\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:11 INFO 140371927496512] Iter[21] Batch [1000]#011Speed: 60657.53 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=21, batch=1000 train rmse <loss>=0.951140309003\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=21, batch=1000 train mse <loss>=0.90466788741\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=21, batch=1000 train absolute_loss <loss>=0.735733930437\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:18:16.526] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 44, \"duration\": 21551, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:16 INFO 140371927496512] #quality_metric: host=algo-1, epoch=21, train rmse <loss>=0.955870287387\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:16 INFO 140371927496512] #quality_metric: host=algo-1, epoch=21, train mse <loss>=0.91368800631\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:16 INFO 140371927496512] #quality_metric: host=algo-1, epoch=21, train absolute_loss <loss>=0.737338005183\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21553.06100845337, \"sum\": 21553.06100845337, \"min\": 21553.06100845337}}, \"EndTime\": 1597076296.526703, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076274.97214}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:16 INFO 140371927496512] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 28601, \"sum\": 28601.0, \"min\": 28601}, \"Total Records Seen\": {\"count\": 1, \"max\": 28589362, \"sum\": 28589362.0, \"min\": 28589362}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 23, \"sum\": 23.0, \"min\": 23}}, \"EndTime\": 1597076296.526894, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 21}, \"StartTime\": 1597076274.973588}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:16 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60290.6426987 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:16 INFO 140371927496512] #quality_metric: host=algo-1, epoch=22, batch=0 train rmse <loss>=1.10791326455\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:16 INFO 140371927496512] #quality_metric: host=algo-1, epoch=22, batch=0 train mse <loss>=1.22747180176\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:16 INFO 140371927496512] #quality_metric: host=algo-1, epoch=22, batch=0 train absolute_loss <loss>=0.905582519531\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/10/2020 16:18:24 INFO 140371927496512] Iter[22] Batch [500]#011Speed: 60033.63 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=22, batch=500 train rmse <loss>=0.959020079624\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=22, batch=500 train mse <loss>=0.919719513122\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=22, batch=500 train absolute_loss <loss>=0.744445897512\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:33 INFO 140371927496512] Iter[22] Batch [1000]#011Speed: 60775.65 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:33 INFO 140371927496512] #quality_metric: host=algo-1, epoch=22, batch=1000 train rmse <loss>=0.944279166244\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:33 INFO 140371927496512] #quality_metric: host=algo-1, epoch=22, batch=1000 train mse <loss>=0.891663143802\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:33 INFO 140371927496512] #quality_metric: host=algo-1, epoch=22, batch=1000 train absolute_loss <loss>=0.729191129732\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:18:37.991] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 46, \"duration\": 21462, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=22, train rmse <loss>=0.949013464294\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=22, train mse <loss>=0.900626555411\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=22, train absolute_loss <loss>=0.73078717811\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21464.282035827637, \"sum\": 21464.282035827637, \"min\": 21464.282035827637}}, \"EndTime\": 1597076317.992424, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076296.52677}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:37 INFO 140371927496512] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 29901, \"sum\": 29901.0, \"min\": 29901}, \"Total Records Seen\": {\"count\": 1, \"max\": 29888833, \"sum\": 29888833.0, \"min\": 29888833}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 24, \"sum\": 24.0, \"min\": 24}}, \"EndTime\": 1597076317.992636, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 22}, \"StartTime\": 1597076296.52811}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:37 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60540.1067856 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:38 INFO 140371927496512] #quality_metric: host=algo-1, epoch=23, batch=0 train rmse <loss>=1.10196435489\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:38 INFO 140371927496512] #quality_metric: host=algo-1, epoch=23, batch=0 train mse <loss>=1.21432543945\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:38 INFO 140371927496512] #quality_metric: host=algo-1, epoch=23, batch=0 train absolute_loss <loss>=0.900449951172\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:46 INFO 140371927496512] Iter[23] Batch [500]#011Speed: 60823.21 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:46 INFO 140371927496512] #quality_metric: host=algo-1, epoch=23, batch=500 train rmse <loss>=0.952238670562\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:46 INFO 140371927496512] #quality_metric: host=algo-1, epoch=23, batch=500 train mse <loss>=0.906758485714\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:46 INFO 140371927496512] #quality_metric: host=algo-1, epoch=23, batch=500 train absolute_loss <loss>=0.737961772013\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:54 INFO 140371927496512] Iter[23] Batch [1000]#011Speed: 61656.50 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=23, batch=1000 train rmse <loss>=0.937511181655\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=23, batch=1000 train mse <loss>=0.878927215729\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=23, batch=1000 train absolute_loss <loss>=0.72273458408\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:18:59.214] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 48, \"duration\": 21218, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:59 INFO 140371927496512] #quality_metric: host=algo-1, epoch=23, train rmse <loss>=0.942252671601\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:59 INFO 140371927496512] #quality_metric: host=algo-1, epoch=23, train mse <loss>=0.88784009714\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:59 INFO 140371927496512] #quality_metric: host=algo-1, epoch=23, train absolute_loss <loss>=0.724325696176\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21220.792055130005, \"sum\": 21220.792055130005, \"min\": 21220.792055130005}}, \"EndTime\": 1597076339.214675, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076317.992503}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:59 INFO 140371927496512] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 31201, \"sum\": 31201.0, \"min\": 31201}, \"Total Records Seen\": {\"count\": 1, \"max\": 31188304, \"sum\": 31188304.0, \"min\": 31188304}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 25, \"sum\": 25.0, \"min\": 25}}, \"EndTime\": 1597076339.214919, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 23}, \"StartTime\": 1597076317.993852}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:59 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=61234.6306432 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:59 INFO 140371927496512] #quality_metric: host=algo-1, epoch=24, batch=0 train rmse <loss>=1.09607426034\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:59 INFO 140371927496512] #quality_metric: host=algo-1, epoch=24, batch=0 train mse <loss>=1.20137878418\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:18:59 INFO 140371927496512] #quality_metric: host=algo-1, epoch=24, batch=0 train absolute_loss <loss>=0.895340454102\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:07 INFO 140371927496512] Iter[24] Batch [500]#011Speed: 60392.22 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=24, batch=500 train rmse <loss>=0.94553679792\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=24, batch=500 train mse <loss>=0.894039836221\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=24, batch=500 train absolute_loss <loss>=0.731552178845\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:15 INFO 140371927496512] Iter[24] Batch [1000]#011Speed: 60455.92 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=24, batch=1000 train rmse <loss>=0.930831970504\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=24, batch=1000 train mse <loss>=0.866448157311\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=24, batch=1000 train absolute_loss <loss>=0.716362410539\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:19:20.674] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 50, \"duration\": 21456, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=24, train rmse <loss>=0.935583383993\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=24, train mse <loss>=0.875316268404\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=24, train absolute_loss <loss>=0.71795130465\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21459.184885025024, \"sum\": 21459.184885025024, \"min\": 21459.184885025024}}, \"EndTime\": 1597076360.675423, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076339.214761}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:20 INFO 140371927496512] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 32501, \"sum\": 32501.0, \"min\": 32501}, \"Total Records Seen\": {\"count\": 1, \"max\": 32487775, \"sum\": 32487775.0, \"min\": 32487775}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 26, \"sum\": 26.0, \"min\": 26}}, \"EndTime\": 1597076360.675635, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 24}, \"StartTime\": 1597076339.216205}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:20 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60554.4582483 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=25, batch=0 train rmse <loss>=1.09024040721\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=25, batch=0 train mse <loss>=1.18862414551\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=25, batch=0 train absolute_loss <loss>=0.890248840332\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/10/2020 16:19:28 INFO 140371927496512] Iter[25] Batch [500]#011Speed: 60977.35 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=25, batch=500 train rmse <loss>=0.938911140512\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=25, batch=500 train mse <loss>=0.881554129778\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=25, batch=500 train absolute_loss <loss>=0.72521514588\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:37 INFO 140371927496512] Iter[25] Batch [1000]#011Speed: 61612.38 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=25, batch=1000 train rmse <loss>=0.92423767263\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=25, batch=1000 train mse <loss>=0.854215275508\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=25, batch=1000 train absolute_loss <loss>=0.710071711309\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:19:41.878] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 52, \"duration\": 21200, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=25, train rmse <loss>=0.929001603045\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=25, train mse <loss>=0.863043978459\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=25, train absolute_loss <loss>=0.71166077139\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21202.15106010437, \"sum\": 21202.15106010437, \"min\": 21202.15106010437}}, \"EndTime\": 1597076381.879109, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076360.6755}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:41 INFO 140371927496512] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 33801, \"sum\": 33801.0, \"min\": 33801}, \"Total Records Seen\": {\"count\": 1, \"max\": 33787246, \"sum\": 33787246.0, \"min\": 33787246}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 27, \"sum\": 27.0, \"min\": 27}}, \"EndTime\": 1597076381.879319, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 25}, \"StartTime\": 1597076360.676923}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:41 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=61288.614819 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=26, batch=0 train rmse <loss>=1.08446043882\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=26, batch=0 train mse <loss>=1.17605444336\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=26, batch=0 train absolute_loss <loss>=0.88517755127\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:50 INFO 140371927496512] Iter[26] Batch [500]#011Speed: 60704.94 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=26, batch=500 train rmse <loss>=0.932358804258\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=26, batch=500 train mse <loss>=0.869292939877\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=26, batch=500 train absolute_loss <loss>=0.718949807538\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:58 INFO 140371927496512] Iter[26] Batch [1000]#011Speed: 61301.98 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=26, batch=1000 train rmse <loss>=0.917724885609\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=26, batch=1000 train mse <loss>=0.842218965666\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:19:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=26, batch=1000 train absolute_loss <loss>=0.703861205323\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:20:03.195] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 54, \"duration\": 21313, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:03 INFO 140371927496512] #quality_metric: host=algo-1, epoch=26, train rmse <loss>=0.922503782187\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:03 INFO 140371927496512] #quality_metric: host=algo-1, epoch=26, train mse <loss>=0.851013228149\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:03 INFO 140371927496512] #quality_metric: host=algo-1, epoch=26, train absolute_loss <loss>=0.705452865366\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21315.820932388306, \"sum\": 21315.820932388306, \"min\": 21315.820932388306}}, \"EndTime\": 1597076403.196399, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076381.879185}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:03 INFO 140371927496512] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 35101, \"sum\": 35101.0, \"min\": 35101}, \"Total Records Seen\": {\"count\": 1, \"max\": 35086717, \"sum\": 35086717.0, \"min\": 35086717}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 28, \"sum\": 28.0, \"min\": 28}}, \"EndTime\": 1597076403.196653, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 26}, \"StartTime\": 1597076381.880543}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:03 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60961.5654053 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:03 INFO 140371927496512] #quality_metric: host=algo-1, epoch=27, batch=0 train rmse <loss>=1.07873261863\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:03 INFO 140371927496512] #quality_metric: host=algo-1, epoch=27, batch=0 train mse <loss>=1.1636640625\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:03 INFO 140371927496512] #quality_metric: host=algo-1, epoch=27, batch=0 train absolute_loss <loss>=0.880128051758\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:11 INFO 140371927496512] Iter[27] Batch [500]#011Speed: 60839.04 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=27, batch=500 train rmse <loss>=0.925877213559\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=27, batch=500 train mse <loss>=0.857248614587\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=27, batch=500 train absolute_loss <loss>=0.712755871314\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:19 INFO 140371927496512] Iter[27] Batch [1000]#011Speed: 61327.58 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:19 INFO 140371927496512] #quality_metric: host=algo-1, epoch=27, batch=1000 train rmse <loss>=0.911290558735\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:19 INFO 140371927496512] #quality_metric: host=algo-1, epoch=27, batch=1000 train mse <loss>=0.83045048244\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:19 INFO 140371927496512] #quality_metric: host=algo-1, epoch=27, batch=1000 train absolute_loss <loss>=0.697729877178\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:20:24.438] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 56, \"duration\": 21238, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=27, train rmse <loss>=0.916086750124\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=27, train mse <loss>=0.839214933753\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=27, train absolute_loss <loss>=0.699326372023\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21240.707874298096, \"sum\": 21240.707874298096, \"min\": 21240.707874298096}}, \"EndTime\": 1597076424.438746, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076403.19648}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:24 INFO 140371927496512] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 36401, \"sum\": 36401.0, \"min\": 36401}, \"Total Records Seen\": {\"count\": 1, \"max\": 36386188, \"sum\": 36386188.0, \"min\": 36386188}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 29, \"sum\": 29.0, \"min\": 29}}, \"EndTime\": 1597076424.438965, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 27}, \"StartTime\": 1597076403.198006}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:24 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=61177.307893 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=28, batch=0 train rmse <loss>=1.07305431206\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=28, batch=0 train mse <loss>=1.15144555664\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=28, batch=0 train absolute_loss <loss>=0.875097717285\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/10/2020 16:20:32 INFO 140371927496512] Iter[28] Batch [500]#011Speed: 60348.76 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=28, batch=500 train rmse <loss>=0.919464105985\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=28, batch=500 train mse <loss>=0.845414242194\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=28, batch=500 train absolute_loss <loss>=0.706632534735\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:40 INFO 140371927496512] Iter[28] Batch [1000]#011Speed: 60796.27 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:40 INFO 140371927496512] #quality_metric: host=algo-1, epoch=28, batch=1000 train rmse <loss>=0.90493196334\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:40 INFO 140371927496512] #quality_metric: host=algo-1, epoch=28, batch=1000 train mse <loss>=0.818901858274\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:40 INFO 140371927496512] #quality_metric: host=algo-1, epoch=28, batch=1000 train absolute_loss <loss>=0.691675576133\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:20:45.907] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 58, \"duration\": 21465, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=28, train rmse <loss>=0.909747648331\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=28, train mse <loss>=0.827640783644\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=28, train absolute_loss <loss>=0.693279066913\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21467.64612197876, \"sum\": 21467.64612197876, \"min\": 21467.64612197876}}, \"EndTime\": 1597076445.907936, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076424.438822}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:45 INFO 140371927496512] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 37701, \"sum\": 37701.0, \"min\": 37701}, \"Total Records Seen\": {\"count\": 1, \"max\": 37685659, \"sum\": 37685659.0, \"min\": 37685659}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 30, \"sum\": 30.0, \"min\": 30}}, \"EndTime\": 1597076445.908142, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 28}, \"StartTime\": 1597076424.440259}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:45 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60530.6482398 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=29, batch=0 train rmse <loss>=1.06742413647\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=29, batch=0 train mse <loss>=1.13939428711\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=29, batch=0 train absolute_loss <loss>=0.870089111328\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:54 INFO 140371927496512] Iter[29] Batch [500]#011Speed: 60186.48 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=29, batch=500 train rmse <loss>=0.913117472339\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=29, batch=500 train mse <loss>=0.833783518291\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:20:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=29, batch=500 train absolute_loss <loss>=0.700577603947\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:02 INFO 140371927496512] Iter[29] Batch [1000]#011Speed: 61113.92 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=29, batch=1000 train rmse <loss>=0.898646650584\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=29, batch=1000 train mse <loss>=0.807565802606\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=29, batch=1000 train absolute_loss <loss>=0.685696497228\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:21:07.424] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 60, \"duration\": 21513, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=29, train rmse <loss>=0.90348390178\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=29, train mse <loss>=0.816283160776\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=29, train absolute_loss <loss>=0.687309190392\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21515.717029571533, \"sum\": 21515.717029571533, \"min\": 21515.717029571533}}, \"EndTime\": 1597076467.425142, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076445.90801}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:07 INFO 140371927496512] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 39001, \"sum\": 39001.0, \"min\": 39001}, \"Total Records Seen\": {\"count\": 1, \"max\": 38985130, \"sum\": 38985130.0, \"min\": 38985130}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}}, \"EndTime\": 1597076467.425387, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 29}, \"StartTime\": 1597076445.90939}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:07 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60395.2802341 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=30, batch=0 train rmse <loss>=1.06184021334\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=30, batch=0 train mse <loss>=1.12750463867\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=30, batch=0 train absolute_loss <loss>=0.865102844238\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:15 INFO 140371927496512] Iter[30] Batch [500]#011Speed: 60382.29 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=30, batch=500 train rmse <loss>=0.906835474883\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=30, batch=500 train mse <loss>=0.822350578506\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=30, batch=500 train absolute_loss <loss>=0.694590945063\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:23 INFO 140371927496512] Iter[30] Batch [1000]#011Speed: 60621.53 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:23 INFO 140371927496512] #quality_metric: host=algo-1, epoch=30, batch=1000 train rmse <loss>=0.892432372062\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:23 INFO 140371927496512] #quality_metric: host=algo-1, epoch=30, batch=1000 train mse <loss>=0.796435538704\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:23 INFO 140371927496512] #quality_metric: host=algo-1, epoch=30, batch=1000 train absolute_loss <loss>=0.679791303179\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:21:28.895] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 62, \"duration\": 21466, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=30, train rmse <loss>=0.897293151782\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=30, train mse <loss>=0.805135000235\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=30, train absolute_loss <loss>=0.681415067984\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21469.160795211792, \"sum\": 21469.160795211792, \"min\": 21469.160795211792}}, \"EndTime\": 1597076488.895921, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076467.425224}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:28 INFO 140371927496512] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 40301, \"sum\": 40301.0, \"min\": 40301}, \"Total Records Seen\": {\"count\": 1, \"max\": 40284601, \"sum\": 40284601.0, \"min\": 40284601}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 32, \"sum\": 32.0, \"min\": 32}}, \"EndTime\": 1597076488.896195, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 30}, \"StartTime\": 1597076467.426724}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:28 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60526.0444204 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=31, batch=0 train rmse <loss>=1.05630084937\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=31, batch=0 train mse <loss>=1.11577148437\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=31, batch=0 train absolute_loss <loss>=0.860138061523\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/10/2020 16:21:37 INFO 140371927496512] Iter[31] Batch [500]#011Speed: 60916.34 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=31, batch=500 train rmse <loss>=0.900616476699\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=31, batch=500 train mse <loss>=0.811110038103\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=31, batch=500 train absolute_loss <loss>=0.688671250882\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:45 INFO 140371927496512] Iter[31] Batch [1000]#011Speed: 61254.36 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=31, batch=1000 train rmse <loss>=0.886287090942\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=31, batch=1000 train mse <loss>=0.78550480757\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=31, batch=1000 train absolute_loss <loss>=0.673959239125\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:21:50.149] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 64, \"duration\": 21250, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=31, train rmse <loss>=0.891173246642\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=31, train mse <loss>=0.794189755531\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=31, train absolute_loss <loss>=0.67559583097\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21252.795934677124, \"sum\": 21252.795934677124, \"min\": 21252.795934677124}}, \"EndTime\": 1597076510.150363, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076488.896012}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:50 INFO 140371927496512] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 41601, \"sum\": 41601.0, \"min\": 41601}, \"Total Records Seen\": {\"count\": 1, \"max\": 41584072, \"sum\": 41584072.0, \"min\": 41584072}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 33, \"sum\": 33.0, \"min\": 33}}, \"EndTime\": 1597076510.150572, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 31}, \"StartTime\": 1597076488.897536}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:50 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=61142.5445831 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=32, batch=0 train rmse <loss>=1.0508046582\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=32, batch=0 train mse <loss>=1.10419042969\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:50 INFO 140371927496512] #quality_metric: host=algo-1, epoch=32, batch=0 train absolute_loss <loss>=0.855196228027\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:58 INFO 140371927496512] Iter[32] Batch [500]#011Speed: 60621.20 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=32, batch=500 train rmse <loss>=0.894458979906\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=32, batch=500 train mse <loss>=0.800056866735\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:21:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=32, batch=500 train absolute_loss <loss>=0.682817184113\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:06 INFO 140371927496512] Iter[32] Batch [1000]#011Speed: 60612.36 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:06 INFO 140371927496512] #quality_metric: host=algo-1, epoch=32, batch=1000 train rmse <loss>=0.880208932763\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:06 INFO 140371927496512] #quality_metric: host=algo-1, epoch=32, batch=1000 train mse <loss>=0.774767765316\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:06 INFO 140371927496512] #quality_metric: host=algo-1, epoch=32, batch=1000 train absolute_loss <loss>=0.668199051498\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:22:11.491] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 66, \"duration\": 21338, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=32, train rmse <loss>=0.885122206094\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=32, train mse <loss>=0.783441319721\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=32, train absolute_loss <loss>=0.669850125545\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21340.600967407227, \"sum\": 21340.600967407227, \"min\": 21340.600967407227}}, \"EndTime\": 1597076531.49248, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076510.150437}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:11 INFO 140371927496512] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 42901, \"sum\": 42901.0, \"min\": 42901}, \"Total Records Seen\": {\"count\": 1, \"max\": 42883543, \"sum\": 42883543.0, \"min\": 42883543}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 34, \"sum\": 34.0, \"min\": 34}}, \"EndTime\": 1597076531.492721, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 32}, \"StartTime\": 1597076510.151849}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:11 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60890.7576736 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=33, batch=0 train rmse <loss>=1.04535016048\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=33, batch=0 train mse <loss>=1.09275695801\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=33, batch=0 train absolute_loss <loss>=0.850285583496\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:19 INFO 140371927496512] Iter[33] Batch [500]#011Speed: 60379.41 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:19 INFO 140371927496512] #quality_metric: host=algo-1, epoch=33, batch=500 train rmse <loss>=0.888361605587\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:19 INFO 140371927496512] #quality_metric: host=algo-1, epoch=33, batch=500 train mse <loss>=0.789186342281\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:19 INFO 140371927496512] #quality_metric: host=algo-1, epoch=33, batch=500 train absolute_loss <loss>=0.677028328353\u001b[0m\n",
      "\n",
      "2020-08-10 16:29:02 Uploading - Uploading generated training model\n",
      "2020-08-10 16:29:02 Completed - Training job completed\n",
      "\u001b[34m[08/10/2020 16:22:28 INFO 140371927496512] Iter[33] Batch [1000]#011Speed: 60967.46 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=33, batch=1000 train rmse <loss>=0.874196166449\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=33, batch=1000 train mse <loss>=0.764218937435\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=33, batch=1000 train absolute_loss <loss>=0.662509599165\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:22:32.883] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 68, \"duration\": 21388, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=33, train rmse <loss>=0.879138195276\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=33, train mse <loss>=0.772883966393\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=33, train absolute_loss <loss>=0.664176380474\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21390.246152877808, \"sum\": 21390.246152877808, \"min\": 21390.246152877808}}, \"EndTime\": 1597076552.884389, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076531.492557}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:32 INFO 140371927496512] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 44201, \"sum\": 44201.0, \"min\": 44201}, \"Total Records Seen\": {\"count\": 1, \"max\": 44183014, \"sum\": 44183014.0, \"min\": 44183014}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 35, \"sum\": 35.0, \"min\": 35}}, \"EndTime\": 1597076552.884638, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 33}, \"StartTime\": 1597076531.494107}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:32 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60749.3589483 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=34, batch=0 train rmse <loss>=1.03993642759\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=34, batch=0 train mse <loss>=1.08146777344\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=34, batch=0 train absolute_loss <loss>=0.845404052734\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:41 INFO 140371927496512] Iter[34] Batch [500]#011Speed: 60700.24 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=34, batch=500 train rmse <loss>=0.882323095993\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=34, batch=500 train mse <loss>=0.778494045722\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=34, batch=500 train absolute_loss <loss>=0.671303886246\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:49 INFO 140371927496512] Iter[34] Batch [1000]#011Speed: 61247.83 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:49 INFO 140371927496512] #quality_metric: host=algo-1, epoch=34, batch=1000 train rmse <loss>=0.868247185334\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:49 INFO 140371927496512] #quality_metric: host=algo-1, epoch=34, batch=1000 train mse <loss>=0.75385317484\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:49 INFO 140371927496512] #quality_metric: host=algo-1, epoch=34, batch=1000 train absolute_loss <loss>=0.656889817275\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:22:54.240] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 70, \"duration\": 21352, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=34, train rmse <loss>=0.873219518186\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=34, train mse <loss>=0.762512326942\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=34, train absolute_loss <loss>=0.658573547551\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21355.201959609985, \"sum\": 21355.201959609985, \"min\": 21355.201959609985}}, \"EndTime\": 1597076574.241185, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076552.884469}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:54 INFO 140371927496512] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 45501, \"sum\": 45501.0, \"min\": 45501}, \"Total Records Seen\": {\"count\": 1, \"max\": 45482485, \"sum\": 45482485.0, \"min\": 45482485}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 36, \"sum\": 36.0, \"min\": 36}}, \"EndTime\": 1597076574.24142, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 34}, \"StartTime\": 1597076552.885948}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:54 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60849.2172577 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=35, batch=0 train rmse <loss>=1.03456168066\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=35, batch=0 train mse <loss>=1.07031787109\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:22:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=35, batch=0 train absolute_loss <loss>=0.840567871094\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:02 INFO 140371927496512] Iter[35] Batch [500]#011Speed: 60325.57 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=35, batch=500 train rmse <loss>=0.876342290419\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=35, batch=500 train mse <loss>=0.767975809977\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=35, batch=500 train absolute_loss <loss>=0.665642628074\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:10 INFO 140371927496512] Iter[35] Batch [1000]#011Speed: 60692.53 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:10 INFO 140371927496512] #quality_metric: host=algo-1, epoch=35, batch=1000 train rmse <loss>=0.862360508458\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:10 INFO 140371927496512] #quality_metric: host=algo-1, epoch=35, batch=1000 train mse <loss>=0.743665646548\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:10 INFO 140371927496512] #quality_metric: host=algo-1, epoch=35, batch=1000 train absolute_loss <loss>=0.651338562195\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:23:15.676] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 72, \"duration\": 21431, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=35, train rmse <loss>=0.867364593864\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=35, train mse <loss>=0.752321338689\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=35, train absolute_loss <loss>=0.65304062885\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21433.839082717896, \"sum\": 21433.839082717896, \"min\": 21433.839082717896}}, \"EndTime\": 1597076595.676657, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076574.241255}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:15 INFO 140371927496512] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 46801, \"sum\": 46801.0, \"min\": 46801}, \"Total Records Seen\": {\"count\": 1, \"max\": 46781956, \"sum\": 46781956.0, \"min\": 46781956}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 37, \"sum\": 37.0, \"min\": 37}}, \"EndTime\": 1597076595.676896, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 35}, \"StartTime\": 1597076574.242746}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:15 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60625.8490654 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=36, batch=0 train rmse <loss>=1.0292251665\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=36, batch=0 train mse <loss>=1.05930444336\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=36, batch=0 train absolute_loss <loss>=0.835762695313\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:24 INFO 140371927496512] Iter[36] Batch [500]#011Speed: 59440.59 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=36, batch=500 train rmse <loss>=0.870418114864\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=36, batch=500 train mse <loss>=0.757627694684\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=36, batch=500 train absolute_loss <loss>=0.660043499549\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:32 INFO 140371927496512] Iter[36] Batch [1000]#011Speed: 61462.85 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=36, batch=1000 train rmse <loss>=0.856534741323\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=36, batch=1000 train mse <loss>=0.733651763093\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=36, batch=1000 train absolute_loss <loss>=0.645853870434\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:23:37.181] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 74, \"duration\": 21501, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=36, train rmse <loss>=0.861571943349\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=36, train mse <loss>=0.742306213567\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=36, train absolute_loss <loss>=0.647575683829\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21503.7899017334, \"sum\": 21503.7899017334, \"min\": 21503.7899017334}}, \"EndTime\": 1597076617.182111, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076595.676739}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:37 INFO 140371927496512] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 48101, \"sum\": 48101.0, \"min\": 48101}, \"Total Records Seen\": {\"count\": 1, \"max\": 48081427, \"sum\": 48081427.0, \"min\": 48081427}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 38, \"sum\": 38.0, \"min\": 38}}, \"EndTime\": 1597076617.182323, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 36}, \"StartTime\": 1597076595.678265}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:37 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60428.7974488 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=37, batch=0 train rmse <loss>=1.02392575424\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=37, batch=0 train mse <loss>=1.0484239502\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:37 INFO 140371927496512] #quality_metric: host=algo-1, epoch=37, batch=0 train absolute_loss <loss>=0.83099206543\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:45 INFO 140371927496512] Iter[37] Batch [500]#011Speed: 60346.22 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=37, batch=500 train rmse <loss>=0.864549555583\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=37, batch=500 train mse <loss>=0.74744593406\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=37, batch=500 train absolute_loss <loss>=0.654505911151\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:53 INFO 140371927496512] Iter[37] Batch [1000]#011Speed: 60741.16 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:53 INFO 140371927496512] #quality_metric: host=algo-1, epoch=37, batch=1000 train rmse <loss>=0.850768584691\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:53 INFO 140371927496512] #quality_metric: host=algo-1, epoch=37, batch=1000 train mse <loss>=0.723807184698\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:53 INFO 140371927496512] #quality_metric: host=algo-1, epoch=37, batch=1000 train absolute_loss <loss>=0.640434429645\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:23:58.634] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 76, \"duration\": 21448, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=37, train rmse <loss>=0.855840186119\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=37, train mse <loss>=0.732462424176\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=37, train absolute_loss <loss>=0.642177120737\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21451.157093048096, \"sum\": 21451.157093048096, \"min\": 21451.157093048096}}, \"EndTime\": 1597076638.634805, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076617.182173}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:58 INFO 140371927496512] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 49401, \"sum\": 49401.0, \"min\": 49401}, \"Total Records Seen\": {\"count\": 1, \"max\": 49380898, \"sum\": 49380898.0, \"min\": 49380898}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 39, \"sum\": 39.0, \"min\": 39}}, \"EndTime\": 1597076638.635066, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 37}, \"StartTime\": 1597076617.183612}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:58 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60576.9141717 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=38, batch=0 train rmse <loss>=1.01866240517\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=38, batch=0 train mse <loss>=1.0376730957\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:23:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=38, batch=0 train absolute_loss <loss>=0.826238952637\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:07 INFO 140371927496512] Iter[38] Batch [500]#011Speed: 59954.50 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=38, batch=500 train rmse <loss>=0.858735689777\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=38, batch=500 train mse <loss>=0.737426984897\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=38, batch=500 train absolute_loss <loss>=0.649028785812\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:15 INFO 140371927496512] Iter[38] Batch [1000]#011Speed: 61072.52 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=38, batch=1000 train rmse <loss>=0.84506082051\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=38, batch=1000 train mse <loss>=0.714127790361\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=38, batch=1000 train absolute_loss <loss>=0.635079449176\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:24:20.033] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 78, \"duration\": 21395, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=38, train rmse <loss>=0.850168018261\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=38, train mse <loss>=0.722785659274\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=38, train absolute_loss <loss>=0.636843990572\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21397.670030593872, \"sum\": 21397.670030593872, \"min\": 21397.670030593872}}, \"EndTime\": 1597076660.034117, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076638.634883}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:20 INFO 140371927496512] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 50701, \"sum\": 50701.0, \"min\": 50701}, \"Total Records Seen\": {\"count\": 1, \"max\": 50680369, \"sum\": 50680369.0, \"min\": 50680369}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 40, \"sum\": 40.0, \"min\": 40}}, \"EndTime\": 1597076660.034323, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 38}, \"StartTime\": 1597076638.636413}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:20 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60728.5768632 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=39, batch=0 train rmse <loss>=1.01343423575\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=39, batch=0 train mse <loss>=1.0270489502\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:20 INFO 140371927496512] #quality_metric: host=algo-1, epoch=39, batch=0 train absolute_loss <loss>=0.821503112793\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:28 INFO 140371927496512] Iter[39] Batch [500]#011Speed: 61112.22 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=39, batch=500 train rmse <loss>=0.852975621476\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=39, batch=500 train mse <loss>=0.727567410833\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=39, batch=500 train absolute_loss <loss>=0.643610691215\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:36 INFO 140371927496512] Iter[39] Batch [1000]#011Speed: 61183.57 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:36 INFO 140371927496512] #quality_metric: host=algo-1, epoch=39, batch=1000 train rmse <loss>=0.839410296486\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:36 INFO 140371927496512] #quality_metric: host=algo-1, epoch=39, batch=1000 train mse <loss>=0.704609645847\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:36 INFO 140371927496512] #quality_metric: host=algo-1, epoch=39, batch=1000 train absolute_loss <loss>=0.629786877856\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:24:41.270] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 80, \"duration\": 21233, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=39, train rmse <loss>=0.844554214619\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=39, train mse <loss>=0.71327182143\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=39, train absolute_loss <loss>=0.631574426504\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21235.81290245056, \"sum\": 21235.81290245056, \"min\": 21235.81290245056}}, \"EndTime\": 1597076681.271521, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076660.034188}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:41 INFO 140371927496512] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 52001, \"sum\": 52001.0, \"min\": 52001}, \"Total Records Seen\": {\"count\": 1, \"max\": 51979840, \"sum\": 51979840.0, \"min\": 51979840}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 41, \"sum\": 41.0, \"min\": 41}}, \"EndTime\": 1597076681.271727, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 39}, \"StartTime\": 1597076660.035676}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:41 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=61191.444401 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=40, batch=0 train rmse <loss>=1.00824046146\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=40, batch=0 train mse <loss>=1.01654882812\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=40, batch=0 train absolute_loss <loss>=0.816784606934\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:49 INFO 140371927496512] Iter[40] Batch [500]#011Speed: 60135.07 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:49 INFO 140371927496512] #quality_metric: host=algo-1, epoch=40, batch=500 train rmse <loss>=0.847268528399\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:49 INFO 140371927496512] #quality_metric: host=algo-1, epoch=40, batch=500 train mse <loss>=0.717863959215\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:49 INFO 140371927496512] #quality_metric: host=algo-1, epoch=40, batch=500 train absolute_loss <loss>=0.638251578021\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:57 INFO 140371927496512] Iter[40] Batch [1000]#011Speed: 60828.06 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:57 INFO 140371927496512] #quality_metric: host=algo-1, epoch=40, batch=1000 train rmse <loss>=0.833815933926\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:57 INFO 140371927496512] #quality_metric: host=algo-1, epoch=40, batch=1000 train mse <loss>=0.695249011669\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:24:57 INFO 140371927496512] #quality_metric: host=algo-1, epoch=40, batch=1000 train absolute_loss <loss>=0.624556416362\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:25:02.728] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 82, \"duration\": 21453, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=40, train rmse <loss>=0.838997618993\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=40, train mse <loss>=0.703917004676\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=40, train absolute_loss <loss>=0.626367740009\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21455.87706565857, \"sum\": 21455.87706565857, \"min\": 21455.87706565857}}, \"EndTime\": 1597076702.728964, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076681.271588}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:02 INFO 140371927496512] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 53301, \"sum\": 53301.0, \"min\": 53301}, \"Total Records Seen\": {\"count\": 1, \"max\": 53279311, \"sum\": 53279311.0, \"min\": 53279311}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 42, \"sum\": 42.0, \"min\": 42}}, \"EndTime\": 1597076702.729165, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 40}, \"StartTime\": 1597076681.273056}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:02 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60563.8172338 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=41, batch=0 train rmse <loss>=1.00308036919\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=41, batch=0 train mse <loss>=1.00617022705\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=41, batch=0 train absolute_loss <loss>=0.812083435059\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:11 INFO 140371927496512] Iter[41] Batch [500]#011Speed: 60145.90 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=41, batch=500 train rmse <loss>=0.84161361835\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=41, batch=500 train mse <loss>=0.708313482593\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=41, batch=500 train absolute_loss <loss>=0.632950429402\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:19 INFO 140371927496512] Iter[41] Batch [1000]#011Speed: 61568.95 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:19 INFO 140371927496512] #quality_metric: host=algo-1, epoch=41, batch=1000 train rmse <loss>=0.828276698872\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:19 INFO 140371927496512] #quality_metric: host=algo-1, epoch=41, batch=1000 train mse <loss>=0.686042289894\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:19 INFO 140371927496512] #quality_metric: host=algo-1, epoch=41, batch=1000 train absolute_loss <loss>=0.619387020847\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:25:24.000] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 84, \"duration\": 21268, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=41, train rmse <loss>=0.833497133033\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=41, train mse <loss>=0.694717470774\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=41, train absolute_loss <loss>=0.621222964595\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21270.128965377808, \"sum\": 21270.128965377808, \"min\": 21270.128965377808}}, \"EndTime\": 1597076724.000677, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076702.729032}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:24 INFO 140371927496512] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 54601, \"sum\": 54601.0, \"min\": 54601}, \"Total Records Seen\": {\"count\": 1, \"max\": 54578782, \"sum\": 54578782.0, \"min\": 54578782}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 43, \"sum\": 43.0, \"min\": 43}}, \"EndTime\": 1597076724.000938, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 41}, \"StartTime\": 1597076702.730511}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:24 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=61092.4785925 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=42, batch=0 train rmse <loss>=0.997953227627\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=42, batch=0 train mse <loss>=0.995910644531\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:24 INFO 140371927496512] #quality_metric: host=algo-1, epoch=42, batch=0 train absolute_loss <loss>=0.807402526855\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:32 INFO 140371927496512] Iter[42] Batch [500]#011Speed: 60007.78 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=42, batch=500 train rmse <loss>=0.836010146666\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=42, batch=500 train mse <loss>=0.698912965329\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=42, batch=500 train absolute_loss <loss>=0.627706215133\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:40 INFO 140371927496512] Iter[42] Batch [1000]#011Speed: 59802.91 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:40 INFO 140371927496512] #quality_metric: host=algo-1, epoch=42, batch=1000 train rmse <loss>=0.822791621012\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:40 INFO 140371927496512] #quality_metric: host=algo-1, epoch=42, batch=1000 train mse <loss>=0.676986051607\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:40 INFO 140371927496512] #quality_metric: host=algo-1, epoch=42, batch=1000 train absolute_loss <loss>=0.61427761478\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:25:45.624] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 86, \"duration\": 21620, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=42, train rmse <loss>=0.828051718314\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=42, train mse <loss>=0.685669648203\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=42, train absolute_loss <loss>=0.616139238657\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21622.49493598938, \"sum\": 21622.49493598938, \"min\": 21622.49493598938}}, \"EndTime\": 1597076745.624845, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076724.000765}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:45 INFO 140371927496512] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 55901, \"sum\": 55901.0, \"min\": 55901}, \"Total Records Seen\": {\"count\": 1, \"max\": 55878253, \"sum\": 55878253.0, \"min\": 55878253}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 44, \"sum\": 44.0, \"min\": 44}}, \"EndTime\": 1597076745.625101, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 42}, \"StartTime\": 1597076724.002318}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:45 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60096.9466959 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=43, batch=0 train rmse <loss>=0.992858348505\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=43, batch=0 train mse <loss>=0.985767700195\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:45 INFO 140371927496512] #quality_metric: host=algo-1, epoch=43, batch=0 train absolute_loss <loss>=0.802757446289\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:53 INFO 140371927496512] Iter[43] Batch [500]#011Speed: 60177.13 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:53 INFO 140371927496512] #quality_metric: host=algo-1, epoch=43, batch=500 train rmse <loss>=0.830457407551\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:53 INFO 140371927496512] #quality_metric: host=algo-1, epoch=43, batch=500 train mse <loss>=0.689659505757\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:25:53 INFO 140371927496512] #quality_metric: host=algo-1, epoch=43, batch=500 train absolute_loss <loss>=0.622517727667\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:02 INFO 140371927496512] Iter[43] Batch [1000]#011Speed: 60514.89 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=43, batch=1000 train rmse <loss>=0.817359777652\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=43, batch=1000 train mse <loss>=0.668077006124\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=43, batch=1000 train absolute_loss <loss>=0.609226880999\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:26:07.181] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 88, \"duration\": 21553, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=43, train rmse <loss>=0.822660386665\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=43, train mse <loss>=0.676770111788\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=43, train absolute_loss <loss>=0.611114871662\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21556.164979934692, \"sum\": 21556.164979934692, \"min\": 21556.164979934692}}, \"EndTime\": 1597076767.182635, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076745.62492}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:07 INFO 140371927496512] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 57201, \"sum\": 57201.0, \"min\": 57201}, \"Total Records Seen\": {\"count\": 1, \"max\": 57177724, \"sum\": 57177724.0, \"min\": 57177724}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}}, \"EndTime\": 1597076767.182906, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 43}, \"StartTime\": 1597076745.626434}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:07 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60281.8106457 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=44, batch=0 train rmse <loss>=0.987795242405\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=44, batch=0 train mse <loss>=0.975739440918\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:07 INFO 140371927496512] #quality_metric: host=algo-1, epoch=44, batch=0 train absolute_loss <loss>=0.798129821777\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:15 INFO 140371927496512] Iter[44] Batch [500]#011Speed: 60814.72 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=44, batch=500 train rmse <loss>=0.824954722581\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=44, batch=500 train mse <loss>=0.680550294309\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=44, batch=500 train absolute_loss <loss>=0.617384304694\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:23 INFO 140371927496512] Iter[44] Batch [1000]#011Speed: 61357.86 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:23 INFO 140371927496512] #quality_metric: host=algo-1, epoch=44, batch=1000 train rmse <loss>=0.811980283526\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:23 INFO 140371927496512] #quality_metric: host=algo-1, epoch=44, batch=1000 train mse <loss>=0.659311980835\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:23 INFO 140371927496512] #quality_metric: host=algo-1, epoch=44, batch=1000 train absolute_loss <loss>=0.604234030648\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:26:28.469] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 90, \"duration\": 21283, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=44, train rmse <loss>=0.817322190551\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=44, train mse <loss>=0.668015563167\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=44, train absolute_loss <loss>=0.606149109521\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21286.109924316406, \"sum\": 21286.109924316406, \"min\": 21286.109924316406}}, \"EndTime\": 1597076788.47037, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076767.182724}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:28 INFO 140371927496512] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 58501, \"sum\": 58501.0, \"min\": 58501}, \"Total Records Seen\": {\"count\": 1, \"max\": 58477195, \"sum\": 58477195.0, \"min\": 58477195}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 46, \"sum\": 46.0, \"min\": 46}}, \"EndTime\": 1597076788.470623, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 44}, \"StartTime\": 1597076767.184224}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:28 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=61046.6480238 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=45, batch=0 train rmse <loss>=0.982763561977\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=45, batch=0 train mse <loss>=0.96582421875\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:28 INFO 140371927496512] #quality_metric: host=algo-1, epoch=45, batch=0 train absolute_loss <loss>=0.793520324707\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:36 INFO 140371927496512] Iter[45] Batch [500]#011Speed: 60148.60 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:36 INFO 140371927496512] #quality_metric: host=algo-1, epoch=45, batch=500 train rmse <loss>=0.819501425585\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:36 INFO 140371927496512] #quality_metric: host=algo-1, epoch=45, batch=500 train mse <loss>=0.671582586536\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:36 INFO 140371927496512] #quality_metric: host=algo-1, epoch=45, batch=500 train absolute_loss <loss>=0.612305200573\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:44 INFO 140371927496512] Iter[45] Batch [1000]#011Speed: 61402.33 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:44 INFO 140371927496512] #quality_metric: host=algo-1, epoch=45, batch=1000 train rmse <loss>=0.806652289458\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:44 INFO 140371927496512] #quality_metric: host=algo-1, epoch=45, batch=1000 train mse <loss>=0.650687916088\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:44 INFO 140371927496512] #quality_metric: host=algo-1, epoch=45, batch=1000 train absolute_loss <loss>=0.599298091618\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:26:49.862] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 92, \"duration\": 21388, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:49 INFO 140371927496512] #quality_metric: host=algo-1, epoch=45, train rmse <loss>=0.812036229209\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:49 INFO 140371927496512] #quality_metric: host=algo-1, epoch=45, train mse <loss>=0.659402837548\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:49 INFO 140371927496512] #quality_metric: host=algo-1, epoch=45, train absolute_loss <loss>=0.601240707163\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21390.885829925537, \"sum\": 21390.885829925537, \"min\": 21390.885829925537}}, \"EndTime\": 1597076809.862894, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076788.470447}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:49 INFO 140371927496512] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 59801, \"sum\": 59801.0, \"min\": 59801}, \"Total Records Seen\": {\"count\": 1, \"max\": 59776666, \"sum\": 59776666.0, \"min\": 59776666}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 47, \"sum\": 47.0, \"min\": 47}}, \"EndTime\": 1597076809.863136, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 45}, \"StartTime\": 1597076788.471973}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:49 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60747.6939894 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:49 INFO 140371927496512] #quality_metric: host=algo-1, epoch=46, batch=0 train rmse <loss>=0.977762512704\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:49 INFO 140371927496512] #quality_metric: host=algo-1, epoch=46, batch=0 train mse <loss>=0.95601953125\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:49 INFO 140371927496512] #quality_metric: host=algo-1, epoch=46, batch=0 train absolute_loss <loss>=0.788944030762\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:58 INFO 140371927496512] Iter[46] Batch [500]#011Speed: 60688.68 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=46, batch=500 train rmse <loss>=0.814096916739\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=46, batch=500 train mse <loss>=0.662753789845\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:26:58 INFO 140371927496512] #quality_metric: host=algo-1, epoch=46, batch=500 train absolute_loss <loss>=0.607280308645\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:06 INFO 140371927496512] Iter[46] Batch [1000]#011Speed: 60696.78 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:06 INFO 140371927496512] #quality_metric: host=algo-1, epoch=46, batch=1000 train rmse <loss>=0.801375001511\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:06 INFO 140371927496512] #quality_metric: host=algo-1, epoch=46, batch=1000 train mse <loss>=0.642201893047\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:06 INFO 140371927496512] #quality_metric: host=algo-1, epoch=46, batch=1000 train absolute_loss <loss>=0.594417979146\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:27:11.269] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 94, \"duration\": 21403, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=46, train rmse <loss>=0.80680164251\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=46, train mse <loss>=0.650928890357\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=46, train absolute_loss <loss>=0.596388591802\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21405.784845352173, \"sum\": 21405.784845352173, \"min\": 21405.784845352173}}, \"EndTime\": 1597076831.270275, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076809.862988}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:11 INFO 140371927496512] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 61101, \"sum\": 61101.0, \"min\": 61101}, \"Total Records Seen\": {\"count\": 1, \"max\": 61076137, \"sum\": 61076137.0, \"min\": 61076137}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 48, \"sum\": 48.0, \"min\": 48}}, \"EndTime\": 1597076831.270496, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 46}, \"StartTime\": 1597076809.864461}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:11 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60705.480992 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=47, batch=0 train rmse <loss>=0.972792221922\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=47, batch=0 train mse <loss>=0.946324707031\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:11 INFO 140371927496512] #quality_metric: host=algo-1, epoch=47, batch=0 train absolute_loss <loss>=0.78438482666\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:19 INFO 140371927496512] Iter[47] Batch [500]#011Speed: 60464.91 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:19 INFO 140371927496512] #quality_metric: host=algo-1, epoch=47, batch=500 train rmse <loss>=0.808740562924\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:19 INFO 140371927496512] #quality_metric: host=algo-1, epoch=47, batch=500 train mse <loss>=0.654061298119\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:19 INFO 140371927496512] #quality_metric: host=algo-1, epoch=47, batch=500 train absolute_loss <loss>=0.602308940286\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:27 INFO 140371927496512] Iter[47] Batch [1000]#011Speed: 60706.42 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:27 INFO 140371927496512] #quality_metric: host=algo-1, epoch=47, batch=1000 train rmse <loss>=0.79614762382\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:27 INFO 140371927496512] #quality_metric: host=algo-1, epoch=47, batch=1000 train mse <loss>=0.633851038915\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:27 INFO 140371927496512] #quality_metric: host=algo-1, epoch=47, batch=1000 train absolute_loss <loss>=0.589593173824\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:27:32.674] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 96, \"duration\": 21401, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=47, train rmse <loss>=0.801617593189\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=47, train mse <loss>=0.64259076571\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=47, train absolute_loss <loss>=0.591592276963\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21403.68103981018, \"sum\": 21403.68103981018, \"min\": 21403.68103981018}}, \"EndTime\": 1597076852.675485, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076831.270356}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:32 INFO 140371927496512] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 62401, \"sum\": 62401.0, \"min\": 62401}, \"Total Records Seen\": {\"count\": 1, \"max\": 62375608, \"sum\": 62375608.0, \"min\": 62375608}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 49, \"sum\": 49.0, \"min\": 49}}, \"EndTime\": 1597076852.675698, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 47}, \"StartTime\": 1597076831.271773}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:32 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60711.511306 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=48, batch=0 train rmse <loss>=0.967851933781\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=48, batch=0 train mse <loss>=0.936737365723\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:32 INFO 140371927496512] #quality_metric: host=algo-1, epoch=48, batch=0 train absolute_loss <loss>=0.779841796875\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:41 INFO 140371927496512] Iter[48] Batch [500]#011Speed: 60103.05 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=48, batch=500 train rmse <loss>=0.803431790619\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=48, batch=500 train mse <loss>=0.645502642177\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:41 INFO 140371927496512] #quality_metric: host=algo-1, epoch=48, batch=500 train absolute_loss <loss>=0.597389193232\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:49 INFO 140371927496512] Iter[48] Batch [1000]#011Speed: 61188.01 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:49 INFO 140371927496512] #quality_metric: host=algo-1, epoch=48, batch=1000 train rmse <loss>=0.79096941733\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:49 INFO 140371927496512] #quality_metric: host=algo-1, epoch=48, batch=1000 train mse <loss>=0.625632619151\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:49 INFO 140371927496512] #quality_metric: host=algo-1, epoch=48, batch=1000 train absolute_loss <loss>=0.584822039075\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:27:54.068] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 98, \"duration\": 21389, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=48, train rmse <loss>=0.796483289732\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=48, train mse <loss>=0.634385630822\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=48, train absolute_loss <loss>=0.586850329895\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21391.75510406494, \"sum\": 21391.75510406494, \"min\": 21391.75510406494}}, \"EndTime\": 1597076874.068909, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076852.675562}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:54 INFO 140371927496512] #progress_metric: host=algo-1, completed 98 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 63701, \"sum\": 63701.0, \"min\": 63701}, \"Total Records Seen\": {\"count\": 1, \"max\": 63675079, \"sum\": 63675079.0, \"min\": 63675079}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 50, \"sum\": 50.0, \"min\": 50}}, \"EndTime\": 1597076874.069149, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 48}, \"StartTime\": 1597076852.677118}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:54 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=60745.2464826 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=49, batch=0 train rmse <loss>=0.96294150791\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=49, batch=0 train mse <loss>=0.927256347656\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:27:54 INFO 140371927496512] #quality_metric: host=algo-1, epoch=49, batch=0 train absolute_loss <loss>=0.775315673828\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:02 INFO 140371927496512] Iter[49] Batch [500]#011Speed: 59625.36 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=49, batch=500 train rmse <loss>=0.798170037494\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=49, batch=500 train mse <loss>=0.637075408753\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:02 INFO 140371927496512] #quality_metric: host=algo-1, epoch=49, batch=500 train absolute_loss <loss>=0.592520670817\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:10 INFO 140371927496512] Iter[49] Batch [1000]#011Speed: 60090.12 samples/sec\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:10 INFO 140371927496512] #quality_metric: host=algo-1, epoch=49, batch=1000 train rmse <loss>=0.785839664945\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:10 INFO 140371927496512] #quality_metric: host=algo-1, epoch=49, batch=1000 train mse <loss>=0.617543979001\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:10 INFO 140371927496512] #quality_metric: host=algo-1, epoch=49, batch=1000 train absolute_loss <loss>=0.580103582331\u001b[0m\n",
      "\u001b[34m[2020-08-10 16:28:15.738] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 100, \"duration\": 21666, \"num_examples\": 1300, \"num_bytes\": 87782072}\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=49, train rmse <loss>=0.791397960707\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=49, train mse <loss>=0.626310732211\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:15 INFO 140371927496512] #quality_metric: host=algo-1, epoch=49, train absolute_loss <loss>=0.582161570998\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:15 INFO 140371927496512] #quality_metric: host=algo-1, train rmse <loss>=0.791397960707\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:15 INFO 140371927496512] #quality_metric: host=algo-1, train mse <loss>=0.626310732211\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:15 INFO 140371927496512] #quality_metric: host=algo-1, train absolute_loss <loss>=0.582161570998\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 21669.414043426514, \"sum\": 21669.414043426514, \"min\": 21669.414043426514}}, \"EndTime\": 1597076895.739949, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076874.068986}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:15 INFO 140371927496512] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 65001, \"sum\": 65001.0, \"min\": 65001}, \"Total Records Seen\": {\"count\": 1, \"max\": 64974550, \"sum\": 64974550.0, \"min\": 64974550}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 51, \"sum\": 51.0, \"min\": 51}}, \"EndTime\": 1597076895.74022, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 49}, \"StartTime\": 1597076874.070501}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:15 INFO 140371927496512] #throughput_metric: host=algo-1, train throughput=59966.7797432 records/second\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:15 WARNING 140371927496512] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:15 INFO 140371927496512] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 121.43611907958984, \"sum\": 121.43611907958984, \"min\": 121.43611907958984}}, \"EndTime\": 1597076895.862046, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076895.740074}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:16 INFO 140371927496512] Saved checkpoint to \"/tmp/tmpMuoldu/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[08/10/2020 16:28:17 INFO 140371927496512] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 1075936.5861415863, \"sum\": 1075936.5861415863, \"min\": 1075936.5861415863}, \"setuptime\": {\"count\": 1, \"max\": 45.36795616149902, \"sum\": 45.36795616149902, \"min\": 45.36795616149902}}, \"EndTime\": 1597076897.436106, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597076895.862202}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 1148\n",
      "Billable seconds: 1148\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "import boto3 \n",
    "\n",
    "region = boto3.Session().region_name\n",
    "crole = 'AmazonSageMaker-ExecutionRole-20200603T105247'\n",
    "\n",
    "print(sagemaker.estimator.Estimator)\n",
    "fm = sagemaker.estimator.Estimator(image_uri=container,\n",
    "                                   role=crole, \n",
    "                                   instance_count=1, \n",
    "                                   instance_type='ml.c4.xlarge',\n",
    "                                   output_path=output_prefix,\n",
    "                                   sagemaker_session=sagemaker.Session())\n",
    "\n",
    "\n",
    "\n",
    "fm.set_hyperparameters(\n",
    "                      feature_dim=nFeatures,\n",
    "                      predictor_type='regressor',\n",
    "                      mini_batch_size=1000,\n",
    "                      num_factors=64,\n",
    "                      epochs=50)\n",
    "\n",
    "fm.fit({'train': train_data})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "fm_predictor = fm.deploy(instance_type='ml.c4.xlarge', initial_instance_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import BaseSerializer\n",
    "import json \n",
    "\n",
    "class FMSerializer(BaseSerializer): \n",
    "    CONTENT_TYPE='application/json'\n",
    "    def serialize(self, data):\n",
    "        js = {'instances': []}\n",
    "        for row in data:\n",
    "            js['instances'].append({'features': row.tolist()})\n",
    "        #print js\n",
    "        return json.dumps(js)\n",
    "\n",
    "fm_predictor.serializer = FMSerializer()\n",
    "fm_predictor.deserializer = sagemaker.deserializers.JSONDeserializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "ConnectionClosedError",
     "evalue": "Connection was closed before we received a valid response from endpoint URL: \"https://runtime.sagemaker.us-east-1.amazonaws.com/endpoints/factorization-machines-2020-08-10-22-13-03-380/invocations\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m             )\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/awsrequest.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         rval = super(AWSConnection, self)._send_request(\n\u001b[0;32m---> 92\u001b[0;31m             method, url, body, headers, *args, **kwargs)\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expect_header_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/awsrequest.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mmessage_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expect_header_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/awsrequest.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, str)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAWSConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36msendall\u001b[0;34m(self, data, flags)\u001b[0m\n\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mamount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1003\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/httpsession.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m             )\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    726\u001b[0m             retries = retries.increment(\n\u001b[0;32m--> 727\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m             )\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;31m# Disabled, indicate to re-raise the error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m             )\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/awsrequest.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         rval = super(AWSConnection, self)._send_request(\n\u001b[0;32m---> 92\u001b[0;31m             method, url, body, headers, *args, **kwargs)\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expect_header_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/awsrequest.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mmessage_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expect_header_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/awsrequest.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, str)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAWSConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36msendall\u001b[0;34m(self, data, flags)\u001b[0m\n\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mamount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1003\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection aborted.', BrokenPipeError(32, 'Broken pipe'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionClosedError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-474851efe6e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfm_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model, target_variant)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mrequest_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_request_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             http, parsed_response = self._make_request(\n\u001b[0;32m--> 622\u001b[0;31m                 operation_model, request_dict, request_context)\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         self.meta.events.emit(\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, operation_model, request_dict, request_context)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_endpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             self.meta.events.emit(\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36mmake_request\u001b[0;34m(self, operation_model, request_dict)\u001b[0m\n\u001b[1;32m    100\u001b[0m         logger.debug(\"Making request for %s with params: %s\",\n\u001b[1;32m    101\u001b[0m                      operation_model, request_dict)\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, request_dict, operation_model)\u001b[0m\n\u001b[1;32m    135\u001b[0m             request, operation_model, context)\n\u001b[1;32m    136\u001b[0m         while self._needs_retry(attempts, operation_model, request_dict,\n\u001b[0;32m--> 137\u001b[0;31m                                 success_response, exception):\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mattempts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;31m# If there is a stream associated with the request, we need\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36m_needs_retry\u001b[0;34m(self, attempts, operation_model, request_dict, response, caught_exception)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0moperation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattempts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattempts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             caught_exception=caught_exception, request_dict=request_dict)\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0mhandler_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_non_none_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandler_response\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/hooks.py\u001b[0m in \u001b[0;36memit\u001b[0;34m(self, event_name, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0maliased_event_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_event_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_emitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maliased_event_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0memit_until_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/hooks.py\u001b[0m in \u001b[0;36memit\u001b[0;34m(self, event_name, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m                  \u001b[0mhandlers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \"\"\"\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_emit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0memit_until_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/hooks.py\u001b[0m in \u001b[0;36m_emit\u001b[0;34m(self, event_name, kwargs, stop_on_response)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers_to_call\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Event %s: calling handler %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0mresponses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop_on_response\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/retryhandler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, attempts, response, caught_exception, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \"\"\"\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattempts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaught_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattempts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattempts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Retry needed, action of: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/retryhandler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, attempt_number, response, caught_exception)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattempt_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaught_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         should_retry = self._should_retry(attempt_number, response,\n\u001b[0;32m--> 251\u001b[0;31m                                           caught_exception)\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshould_retry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mattempt_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_attempts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/retryhandler.py\u001b[0m in \u001b[0;36m_should_retry\u001b[0;34m(self, attempt_number, response, caught_exception)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# If we've exceeded the max attempts we just let the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;31m# propogate if one has occurred.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattempt_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaught_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/retryhandler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, attempt_number, response, caught_exception)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchecker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             checker_response = checker(attempt_number, response,\n\u001b[0;32m--> 317\u001b[0;31m                                        caught_exception)\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchecker_response\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mchecker_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/retryhandler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, attempt_number, response, caught_exception)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcaught_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             return self._check_caught_exception(\n\u001b[0;32m--> 223\u001b[0;31m                 attempt_number, caught_exception)\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Both response and caught_exception are None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/retryhandler.py\u001b[0m in \u001b[0;36m_check_caught_exception\u001b[0;34m(self, attempt_number, caught_exception)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the MaxAttemptsDecorator is not interested in retrying the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;31m# then this exception just propogates out past the retry code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mcaught_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36m_do_get_response\u001b[0;34m(self, request, operation_model)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mhttp_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_non_none_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhttp_response\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                 \u001b[0mhttp_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPClientError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36m_send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/recommender/venv/lib/python3.7/site-packages/botocore/httpsession.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m                 \u001b[0mendpoint_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             )\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionClosedError\u001b[0m: Connection was closed before we received a valid response from endpoint URL: \"https://runtime.sagemaker.us-east-1.amazonaws.com/endpoints/factorization-machines-2020-08-10-22-13-03-380/invocations\"."
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "import numpy \n",
    "\n",
    "X_test_arr = X_test[:100].toarray(order='C')\n",
    "print(X_test_arr)\n",
    "\n",
    "result = fm_predictor.predict(X_test_arr) \n",
    "y_pred = [] \n",
    "for p in result['predictions']: \n",
    "    y_pred.append(p['score'])\n",
    "\n",
    "rmse = numpy.sqrt(numpy.mean((y_pred-Y_test[:100])**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>uid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>imdb url</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>...</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>age_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46289</th>\n",
       "      <td>244</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>880602451</td>\n",
       "      <td>Smilla's Sense of Snow (1997)</td>\n",
       "      <td>14-Mar-1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Smilla%27s%20...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46290</th>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>879372325</td>\n",
       "      <td>Stargate (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Stargate%20(1...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46291</th>\n",
       "      <td>286</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>876522316</td>\n",
       "      <td>English Patient, The (1996)</td>\n",
       "      <td>15-Nov-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?English%20Pat...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46292</th>\n",
       "      <td>303</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>879485184</td>\n",
       "      <td>Ulee's Gold (1997)</td>\n",
       "      <td>01-Jan-1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Ulee%27s+Gold...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46293</th>\n",
       "      <td>291</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>874833936</td>\n",
       "      <td>Absolute Power (1997)</td>\n",
       "      <td>14-Feb-1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Absolute%20Po...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46374</th>\n",
       "      <td>916</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>880843838</td>\n",
       "      <td>Lost in Space (1998)</td>\n",
       "      <td>27-Mar-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/Title?Lost+in+Space+(1998)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46375</th>\n",
       "      <td>910</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>881421019</td>\n",
       "      <td>Nil By Mouth (1997)</td>\n",
       "      <td>06-Feb-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/Title?Nil+By+Mouth+(1997)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46376</th>\n",
       "      <td>923</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>880387707</td>\n",
       "      <td>Raise the Red Lantern (1991)</td>\n",
       "      <td>01-Jan-1991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Da%20Hong%20D...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46377</th>\n",
       "      <td>917</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>882911567</td>\n",
       "      <td>Mercury Rising (1998)</td>\n",
       "      <td>27-Mar-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/Title?Mercury+Rising+(1998)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46378</th>\n",
       "      <td>936</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>886833148</td>\n",
       "      <td>Brassed Off (1996)</td>\n",
       "      <td>13-Jun-1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Brassed%20Off...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       iid  uid  rating  timestamp                          title  \\\n",
       "46289  244    3       5  880602451  Smilla's Sense of Snow (1997)   \n",
       "46290   62    3       3  879372325                Stargate (1994)   \n",
       "46291  286    3       2  876522316    English Patient, The (1996)   \n",
       "46292  303    3       3  879485184             Ulee's Gold (1997)   \n",
       "46293  291    3       3  874833936          Absolute Power (1997)   \n",
       "...    ...  ...     ...        ...                            ...   \n",
       "46374  916    3       3  880843838           Lost in Space (1998)   \n",
       "46375  910    3       2  881421019            Nil By Mouth (1997)   \n",
       "46376  923    3       4  880387707   Raise the Red Lantern (1991)   \n",
       "46377  917    3       1  882911567          Mercury Rising (1998)   \n",
       "46378  936    3       4  886833148             Brassed Off (1996)   \n",
       "\n",
       "      release_date  video_release_date  \\\n",
       "46289  14-Mar-1997                 NaN   \n",
       "46290  01-Jan-1994                 NaN   \n",
       "46291  15-Nov-1996                 NaN   \n",
       "46292  01-Jan-1997                 NaN   \n",
       "46293  14-Feb-1997                 NaN   \n",
       "...            ...                 ...   \n",
       "46374  27-Mar-1998                 NaN   \n",
       "46375  06-Feb-1998                 NaN   \n",
       "46376  01-Jan-1991                 NaN   \n",
       "46377  27-Mar-1998                 NaN   \n",
       "46378  13-Jun-1997                 NaN   \n",
       "\n",
       "                                                imdb url  unknown  Action  \\\n",
       "46289  http://us.imdb.com/M/title-exact?Smilla%27s%20...        0       1   \n",
       "46290  http://us.imdb.com/M/title-exact?Stargate%20(1...        0       1   \n",
       "46291  http://us.imdb.com/M/title-exact?English%20Pat...        0       0   \n",
       "46292  http://us.imdb.com/M/title-exact?Ulee%27s+Gold...        0       0   \n",
       "46293  http://us.imdb.com/M/title-exact?Absolute%20Po...        0       0   \n",
       "...                                                  ...      ...     ...   \n",
       "46374      http://us.imdb.com/Title?Lost+in+Space+(1998)        0       1   \n",
       "46375       http://us.imdb.com/Title?Nil+By+Mouth+(1997)        0       0   \n",
       "46376  http://us.imdb.com/M/title-exact?Da%20Hong%20D...        0       0   \n",
       "46377     http://us.imdb.com/Title?Mercury+Rising+(1998)        0       1   \n",
       "46378  http://us.imdb.com/M/title-exact?Brassed%20Off...        0       0   \n",
       "\n",
       "       ...  Romance  Sci-Fi  Thriller  War  Western  age  gender  occupation  \\\n",
       "46289  ...        0       0         1    0        0   23       M      writer   \n",
       "46290  ...        0       1         0    0        0   23       M      writer   \n",
       "46291  ...        1       0         0    1        0   23       M      writer   \n",
       "46292  ...        0       0         0    0        0   23       M      writer   \n",
       "46293  ...        0       0         1    0        0   23       M      writer   \n",
       "...    ...      ...     ...       ...  ...      ...  ...     ...         ...   \n",
       "46374  ...        0       1         1    0        0   23       M      writer   \n",
       "46375  ...        0       0         0    0        0   23       M      writer   \n",
       "46376  ...        0       0         0    0        0   23       M      writer   \n",
       "46377  ...        0       0         1    0        0   23       M      writer   \n",
       "46378  ...        1       0         0    0        0   23       M      writer   \n",
       "\n",
       "       zipcode  age_segment  \n",
       "46289    32067            2  \n",
       "46290    32067            2  \n",
       "46291    32067            2  \n",
       "46292    32067            2  \n",
       "46293    32067            2  \n",
       "...        ...          ...  \n",
       "46374    32067            2  \n",
       "46375    32067            2  \n",
       "46376    32067            2  \n",
       "46377    32067            2  \n",
       "46378    32067            2  \n",
       "\n",
       "[90 rows x 32 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
