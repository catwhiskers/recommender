{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-18 13:58:50--  https://tinyurl.com/yy5roqgd\n",
      "Resolving tinyurl.com (tinyurl.com)... 104.20.139.65, 104.20.138.65, 172.67.1.225, ...\n",
      "Connecting to tinyurl.com (tinyurl.com)|104.20.139.65|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://recommendation-demo-yianc.s3.us-east-1.amazonaws.com/amz-review-apparel.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIATLORAEYMTX7JY4ER%2F20200816%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200816T040109Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=d56c2cd480721982600725e9dc7d4ccfacdbd46a1efce519d0288952ad114d37 [following]\n",
      "--2020-08-18 13:58:50--  https://recommendation-demo-yianc.s3.us-east-1.amazonaws.com/amz-review-apparel.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIATLORAEYMTX7JY4ER%2F20200816%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200816T040109Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=d56c2cd480721982600725e9dc7d4ccfacdbd46a1efce519d0288952ad114d37\n",
      "Resolving recommendation-demo-yianc.s3.us-east-1.amazonaws.com (recommendation-demo-yianc.s3.us-east-1.amazonaws.com)... 52.216.29.80\n",
      "Connecting to recommendation-demo-yianc.s3.us-east-1.amazonaws.com (recommendation-demo-yianc.s3.us-east-1.amazonaws.com)|52.216.29.80|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 621522774 (593M) [text/csv]\n",
      "Saving to: ‘amz-review-apparel.csv’\n",
      "\n",
      "amz-review-apparel. 100%[===================>] 592.73M  45.8MB/s    in 13s     \n",
      "\n",
      "2020-08-18 13:59:04 (46.0 MB/s) - ‘amz-review-apparel.csv’ saved [621522774/621522774]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O amz-review-apparel.csv https://tinyurl.com/yy5roqgd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>cnt</th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id.1</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28563435</td>\n",
       "      <td>13</td>\n",
       "      <td>US</td>\n",
       "      <td>28563435</td>\n",
       "      <td>R2M9YYZ4DLZRMN</td>\n",
       "      <td>B003OQTQ0W</td>\n",
       "      <td>97286984</td>\n",
       "      <td>Carhartt Men's Two-Tone Trifold Wallet</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Outstanding Wallet</td>\n",
       "      <td>I have owned a lot of wallets over the years a...</td>\n",
       "      <td>2013-07-11</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28563435</td>\n",
       "      <td>13</td>\n",
       "      <td>US</td>\n",
       "      <td>28563435</td>\n",
       "      <td>R2DIHSYWNP3FPJ</td>\n",
       "      <td>B0093O17U6</td>\n",
       "      <td>765210786</td>\n",
       "      <td>IH Camouflage Trucker Cap in Mossy Oak Break-U...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Great cap</td>\n",
       "      <td>This is a very nice hat,but i have got another...</td>\n",
       "      <td>2013-05-11</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28563435</td>\n",
       "      <td>13</td>\n",
       "      <td>US</td>\n",
       "      <td>28563435</td>\n",
       "      <td>R36XY86RBEESP6</td>\n",
       "      <td>B0051I6MYY</td>\n",
       "      <td>268391293</td>\n",
       "      <td>IH 5 Panel Trucker Cap with Liquid Metal Logo</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Great hat!!!</td>\n",
       "      <td>This is a great hat and is very well made!! I ...</td>\n",
       "      <td>2013-04-13</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28563435</td>\n",
       "      <td>13</td>\n",
       "      <td>US</td>\n",
       "      <td>28563435</td>\n",
       "      <td>R2X9GLV67VACAN</td>\n",
       "      <td>B005F29FKO</td>\n",
       "      <td>506334102</td>\n",
       "      <td>Carhartt Men's Relaxed Straight Denim Five Poc...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Great pants</td>\n",
       "      <td>I have always been a Wrangler man most of my l...</td>\n",
       "      <td>2012-12-08</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28563435</td>\n",
       "      <td>13</td>\n",
       "      <td>US</td>\n",
       "      <td>28563435</td>\n",
       "      <td>RS4RG84BX2KK5</td>\n",
       "      <td>B004QF0THY</td>\n",
       "      <td>206343191</td>\n",
       "      <td>Dickies Men's 2 Pack Wool Blend Boot Crew Socks</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Very Great socks!!</td>\n",
       "      <td>Wool is the only socks i wear and the only thi...</td>\n",
       "      <td>2012-12-08</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  cnt marketplace  customer_id.1       review_id  product_id  \\\n",
       "0     28563435   13          US       28563435  R2M9YYZ4DLZRMN  B003OQTQ0W   \n",
       "1     28563435   13          US       28563435  R2DIHSYWNP3FPJ  B0093O17U6   \n",
       "2     28563435   13          US       28563435  R36XY86RBEESP6  B0051I6MYY   \n",
       "3     28563435   13          US       28563435  R2X9GLV67VACAN  B005F29FKO   \n",
       "4     28563435   13          US       28563435   RS4RG84BX2KK5  B004QF0THY   \n",
       "\n",
       "   product_parent                                      product_title  \\\n",
       "0        97286984             Carhartt Men's Two-Tone Trifold Wallet   \n",
       "1       765210786  IH Camouflage Trucker Cap in Mossy Oak Break-U...   \n",
       "2       268391293      IH 5 Panel Trucker Cap with Liquid Metal Logo   \n",
       "3       506334102  Carhartt Men's Relaxed Straight Denim Five Poc...   \n",
       "4       206343191    Dickies Men's 2 Pack Wool Blend Boot Crew Socks   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            5              0            0    N                 Y   \n",
       "1            5              0            0    N                 Y   \n",
       "2            5              1            1    N                 Y   \n",
       "3            5              0            0    N                 Y   \n",
       "4            5              0            0    N                 Y   \n",
       "\n",
       "      review_headline                                        review_body  \\\n",
       "0  Outstanding Wallet  I have owned a lot of wallets over the years a...   \n",
       "1           Great cap  This is a very nice hat,but i have got another...   \n",
       "2        Great hat!!!  This is a great hat and is very well made!! I ...   \n",
       "3         Great pants  I have always been a Wrangler man most of my l...   \n",
       "4  Very Great socks!!  Wool is the only socks i wear and the only thi...   \n",
       "\n",
       "  review_date  year  \n",
       "0  2013-07-11  2013  \n",
       "1  2013-05-11  2013  \n",
       "2  2013-04-13  2013  \n",
       "3  2012-12-08  2012  \n",
       "4  2012-12-08  2012  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "user_item = './amz-review-apparel.csv'\n",
    "\n",
    "user_item_df = pd.read_csv(user_item)\n",
    "user_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from preprocessing.amz_datareader import AMZComprehendDataReader\n",
    "from preprocessing.factorization_machine_transformer import  FactorizationMachineTransformer\n",
    "\n",
    "\n",
    "user_item = './amz-review-apparel.csv'\n",
    "comprehend_item_data = './item-topics.csv'\n",
    "reader = AMZComprehendDataReader()\n",
    "user_item  = reader.read_user_item_rating(user_item)\n",
    "users = {}\n",
    "items = reader.read_item_data(comprehend_item_data)\n",
    "train_user_item = user_item[:int(len(user_item)*0.8)]\n",
    "test_user_item = user_item[int(len(user_item)*0.8):]\n",
    "transformer = FactorizationMachineTransformer(users, items, train_user_item)\n",
    "X_train, Y_train, _, _, nFeatures = transformer.get_feature_vectors(users, items, train_user_item)\n",
    "X_test, Y_test, X_test_cold, Y_test_cold, testnFeature = transformer.get_feature_vectors(users, items, test_user_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1299471, 980914)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.BytesIO object at 0x7f50c6641620>\n",
      "Output: s3://recommendation-demo-yianc/sagemaker/fm-amz-comprehend/output\n"
     ]
    }
   ],
   "source": [
    "bucket = 'recommendation-demo-yianc'\n",
    "prefix = 'sagemaker/fm-amz-comprehend'\n",
    "train_key      = 'train.protobuf'\n",
    "train_prefix   = '{}/{}'.format(prefix, 'train')\n",
    "test_key       = 'test.protobuf'\n",
    "test_prefix    = '{}/{}/'.format(prefix, 'test')\n",
    "output_prefix  = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "\n",
    "def writeDatasetToProtobuf(X, Y, bucket, prefix, key):\n",
    "    import io,boto3\n",
    "    import sagemaker.amazon.common as smac\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_spmatrix_to_sparse_tensor(buf, X, Y)\n",
    "    buf.seek(0)\n",
    "    print(buf)\n",
    "    obj = '{}/{}'.format(prefix, key)\n",
    "    boto3.resource('s3').Bucket(bucket).Object(obj).upload_fileobj(buf)\n",
    "    return 's3://{}/{}'.format(bucket,obj)\n",
    " \n",
    "    \n",
    "train_data = writeDatasetToProtobuf(X_train, Y_train, bucket, train_prefix, train_key)    \n",
    "  \n",
    "print('Output: {}'.format(output_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://recommendation-demo-yianc/sagemaker/fm-amz-comprehend/train/train.protobuf'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'382416733822.dkr.ecr.us-east-1.amazonaws.com/factorization-machines:latest'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3 \n",
    "import sagemaker \n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "container = get_image_uri(region, 'factorization-machines', 'latest')\n",
    "container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sagemaker.estimator.Estimator'>\n",
      "2020-08-18 14:17:36 Starting - Starting the training job...\n",
      "2020-08-18 14:17:38 Starting - Launching requested ML instances......\n",
      "2020-08-18 14:18:54 Starting - Preparing the instances for training......\n",
      "2020-08-18 14:19:44 Downloading - Downloading input data...\n",
      "2020-08-18 14:20:26 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python2.7/site-packages/pandas/util/nosetester.py:13: DeprecationWarning: Importing from numpy.testing.nosetester is deprecated, import from numpy.testing instead.\n",
      "  from numpy.testing import nosetester\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:20:50 INFO 140531487123264] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': 1, u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:20:50 INFO 140531487123264] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'epochs': u'50', u'feature_dim': u'980914', u'mini_batch_size': u'1000', u'predictor_type': u'regressor', u'num_factors': u'64'}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:20:50 INFO 140531487123264] Final configuration: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': u'50', u'feature_dim': u'980914', u'num_factors': u'64', u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'predictor_type': u'regressor', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:20:50 WARNING 140531487123264] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:20:50 INFO 140531487123264] Using default worker.\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:20:50.135] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 7, \"num_examples\": 1, \"num_bytes\": 72008}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:20:50 INFO 140531487123264] nvidia-smi took: 0.0251729488373 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:20:50 INFO 140531487123264] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:20:50 INFO 140531487123264] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:20:50 INFO 140531487123264] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 36.50999069213867, \"sum\": 36.50999069213867, \"min\": 36.50999069213867}}, \"EndTime\": 1597760450.170634, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760450.127262}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1597760450.170833, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760450.170786}\n",
      "\u001b[0m\n",
      "\u001b[34m[14:20:50] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.203343.0/AL2012/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[14:20:50] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.203343.0/AL2012/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\n",
      "2020-08-18 14:20:46 Training - Training image download completed. Training in progress.\u001b[34m[08/18/2020 14:20:52 INFO 140531487123264] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=4.36159173031\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:20:52 INFO 140531487123264] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=19.0234824219\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:20:52 INFO 140531487123264] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=4.17920166016\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:01 INFO 140531487123264] Iter[0] Batch [500]#011Speed: 54988.27 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:01 INFO 140531487123264] #quality_metric: host=algo-1, epoch=0, batch=500 train rmse <loss>=1.36091986259\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:01 INFO 140531487123264] #quality_metric: host=algo-1, epoch=0, batch=500 train mse <loss>=1.85210287238\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:01 INFO 140531487123264] #quality_metric: host=algo-1, epoch=0, batch=500 train absolute_loss <loss>=1.05390770961\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:10 INFO 140531487123264] Iter[0] Batch [1000]#011Speed: 58402.84 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:10 INFO 140531487123264] #quality_metric: host=algo-1, epoch=0, batch=1000 train rmse <loss>=1.24933856536\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:10 INFO 140531487123264] #quality_metric: host=algo-1, epoch=0, batch=1000 train mse <loss>=1.5608468509\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:10 INFO 140531487123264] #quality_metric: host=algo-1, epoch=0, batch=1000 train absolute_loss <loss>=0.979373343636\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:21:15.586] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 23610, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=1.22868465955\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=0, train mse <loss>=1.50966599262\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=0.966435474994\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 50, \"sum\": 50.0, \"min\": 50}, \"update.time\": {\"count\": 1, \"max\": 25416.3339138031, \"sum\": 25416.3339138031, \"min\": 25416.3339138031}}, \"EndTime\": 1597760475.587395, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760450.170711}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:15 INFO 140531487123264] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1301, \"sum\": 1301.0, \"min\": 1301}, \"Total Records Seen\": {\"count\": 1, \"max\": 1300471, \"sum\": 1300471.0, \"min\": 1300471}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1597760475.587645, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 0}, \"StartTime\": 1597760450.171025}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:15 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=51126.5622512 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=1.25338311712\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=1.57096923828\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=1.00422393799\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/18/2020 14:21:24 INFO 140531487123264] Iter[1] Batch [500]#011Speed: 56868.29 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:24 INFO 140531487123264] #quality_metric: host=algo-1, epoch=1, batch=500 train rmse <loss>=1.13846791917\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:24 INFO 140531487123264] #quality_metric: host=algo-1, epoch=1, batch=500 train mse <loss>=1.29610920298\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:24 INFO 140531487123264] #quality_metric: host=algo-1, epoch=1, batch=500 train absolute_loss <loss>=0.911970374193\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:32 INFO 140531487123264] Iter[1] Batch [1000]#011Speed: 58216.82 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:32 INFO 140531487123264] #quality_metric: host=algo-1, epoch=1, batch=1000 train rmse <loss>=1.12109262743\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:32 INFO 140531487123264] #quality_metric: host=algo-1, epoch=1, batch=1000 train mse <loss>=1.25684867927\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:32 INFO 140531487123264] #quality_metric: host=algo-1, epoch=1, batch=1000 train absolute_loss <loss>=0.895861876771\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:21:38.073] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 22482, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:38 INFO 140531487123264] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=1.12300254283\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:38 INFO 140531487123264] #quality_metric: host=algo-1, epoch=1, train mse <loss>=1.26113471121\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:38 INFO 140531487123264] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=0.895692052894\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22484.740018844604, \"sum\": 22484.740018844604, \"min\": 22484.740018844604}}, \"EndTime\": 1597760498.073721, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760475.587477}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:38 INFO 140531487123264] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2601, \"sum\": 2601.0, \"min\": 2601}, \"Total Records Seen\": {\"count\": 1, \"max\": 2599942, \"sum\": 2599942.0, \"min\": 2599942}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1597760498.073972, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 1}, \"StartTime\": 1597760475.588952}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:38 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57792.4094031 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:38 INFO 140531487123264] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=1.23760317594\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:38 INFO 140531487123264] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=1.53166162109\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:38 INFO 140531487123264] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=0.993148193359\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:46 INFO 140531487123264] Iter[2] Batch [500]#011Speed: 57794.74 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:46 INFO 140531487123264] #quality_metric: host=algo-1, epoch=2, batch=500 train rmse <loss>=1.10130448343\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:46 INFO 140531487123264] #quality_metric: host=algo-1, epoch=2, batch=500 train mse <loss>=1.21287156522\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:46 INFO 140531487123264] #quality_metric: host=algo-1, epoch=2, batch=500 train absolute_loss <loss>=0.874900839556\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:55 INFO 140531487123264] Iter[2] Batch [1000]#011Speed: 58428.78 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=2, batch=1000 train rmse <loss>=1.08155771683\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=2, batch=1000 train mse <loss>=1.16976709484\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:21:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=2, batch=1000 train absolute_loss <loss>=0.855608571543\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:22:00.428] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 22351, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=1.08215428663\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=2, train mse <loss>=1.17105790006\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=0.854265243577\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22353.690147399902, \"sum\": 22353.690147399902, \"min\": 22353.690147399902}}, \"EndTime\": 1597760520.429099, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760498.073803}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:00 INFO 140531487123264] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3901, \"sum\": 3901.0, \"min\": 3901}, \"Total Records Seen\": {\"count\": 1, \"max\": 3899413, \"sum\": 3899413.0, \"min\": 3899413}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1597760520.429351, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 2}, \"StartTime\": 1597760498.075376}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:00 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=58131.1942515 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=1.20233506941\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=3, batch=0 train mse <loss>=1.44560961914\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=3, batch=0 train absolute_loss <loss>=0.959992614746\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:09 INFO 140531487123264] Iter[3] Batch [500]#011Speed: 57245.50 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:09 INFO 140531487123264] #quality_metric: host=algo-1, epoch=3, batch=500 train rmse <loss>=1.05056679389\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:09 INFO 140531487123264] #quality_metric: host=algo-1, epoch=3, batch=500 train mse <loss>=1.10369058843\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:09 INFO 140531487123264] #quality_metric: host=algo-1, epoch=3, batch=500 train absolute_loss <loss>=0.824962566932\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:17 INFO 140531487123264] Iter[3] Batch [1000]#011Speed: 58668.85 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=3, batch=1000 train rmse <loss>=1.03042452072\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=3, batch=1000 train mse <loss>=1.0617746929\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=3, batch=1000 train absolute_loss <loss>=0.804671469949\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:22:22.864] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 22431, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:22 INFO 140531487123264] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=1.03046410466\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:22 INFO 140531487123264] #quality_metric: host=algo-1, epoch=3, train mse <loss>=1.06185627099\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:22 INFO 140531487123264] #quality_metric: host=algo-1, epoch=3, train absolute_loss <loss>=0.802826985286\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22434.154987335205, \"sum\": 22434.154987335205, \"min\": 22434.154987335205}}, \"EndTime\": 1597760542.865057, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760520.429179}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:22 INFO 140531487123264] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5201, \"sum\": 5201.0, \"min\": 5201}, \"Total Records Seen\": {\"count\": 1, \"max\": 5198884, \"sum\": 5198884.0, \"min\": 5198884}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1597760542.865266, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 3}, \"StartTime\": 1597760520.430875}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:22 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57922.8786773 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:22 INFO 140531487123264] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=1.15762529062\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:22 INFO 140531487123264] #quality_metric: host=algo-1, epoch=4, batch=0 train mse <loss>=1.34009631348\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:22 INFO 140531487123264] #quality_metric: host=algo-1, epoch=4, batch=0 train absolute_loss <loss>=0.911582214355\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/18/2020 14:22:31 INFO 140531487123264] Iter[4] Batch [500]#011Speed: 57774.87 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=4, batch=500 train rmse <loss>=0.99635072624\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=4, batch=500 train mse <loss>=0.992714769679\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=4, batch=500 train absolute_loss <loss>=0.771760415205\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:40 INFO 140531487123264] Iter[4] Batch [1000]#011Speed: 58157.19 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=4, batch=1000 train rmse <loss>=0.976759436936\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=4, batch=1000 train mse <loss>=0.954058997643\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=4, batch=1000 train absolute_loss <loss>=0.752025181606\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:22:45.287] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 22419, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=0.976501780757\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=4, train mse <loss>=0.953555727821\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=4, train absolute_loss <loss>=0.750019183021\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22421.26703262329, \"sum\": 22421.26703262329, \"min\": 22421.26703262329}}, \"EndTime\": 1597760565.288055, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760542.865132}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:45 INFO 140531487123264] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6501, \"sum\": 6501.0, \"min\": 6501}, \"Total Records Seen\": {\"count\": 1, \"max\": 6498355, \"sum\": 6498355.0, \"min\": 6498355}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1597760565.288303, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 4}, \"StartTime\": 1597760542.866756}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:45 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57956.0131605 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=5, batch=0 train rmse <loss>=1.10907351757\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=5, batch=0 train mse <loss>=1.23004406738\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=5, batch=0 train absolute_loss <loss>=0.863965881348\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:54 INFO 140531487123264] Iter[5] Batch [500]#011Speed: 57269.16 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:54 INFO 140531487123264] #quality_metric: host=algo-1, epoch=5, batch=500 train rmse <loss>=0.944635551239\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:54 INFO 140531487123264] #quality_metric: host=algo-1, epoch=5, batch=500 train mse <loss>=0.892336324665\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:22:54 INFO 140531487123264] #quality_metric: host=algo-1, epoch=5, batch=500 train absolute_loss <loss>=0.720544451259\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:02 INFO 140531487123264] Iter[5] Batch [1000]#011Speed: 58278.89 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:02 INFO 140531487123264] #quality_metric: host=algo-1, epoch=5, batch=1000 train rmse <loss>=0.925891638331\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:02 INFO 140531487123264] #quality_metric: host=algo-1, epoch=5, batch=1000 train mse <loss>=0.857275325931\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:02 INFO 140531487123264] #quality_metric: host=algo-1, epoch=5, batch=1000 train absolute_loss <loss>=0.702373279431\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:23:07.737] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 22445, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:07 INFO 140531487123264] #quality_metric: host=algo-1, epoch=5, train rmse <loss>=0.925367759437\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:07 INFO 140531487123264] #quality_metric: host=algo-1, epoch=5, train mse <loss>=0.856305490206\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:07 INFO 140531487123264] #quality_metric: host=algo-1, epoch=5, train absolute_loss <loss>=0.700400212355\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22448.010206222534, \"sum\": 22448.010206222534, \"min\": 22448.010206222534}}, \"EndTime\": 1597760587.737921, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760565.288138}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:07 INFO 140531487123264] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7801, \"sum\": 7801.0, \"min\": 7801}, \"Total Records Seen\": {\"count\": 1, \"max\": 7797826, \"sum\": 7797826.0, \"min\": 7797826}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1597760587.738185, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 5}, \"StartTime\": 1597760565.289876}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:07 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57886.9409239 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:07 INFO 140531487123264] #quality_metric: host=algo-1, epoch=6, batch=0 train rmse <loss>=1.05786777459\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:07 INFO 140531487123264] #quality_metric: host=algo-1, epoch=6, batch=0 train mse <loss>=1.11908422852\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:07 INFO 140531487123264] #quality_metric: host=algo-1, epoch=6, batch=0 train absolute_loss <loss>=0.810703125\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:16 INFO 140531487123264] Iter[6] Batch [500]#011Speed: 57397.69 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:16 INFO 140531487123264] #quality_metric: host=algo-1, epoch=6, batch=500 train rmse <loss>=0.897712118489\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:16 INFO 140531487123264] #quality_metric: host=algo-1, epoch=6, batch=500 train mse <loss>=0.805887047682\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:16 INFO 140531487123264] #quality_metric: host=algo-1, epoch=6, batch=500 train absolute_loss <loss>=0.67436203143\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:25 INFO 140531487123264] Iter[6] Batch [1000]#011Speed: 58012.11 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:25 INFO 140531487123264] #quality_metric: host=algo-1, epoch=6, batch=1000 train rmse <loss>=0.87989270545\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:25 INFO 140531487123264] #quality_metric: host=algo-1, epoch=6, batch=1000 train mse <loss>=0.774211173104\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:25 INFO 140531487123264] #quality_metric: host=algo-1, epoch=6, batch=1000 train absolute_loss <loss>=0.658027417102\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:23:30.235] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 22493, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:30 INFO 140531487123264] #quality_metric: host=algo-1, epoch=6, train rmse <loss>=0.879077297458\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:30 INFO 140531487123264] #quality_metric: host=algo-1, epoch=6, train mse <loss>=0.772776894907\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:30 INFO 140531487123264] #quality_metric: host=algo-1, epoch=6, train absolute_loss <loss>=0.656159784828\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22496.355056762695, \"sum\": 22496.355056762695, \"min\": 22496.355056762695}}, \"EndTime\": 1597760610.236113, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760587.738005}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:30 INFO 140531487123264] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 9101, \"sum\": 9101.0, \"min\": 9101}, \"Total Records Seen\": {\"count\": 1, \"max\": 9097297, \"sum\": 9097297.0, \"min\": 9097297}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1597760610.236373, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 6}, \"StartTime\": 1597760587.739726}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:30 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57762.5639439 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:30 INFO 140531487123264] #quality_metric: host=algo-1, epoch=7, batch=0 train rmse <loss>=1.00554207677\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:30 INFO 140531487123264] #quality_metric: host=algo-1, epoch=7, batch=0 train mse <loss>=1.01111486816\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:30 INFO 140531487123264] #quality_metric: host=algo-1, epoch=7, batch=0 train absolute_loss <loss>=0.753374633789\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/18/2020 14:23:38 INFO 140531487123264] Iter[7] Batch [500]#011Speed: 57338.58 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:38 INFO 140531487123264] #quality_metric: host=algo-1, epoch=7, batch=500 train rmse <loss>=0.85557821334\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:38 INFO 140531487123264] #quality_metric: host=algo-1, epoch=7, batch=500 train mse <loss>=0.732014079142\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:38 INFO 140531487123264] #quality_metric: host=algo-1, epoch=7, batch=500 train absolute_loss <loss>=0.633937567979\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:47 INFO 140531487123264] Iter[7] Batch [1000]#011Speed: 58356.23 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:47 INFO 140531487123264] #quality_metric: host=algo-1, epoch=7, batch=1000 train rmse <loss>=0.838735581232\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:47 INFO 140531487123264] #quality_metric: host=algo-1, epoch=7, batch=1000 train mse <loss>=0.703477375225\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:47 INFO 140531487123264] #quality_metric: host=algo-1, epoch=7, batch=1000 train absolute_loss <loss>=0.619269229001\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:23:52.662] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 22423, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:52 INFO 140531487123264] #quality_metric: host=algo-1, epoch=7, train rmse <loss>=0.837616184687\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:52 INFO 140531487123264] #quality_metric: host=algo-1, epoch=7, train mse <loss>=0.70160087285\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:52 INFO 140531487123264] #quality_metric: host=algo-1, epoch=7, train absolute_loss <loss>=0.617433731549\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22425.312995910645, \"sum\": 22425.312995910645, \"min\": 22425.312995910645}}, \"EndTime\": 1597760632.663352, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760610.236197}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:52 INFO 140531487123264] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 10401, \"sum\": 10401.0, \"min\": 10401}, \"Total Records Seen\": {\"count\": 1, \"max\": 10396768, \"sum\": 10396768.0, \"min\": 10396768}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1597760632.663552, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 7}, \"StartTime\": 1597760610.23801}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:52 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57945.7559418 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:52 INFO 140531487123264] #quality_metric: host=algo-1, epoch=8, batch=0 train rmse <loss>=0.953652645957\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:52 INFO 140531487123264] #quality_metric: host=algo-1, epoch=8, batch=0 train mse <loss>=0.909453369141\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:23:52 INFO 140531487123264] #quality_metric: host=algo-1, epoch=8, batch=0 train absolute_loss <loss>=0.695675292969\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:01 INFO 140531487123264] Iter[8] Batch [500]#011Speed: 56771.07 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:01 INFO 140531487123264] #quality_metric: host=algo-1, epoch=8, batch=500 train rmse <loss>=0.817270727251\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:01 INFO 140531487123264] #quality_metric: host=algo-1, epoch=8, batch=500 train mse <loss>=0.667931441621\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:01 INFO 140531487123264] #quality_metric: host=algo-1, epoch=8, batch=500 train absolute_loss <loss>=0.598060728458\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:10 INFO 140531487123264] Iter[8] Batch [1000]#011Speed: 58181.26 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:10 INFO 140531487123264] #quality_metric: host=algo-1, epoch=8, batch=1000 train rmse <loss>=0.801530507299\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:10 INFO 140531487123264] #quality_metric: host=algo-1, epoch=8, batch=1000 train mse <loss>=0.642451154132\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:10 INFO 140531487123264] #quality_metric: host=algo-1, epoch=8, batch=1000 train absolute_loss <loss>=0.584905914185\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:24:15.276] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 22610, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=8, train rmse <loss>=0.800141329225\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=8, train mse <loss>=0.640226146733\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=8, train absolute_loss <loss>=0.583038875615\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22612.34402656555, \"sum\": 22612.34402656555, \"min\": 22612.34402656555}}, \"EndTime\": 1597760655.277476, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760632.663424}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:15 INFO 140531487123264] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 11701, \"sum\": 11701.0, \"min\": 11701}, \"Total Records Seen\": {\"count\": 1, \"max\": 11696239, \"sum\": 11696239.0, \"min\": 11696239}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1597760655.277678, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 8}, \"StartTime\": 1597760632.665102}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:15 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57466.461944 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=9, batch=0 train rmse <loss>=0.903365864561\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=9, batch=0 train mse <loss>=0.816069885254\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=9, batch=0 train absolute_loss <loss>=0.640696472168\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:24 INFO 140531487123264] Iter[9] Batch [500]#011Speed: 57391.42 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:24 INFO 140531487123264] #quality_metric: host=algo-1, epoch=9, batch=500 train rmse <loss>=0.781878451113\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:24 INFO 140531487123264] #quality_metric: host=algo-1, epoch=9, batch=500 train mse <loss>=0.611333912315\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:24 INFO 140531487123264] #quality_metric: host=algo-1, epoch=9, batch=500 train absolute_loss <loss>=0.565499409993\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:32 INFO 140531487123264] Iter[9] Batch [1000]#011Speed: 57680.06 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:32 INFO 140531487123264] #quality_metric: host=algo-1, epoch=9, batch=1000 train rmse <loss>=0.76743373246\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:32 INFO 140531487123264] #quality_metric: host=algo-1, epoch=9, batch=1000 train mse <loss>=0.588954533717\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:32 INFO 140531487123264] #quality_metric: host=algo-1, epoch=9, batch=1000 train absolute_loss <loss>=0.553682974984\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:24:37.898] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 22617, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:37 INFO 140531487123264] #quality_metric: host=algo-1, epoch=9, train rmse <loss>=0.765853655576\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:37 INFO 140531487123264] #quality_metric: host=algo-1, epoch=9, train mse <loss>=0.586531821759\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:37 INFO 140531487123264] #quality_metric: host=algo-1, epoch=9, train absolute_loss <loss>=0.551772311707\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22619.330883026123, \"sum\": 22619.330883026123, \"min\": 22619.330883026123}}, \"EndTime\": 1597760677.898636, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760655.277546}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:37 INFO 140531487123264] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 13001, \"sum\": 13001.0, \"min\": 13001}, \"Total Records Seen\": {\"count\": 1, \"max\": 12995710, \"sum\": 12995710.0, \"min\": 12995710}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1597760677.898839, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 9}, \"StartTime\": 1597760655.279278}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:37 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57448.7181297 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:37 INFO 140531487123264] #quality_metric: host=algo-1, epoch=10, batch=0 train rmse <loss>=0.855332216559\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:37 INFO 140531487123264] #quality_metric: host=algo-1, epoch=10, batch=0 train mse <loss>=0.731593200684\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:37 INFO 140531487123264] #quality_metric: host=algo-1, epoch=10, batch=0 train absolute_loss <loss>=0.587729370117\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/18/2020 14:24:46 INFO 140531487123264] Iter[10] Batch [500]#011Speed: 56707.56 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:46 INFO 140531487123264] #quality_metric: host=algo-1, epoch=10, batch=500 train rmse <loss>=0.74892645315\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:46 INFO 140531487123264] #quality_metric: host=algo-1, epoch=10, batch=500 train mse <loss>=0.560890832227\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:46 INFO 140531487123264] #quality_metric: host=algo-1, epoch=10, batch=500 train absolute_loss <loss>=0.535336865941\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:55 INFO 140531487123264] Iter[10] Batch [1000]#011Speed: 57720.63 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=10, batch=1000 train rmse <loss>=0.735972838286\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=10, batch=1000 train mse <loss>=0.541656018694\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:24:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=10, batch=1000 train absolute_loss <loss>=0.52522116345\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:25:00.480] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 22579, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=10, train rmse <loss>=0.734300236819\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=10, train mse <loss>=0.539196837792\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=10, train absolute_loss <loss>=0.523421768001\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22581.099033355713, \"sum\": 22581.099033355713, \"min\": 22581.099033355713}}, \"EndTime\": 1597760700.48159, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760677.898708}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:00 INFO 140531487123264] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 14301, \"sum\": 14301.0, \"min\": 14301}, \"Total Records Seen\": {\"count\": 1, \"max\": 14295181, \"sum\": 14295181.0, \"min\": 14295181}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}}, \"EndTime\": 1597760700.481892, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 10}, \"StartTime\": 1597760677.900458}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:00 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57545.6471829 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=11, batch=0 train rmse <loss>=0.809752264874\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=11, batch=0 train mse <loss>=0.655698730469\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=11, batch=0 train absolute_loss <loss>=0.538445556641\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:09 INFO 140531487123264] Iter[11] Batch [500]#011Speed: 56448.98 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:09 INFO 140531487123264] #quality_metric: host=algo-1, epoch=11, batch=500 train rmse <loss>=0.718257146597\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:09 INFO 140531487123264] #quality_metric: host=algo-1, epoch=11, batch=500 train mse <loss>=0.515893328638\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:09 INFO 140531487123264] #quality_metric: host=algo-1, epoch=11, batch=500 train absolute_loss <loss>=0.507783413885\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:18 INFO 140531487123264] Iter[11] Batch [1000]#011Speed: 57907.64 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:18 INFO 140531487123264] #quality_metric: host=algo-1, epoch=11, batch=1000 train rmse <loss>=0.706945992901\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:18 INFO 140531487123264] #quality_metric: host=algo-1, epoch=11, batch=1000 train mse <loss>=0.499772636879\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:18 INFO 140531487123264] #quality_metric: host=algo-1, epoch=11, batch=1000 train absolute_loss <loss>=0.499371224235\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:25:23.137] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 22651, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:23 INFO 140531487123264] #quality_metric: host=algo-1, epoch=11, train rmse <loss>=0.705278134288\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:23 INFO 140531487123264] #quality_metric: host=algo-1, epoch=11, train mse <loss>=0.497417246704\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:23 INFO 140531487123264] #quality_metric: host=algo-1, epoch=11, train absolute_loss <loss>=0.497687801349\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22654.25705909729, \"sum\": 22654.25705909729, \"min\": 22654.25705909729}}, \"EndTime\": 1597760723.137759, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760700.481705}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:23 INFO 140531487123264] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 15601, \"sum\": 15601.0, \"min\": 15601}, \"Total Records Seen\": {\"count\": 1, \"max\": 15594652, \"sum\": 15594652.0, \"min\": 15594652}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1597760723.138003, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 11}, \"StartTime\": 1597760700.483467}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:23 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57359.9917271 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:23 INFO 140531487123264] #quality_metric: host=algo-1, epoch=12, batch=0 train rmse <loss>=0.766724258692\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:23 INFO 140531487123264] #quality_metric: host=algo-1, epoch=12, batch=0 train mse <loss>=0.587866088867\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:23 INFO 140531487123264] #quality_metric: host=algo-1, epoch=12, batch=0 train absolute_loss <loss>=0.496043884277\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:31 INFO 140531487123264] Iter[12] Batch [500]#011Speed: 57349.36 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=12, batch=500 train rmse <loss>=0.689831412367\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=12, batch=500 train mse <loss>=0.475867377489\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=12, batch=500 train absolute_loss <loss>=0.482651039352\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:40 INFO 140531487123264] Iter[12] Batch [1000]#011Speed: 58545.98 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=12, batch=1000 train rmse <loss>=0.680265310681\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=12, batch=1000 train mse <loss>=0.462760892916\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=12, batch=1000 train absolute_loss <loss>=0.475782129796\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:25:45.574] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 22433, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=12, train rmse <loss>=0.678698477577\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=12, train mse <loss>=0.460631623465\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=12, train absolute_loss <loss>=0.474222525071\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22435.784101486206, \"sum\": 22435.784101486206, \"min\": 22435.784101486206}}, \"EndTime\": 1597760745.575525, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760723.137836}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:45 INFO 140531487123264] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 16901, \"sum\": 16901.0, \"min\": 16901}, \"Total Records Seen\": {\"count\": 1, \"max\": 16894123, \"sum\": 16894123.0, \"min\": 16894123}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 14, \"sum\": 14.0, \"min\": 14}}, \"EndTime\": 1597760745.575771, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 12}, \"StartTime\": 1597760723.139708}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:45 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57918.5263457 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=13, batch=0 train rmse <loss>=0.726816697804\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=13, batch=0 train mse <loss>=0.528262512207\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=13, batch=0 train absolute_loss <loss>=0.455559356689\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/18/2020 14:25:54 INFO 140531487123264] Iter[13] Batch [500]#011Speed: 57654.73 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:54 INFO 140531487123264] #quality_metric: host=algo-1, epoch=13, batch=500 train rmse <loss>=0.663699940561\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:54 INFO 140531487123264] #quality_metric: host=algo-1, epoch=13, batch=500 train mse <loss>=0.440497611101\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:25:54 INFO 140531487123264] #quality_metric: host=algo-1, epoch=13, batch=500 train absolute_loss <loss>=0.459889055873\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:03 INFO 140531487123264] Iter[13] Batch [1000]#011Speed: 56879.35 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:03 INFO 140531487123264] #quality_metric: host=algo-1, epoch=13, batch=1000 train rmse <loss>=0.655974011888\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:03 INFO 140531487123264] #quality_metric: host=algo-1, epoch=13, batch=1000 train mse <loss>=0.430301904272\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:03 INFO 140531487123264] #quality_metric: host=algo-1, epoch=13, batch=1000 train absolute_loss <loss>=0.454792732902\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:26:08.374] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 22795, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:08 INFO 140531487123264] #quality_metric: host=algo-1, epoch=13, train rmse <loss>=0.654623591004\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:08 INFO 140531487123264] #quality_metric: host=algo-1, epoch=13, train mse <loss>=0.428532045898\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:08 INFO 140531487123264] #quality_metric: host=algo-1, epoch=13, train absolute_loss <loss>=0.453632773179\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22797.89900779724, \"sum\": 22797.89900779724, \"min\": 22797.89900779724}}, \"EndTime\": 1597760768.375371, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760745.575605}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:08 INFO 140531487123264] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 18201, \"sum\": 18201.0, \"min\": 18201}, \"Total Records Seen\": {\"count\": 1, \"max\": 18193594, \"sum\": 18193594.0, \"min\": 18193594}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1597760768.375583, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 13}, \"StartTime\": 1597760745.577442}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:08 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=56998.7296246 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:08 INFO 140531487123264] #quality_metric: host=algo-1, epoch=14, batch=0 train rmse <loss>=0.691900622161\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:08 INFO 140531487123264] #quality_metric: host=algo-1, epoch=14, batch=0 train mse <loss>=0.478726470947\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:08 INFO 140531487123264] #quality_metric: host=algo-1, epoch=14, batch=0 train absolute_loss <loss>=0.419500915527\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:17 INFO 140531487123264] Iter[14] Batch [500]#011Speed: 55495.14 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=14, batch=500 train rmse <loss>=0.640395327867\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=14, batch=500 train mse <loss>=0.410106175954\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=14, batch=500 train absolute_loss <loss>=0.4407971044\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:26 INFO 140531487123264] Iter[14] Batch [1000]#011Speed: 56710.18 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=14, batch=1000 train rmse <loss>=0.634790057597\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=14, batch=1000 train mse <loss>=0.402958417224\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=14, batch=1000 train absolute_loss <loss>=0.437997181377\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:26:31.340] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 22961, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=14, train rmse <loss>=0.633494244982\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=14, train mse <loss>=0.401314958426\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=14, train absolute_loss <loss>=0.437195970553\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22963.797092437744, \"sum\": 22963.797092437744, \"min\": 22963.797092437744}}, \"EndTime\": 1597760791.341125, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760768.375449}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:31 INFO 140531487123264] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 19501, \"sum\": 19501.0, \"min\": 19501}, \"Total Records Seen\": {\"count\": 1, \"max\": 19493065, \"sum\": 19493065.0, \"min\": 19493065}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 16, \"sum\": 16.0, \"min\": 16}}, \"EndTime\": 1597760791.341318, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 14}, \"StartTime\": 1597760768.377299}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:31 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=56586.9604551 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=15, batch=0 train rmse <loss>=0.653719591415\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=15, batch=0 train mse <loss>=0.427349304199\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=15, batch=0 train absolute_loss <loss>=0.395680999756\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:39 INFO 140531487123264] Iter[15] Batch [500]#011Speed: 58032.39 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:39 INFO 140531487123264] #quality_metric: host=algo-1, epoch=15, batch=500 train rmse <loss>=0.621276595156\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:39 INFO 140531487123264] #quality_metric: host=algo-1, epoch=15, batch=500 train mse <loss>=0.385984607689\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:39 INFO 140531487123264] #quality_metric: host=algo-1, epoch=15, batch=500 train absolute_loss <loss>=0.42745972368\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:48 INFO 140531487123264] Iter[15] Batch [1000]#011Speed: 58101.51 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:48 INFO 140531487123264] #quality_metric: host=algo-1, epoch=15, batch=1000 train rmse <loss>=0.61725623373\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:48 INFO 140531487123264] #quality_metric: host=algo-1, epoch=15, batch=1000 train mse <loss>=0.381005258078\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:48 INFO 140531487123264] #quality_metric: host=algo-1, epoch=15, batch=1000 train absolute_loss <loss>=0.426046632993\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:26:53.682] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 22339, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:53 INFO 140531487123264] #quality_metric: host=algo-1, epoch=15, train rmse <loss>=0.615392816785\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:53 INFO 140531487123264] #quality_metric: host=algo-1, epoch=15, train mse <loss>=0.378708318951\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:53 INFO 140531487123264] #quality_metric: host=algo-1, epoch=15, train absolute_loss <loss>=0.424453334515\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22341.383934020996, \"sum\": 22341.383934020996, \"min\": 22341.383934020996}}, \"EndTime\": 1597760813.682967, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760791.341189}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:53 INFO 140531487123264] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 20801, \"sum\": 20801.0, \"min\": 20801}, \"Total Records Seen\": {\"count\": 1, \"max\": 20792536, \"sum\": 20792536.0, \"min\": 20792536}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 17, \"sum\": 17.0, \"min\": 17}}, \"EndTime\": 1597760813.68316, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 15}, \"StartTime\": 1597760791.341555}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:53 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=58163.4608543 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:53 INFO 140531487123264] #quality_metric: host=algo-1, epoch=16, batch=0 train rmse <loss>=0.620386709391\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:53 INFO 140531487123264] #quality_metric: host=algo-1, epoch=16, batch=0 train mse <loss>=0.384879669189\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:26:53 INFO 140531487123264] #quality_metric: host=algo-1, epoch=16, batch=0 train absolute_loss <loss>=0.386719787598\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/18/2020 14:27:02 INFO 140531487123264] Iter[16] Batch [500]#011Speed: 57911.08 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:02 INFO 140531487123264] #quality_metric: host=algo-1, epoch=16, batch=500 train rmse <loss>=0.603603202756\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:02 INFO 140531487123264] #quality_metric: host=algo-1, epoch=16, batch=500 train mse <loss>=0.364336826378\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:02 INFO 140531487123264] #quality_metric: host=algo-1, epoch=16, batch=500 train absolute_loss <loss>=0.415063321964\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:10 INFO 140531487123264] Iter[16] Batch [1000]#011Speed: 58266.13 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:10 INFO 140531487123264] #quality_metric: host=algo-1, epoch=16, batch=1000 train rmse <loss>=0.600120120745\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:10 INFO 140531487123264] #quality_metric: host=algo-1, epoch=16, batch=1000 train mse <loss>=0.360144159323\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:10 INFO 140531487123264] #quality_metric: host=algo-1, epoch=16, batch=1000 train absolute_loss <loss>=0.413438746129\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:27:15.970] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 34, \"duration\": 22283, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=16, train rmse <loss>=0.597978744622\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=16, train mse <loss>=0.357578579019\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=16, train absolute_loss <loss>=0.411339160062\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22285.985946655273, \"sum\": 22285.985946655273, \"min\": 22285.985946655273}}, \"EndTime\": 1597760835.970793, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760813.683031}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:15 INFO 140531487123264] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 22101, \"sum\": 22101.0, \"min\": 22101}, \"Total Records Seen\": {\"count\": 1, \"max\": 22092007, \"sum\": 22092007.0, \"min\": 22092007}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 18, \"sum\": 18.0, \"min\": 18}}, \"EndTime\": 1597760835.970992, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 16}, \"StartTime\": 1597760813.68478}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:15 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=58308.0295372 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:16 INFO 140531487123264] #quality_metric: host=algo-1, epoch=17, batch=0 train rmse <loss>=0.590430508032\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:16 INFO 140531487123264] #quality_metric: host=algo-1, epoch=17, batch=0 train mse <loss>=0.348608184814\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:16 INFO 140531487123264] #quality_metric: host=algo-1, epoch=17, batch=0 train absolute_loss <loss>=0.367519714355\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:24 INFO 140531487123264] Iter[17] Batch [500]#011Speed: 57605.11 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:24 INFO 140531487123264] #quality_metric: host=algo-1, epoch=17, batch=500 train rmse <loss>=0.586478115745\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:24 INFO 140531487123264] #quality_metric: host=algo-1, epoch=17, batch=500 train mse <loss>=0.343956580248\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:24 INFO 140531487123264] #quality_metric: host=algo-1, epoch=17, batch=500 train absolute_loss <loss>=0.401876470631\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:33 INFO 140531487123264] Iter[17] Batch [1000]#011Speed: 58093.20 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:33 INFO 140531487123264] #quality_metric: host=algo-1, epoch=17, batch=1000 train rmse <loss>=0.583773958985\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:33 INFO 140531487123264] #quality_metric: host=algo-1, epoch=17, batch=1000 train mse <loss>=0.34079203519\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:33 INFO 140531487123264] #quality_metric: host=algo-1, epoch=17, batch=1000 train absolute_loss <loss>=0.400577712144\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:27:38.407] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 36, \"duration\": 22432, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:38 INFO 140531487123264] #quality_metric: host=algo-1, epoch=17, train rmse <loss>=0.581590919836\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:38 INFO 140531487123264] #quality_metric: host=algo-1, epoch=17, train mse <loss>=0.338247998035\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:38 INFO 140531487123264] #quality_metric: host=algo-1, epoch=17, train absolute_loss <loss>=0.398350368159\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22434.782028198242, \"sum\": 22434.782028198242, \"min\": 22434.782028198242}}, \"EndTime\": 1597760858.407518, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760835.970863}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:38 INFO 140531487123264] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 23401, \"sum\": 23401.0, \"min\": 23401}, \"Total Records Seen\": {\"count\": 1, \"max\": 23391478, \"sum\": 23391478.0, \"min\": 23391478}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 19, \"sum\": 19.0, \"min\": 19}}, \"EndTime\": 1597760858.407712, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 17}, \"StartTime\": 1597760835.972709}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:38 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57921.3065675 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:38 INFO 140531487123264] #quality_metric: host=algo-1, epoch=18, batch=0 train rmse <loss>=0.560802750833\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:38 INFO 140531487123264] #quality_metric: host=algo-1, epoch=18, batch=0 train mse <loss>=0.314499725342\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:38 INFO 140531487123264] #quality_metric: host=algo-1, epoch=18, batch=0 train absolute_loss <loss>=0.345953918457\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:47 INFO 140531487123264] Iter[18] Batch [500]#011Speed: 57707.95 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:47 INFO 140531487123264] #quality_metric: host=algo-1, epoch=18, batch=500 train rmse <loss>=0.570745882518\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:47 INFO 140531487123264] #quality_metric: host=algo-1, epoch=18, batch=500 train mse <loss>=0.325750862411\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:47 INFO 140531487123264] #quality_metric: host=algo-1, epoch=18, batch=500 train absolute_loss <loss>=0.389547480722\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:55 INFO 140531487123264] Iter[18] Batch [1000]#011Speed: 58829.65 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=18, batch=1000 train rmse <loss>=0.568873790049\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=18, batch=1000 train mse <loss>=0.323617389004\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:27:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=18, batch=1000 train absolute_loss <loss>=0.388802596817\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:28:00.651] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 38, \"duration\": 22240, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=18, train rmse <loss>=0.566721597674\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=18, train mse <loss>=0.32117336927\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=18, train absolute_loss <loss>=0.386540102516\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22242.904901504517, \"sum\": 22242.904901504517, \"min\": 22242.904901504517}}, \"EndTime\": 1597760880.652326, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760858.407582}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:00 INFO 140531487123264] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 24701, \"sum\": 24701.0, \"min\": 24701}, \"Total Records Seen\": {\"count\": 1, \"max\": 24690949, \"sum\": 24690949.0, \"min\": 24690949}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}}, \"EndTime\": 1597760880.652576, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 18}, \"StartTime\": 1597760858.409388}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:00 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=58420.7616991 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=19, batch=0 train rmse <loss>=0.53320987862\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=19, batch=0 train mse <loss>=0.284312774658\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=19, batch=0 train absolute_loss <loss>=0.325911224365\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:09 INFO 140531487123264] Iter[19] Batch [500]#011Speed: 57415.19 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:09 INFO 140531487123264] #quality_metric: host=algo-1, epoch=19, batch=500 train rmse <loss>=0.556950168932\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:09 INFO 140531487123264] #quality_metric: host=algo-1, epoch=19, batch=500 train mse <loss>=0.310193490674\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:09 INFO 140531487123264] #quality_metric: host=algo-1, epoch=19, batch=500 train absolute_loss <loss>=0.378967503531\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/18/2020 14:28:17 INFO 140531487123264] Iter[19] Batch [1000]#011Speed: 58122.11 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=19, batch=1000 train rmse <loss>=0.555717094609\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=19, batch=1000 train mse <loss>=0.308821489241\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=19, batch=1000 train absolute_loss <loss>=0.37866819155\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:28:23.113] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 40, \"duration\": 22457, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:23 INFO 140531487123264] #quality_metric: host=algo-1, epoch=19, train rmse <loss>=0.553581362514\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:23 INFO 140531487123264] #quality_metric: host=algo-1, epoch=19, train mse <loss>=0.306452324923\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:23 INFO 140531487123264] #quality_metric: host=algo-1, epoch=19, train absolute_loss <loss>=0.376353434941\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22459.63215827942, \"sum\": 22459.63215827942, \"min\": 22459.63215827942}}, \"EndTime\": 1597760903.11398, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760880.652404}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:23 INFO 140531487123264] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 26001, \"sum\": 26001.0, \"min\": 26001}, \"Total Records Seen\": {\"count\": 1, \"max\": 25990420, \"sum\": 25990420.0, \"min\": 25990420}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 21, \"sum\": 21.0, \"min\": 21}}, \"EndTime\": 1597760903.114221, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 19}, \"StartTime\": 1597760880.65432}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:23 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57857.0874414 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:23 INFO 140531487123264] #quality_metric: host=algo-1, epoch=20, batch=0 train rmse <loss>=0.508669979166\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:23 INFO 140531487123264] #quality_metric: host=algo-1, epoch=20, batch=0 train mse <loss>=0.258745147705\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:23 INFO 140531487123264] #quality_metric: host=algo-1, epoch=20, batch=0 train absolute_loss <loss>=0.309948120117\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:31 INFO 140531487123264] Iter[20] Batch [500]#011Speed: 57891.54 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=20, batch=500 train rmse <loss>=0.545338320581\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=20, batch=500 train mse <loss>=0.297393883894\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=20, batch=500 train absolute_loss <loss>=0.370566218881\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:40 INFO 140531487123264] Iter[20] Batch [1000]#011Speed: 58388.49 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=20, batch=1000 train rmse <loss>=0.544320261703\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=20, batch=1000 train mse <loss>=0.296284547301\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=20, batch=1000 train absolute_loss <loss>=0.370241330965\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:28:45.468] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 42, \"duration\": 22350, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=20, train rmse <loss>=0.542124094277\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=20, train mse <loss>=0.293898533595\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=20, train absolute_loss <loss>=0.367806837064\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22353.05905342102, \"sum\": 22353.05905342102, \"min\": 22353.05905342102}}, \"EndTime\": 1597760925.468952, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760903.114049}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:45 INFO 140531487123264] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 27301, \"sum\": 27301.0, \"min\": 27301}, \"Total Records Seen\": {\"count\": 1, \"max\": 27289891, \"sum\": 27289891.0, \"min\": 27289891}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}}, \"EndTime\": 1597760925.469153, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 20}, \"StartTime\": 1597760903.115864}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:45 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=58133.0586526 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=21, batch=0 train rmse <loss>=0.486202449876\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=21, batch=0 train mse <loss>=0.236392822266\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=21, batch=0 train absolute_loss <loss>=0.297222412109\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:54 INFO 140531487123264] Iter[21] Batch [500]#011Speed: 56546.58 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:54 INFO 140531487123264] #quality_metric: host=algo-1, epoch=21, batch=500 train rmse <loss>=0.535598827998\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:54 INFO 140531487123264] #quality_metric: host=algo-1, epoch=21, batch=500 train mse <loss>=0.286866104552\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:28:54 INFO 140531487123264] #quality_metric: host=algo-1, epoch=21, batch=500 train absolute_loss <loss>=0.363744091407\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:02 INFO 140531487123264] Iter[21] Batch [1000]#011Speed: 57809.00 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:02 INFO 140531487123264] #quality_metric: host=algo-1, epoch=21, batch=1000 train rmse <loss>=0.534350660178\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:02 INFO 140531487123264] #quality_metric: host=algo-1, epoch=21, batch=1000 train mse <loss>=0.285530628033\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:02 INFO 140531487123264] #quality_metric: host=algo-1, epoch=21, batch=1000 train absolute_loss <loss>=0.362985392049\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:29:08.085] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 44, \"duration\": 22613, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:08 INFO 140531487123264] #quality_metric: host=algo-1, epoch=21, train rmse <loss>=0.532004697173\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:08 INFO 140531487123264] #quality_metric: host=algo-1, epoch=21, train mse <loss>=0.283028997814\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:08 INFO 140531487123264] #quality_metric: host=algo-1, epoch=21, train absolute_loss <loss>=0.360371382517\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22615.077018737793, \"sum\": 22615.077018737793, \"min\": 22615.077018737793}}, \"EndTime\": 1597760948.08597, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760925.469022}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:08 INFO 140531487123264] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 28601, \"sum\": 28601.0, \"min\": 28601}, \"Total Records Seen\": {\"count\": 1, \"max\": 28589362, \"sum\": 28589362.0, \"min\": 28589362}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 23, \"sum\": 23.0, \"min\": 23}}, \"EndTime\": 1597760948.08623, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 21}, \"StartTime\": 1597760925.47086}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:08 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57459.3773989 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:08 INFO 140531487123264] #quality_metric: host=algo-1, epoch=22, batch=0 train rmse <loss>=0.464962219016\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:08 INFO 140531487123264] #quality_metric: host=algo-1, epoch=22, batch=0 train mse <loss>=0.216189865112\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:08 INFO 140531487123264] #quality_metric: host=algo-1, epoch=22, batch=0 train absolute_loss <loss>=0.284284912109\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/18/2020 14:29:16 INFO 140531487123264] Iter[22] Batch [500]#011Speed: 57747.27 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:16 INFO 140531487123264] #quality_metric: host=algo-1, epoch=22, batch=500 train rmse <loss>=0.5270944565\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:16 INFO 140531487123264] #quality_metric: host=algo-1, epoch=22, batch=500 train mse <loss>=0.277828566073\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:16 INFO 140531487123264] #quality_metric: host=algo-1, epoch=22, batch=500 train absolute_loss <loss>=0.357626141546\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:25 INFO 140531487123264] Iter[22] Batch [1000]#011Speed: 58466.53 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:25 INFO 140531487123264] #quality_metric: host=algo-1, epoch=22, batch=1000 train rmse <loss>=0.525406550936\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:25 INFO 140531487123264] #quality_metric: host=algo-1, epoch=22, batch=1000 train mse <loss>=0.276052043766\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:25 INFO 140531487123264] #quality_metric: host=algo-1, epoch=22, batch=1000 train absolute_loss <loss>=0.356274181278\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:29:30.447] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 46, \"duration\": 22359, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:30 INFO 140531487123264] #quality_metric: host=algo-1, epoch=22, train rmse <loss>=0.522859433656\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:30 INFO 140531487123264] #quality_metric: host=algo-1, epoch=22, train mse <loss>=0.273381987363\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:30 INFO 140531487123264] #quality_metric: host=algo-1, epoch=22, train absolute_loss <loss>=0.353412875425\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22361.909866333008, \"sum\": 22361.909866333008, \"min\": 22361.909866333008}}, \"EndTime\": 1597760970.448423, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760948.086034}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:30 INFO 140531487123264] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 29901, \"sum\": 29901.0, \"min\": 29901}, \"Total Records Seen\": {\"count\": 1, \"max\": 29888833, \"sum\": 29888833.0, \"min\": 29888833}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 24, \"sum\": 24.0, \"min\": 24}}, \"EndTime\": 1597760970.448622, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 22}, \"StartTime\": 1597760948.086482}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:30 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=58109.9979683 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:30 INFO 140531487123264] #quality_metric: host=algo-1, epoch=23, batch=0 train rmse <loss>=0.445236938491\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:30 INFO 140531487123264] #quality_metric: host=algo-1, epoch=23, batch=0 train mse <loss>=0.198235931396\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:30 INFO 140531487123264] #quality_metric: host=algo-1, epoch=23, batch=0 train absolute_loss <loss>=0.271418640137\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:39 INFO 140531487123264] Iter[23] Batch [500]#011Speed: 56360.10 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:39 INFO 140531487123264] #quality_metric: host=algo-1, epoch=23, batch=500 train rmse <loss>=0.519528400677\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:39 INFO 140531487123264] #quality_metric: host=algo-1, epoch=23, batch=500 train mse <loss>=0.26990975911\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:39 INFO 140531487123264] #quality_metric: host=algo-1, epoch=23, batch=500 train absolute_loss <loss>=0.351775656055\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:47 INFO 140531487123264] Iter[23] Batch [1000]#011Speed: 58287.38 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:47 INFO 140531487123264] #quality_metric: host=algo-1, epoch=23, batch=1000 train rmse <loss>=0.517351435922\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:47 INFO 140531487123264] #quality_metric: host=algo-1, epoch=23, batch=1000 train mse <loss>=0.267652508251\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:47 INFO 140531487123264] #quality_metric: host=algo-1, epoch=23, batch=1000 train absolute_loss <loss>=0.349946729098\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:29:53.154] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 48, \"duration\": 22703, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:53 INFO 140531487123264] #quality_metric: host=algo-1, epoch=23, train rmse <loss>=0.514598305521\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:53 INFO 140531487123264] #quality_metric: host=algo-1, epoch=23, train mse <loss>=0.264811416045\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:53 INFO 140531487123264] #quality_metric: host=algo-1, epoch=23, train absolute_loss <loss>=0.346849787609\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22705.130100250244, \"sum\": 22705.130100250244, \"min\": 22705.130100250244}}, \"EndTime\": 1597760993.155562, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760970.448489}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:53 INFO 140531487123264] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 31201, \"sum\": 31201.0, \"min\": 31201}, \"Total Records Seen\": {\"count\": 1, \"max\": 31188304, \"sum\": 31188304.0, \"min\": 31188304}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 25, \"sum\": 25.0, \"min\": 25}}, \"EndTime\": 1597760993.155811, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 23}, \"StartTime\": 1597760970.450398}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:53 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57231.4733848 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:53 INFO 140531487123264] #quality_metric: host=algo-1, epoch=24, batch=0 train rmse <loss>=0.428349675165\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:53 INFO 140531487123264] #quality_metric: host=algo-1, epoch=24, batch=0 train mse <loss>=0.183483444214\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:29:53 INFO 140531487123264] #quality_metric: host=algo-1, epoch=24, batch=0 train absolute_loss <loss>=0.262235656738\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:01 INFO 140531487123264] Iter[24] Batch [500]#011Speed: 57461.19 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:01 INFO 140531487123264] #quality_metric: host=algo-1, epoch=24, batch=500 train rmse <loss>=0.513050920227\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:01 INFO 140531487123264] #quality_metric: host=algo-1, epoch=24, batch=500 train mse <loss>=0.263221246746\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:01 INFO 140531487123264] #quality_metric: host=algo-1, epoch=24, batch=500 train absolute_loss <loss>=0.346614526897\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:10 INFO 140531487123264] Iter[24] Batch [1000]#011Speed: 58356.14 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:10 INFO 140531487123264] #quality_metric: host=algo-1, epoch=24, batch=1000 train rmse <loss>=0.510311681122\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:10 INFO 140531487123264] #quality_metric: host=algo-1, epoch=24, batch=1000 train mse <loss>=0.260418011889\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:10 INFO 140531487123264] #quality_metric: host=algo-1, epoch=24, batch=1000 train absolute_loss <loss>=0.344338756138\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:30:15.563] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 50, \"duration\": 22404, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=24, train rmse <loss>=0.507377071513\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=24, train mse <loss>=0.257431492697\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=24, train absolute_loss <loss>=0.34107763774\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22406.64792060852, \"sum\": 22406.64792060852, \"min\": 22406.64792060852}}, \"EndTime\": 1597761015.564296, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597760993.155639}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:15 INFO 140531487123264] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 32501, \"sum\": 32501.0, \"min\": 32501}, \"Total Records Seen\": {\"count\": 1, \"max\": 32487775, \"sum\": 32487775.0, \"min\": 32487775}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 26, \"sum\": 26.0, \"min\": 26}}, \"EndTime\": 1597761015.564511, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 24}, \"StartTime\": 1597760993.157615}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:15 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57993.9909732 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=25, batch=0 train rmse <loss>=0.415222193054\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=25, batch=0 train mse <loss>=0.172409469604\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:15 INFO 140531487123264] #quality_metric: host=algo-1, epoch=25, batch=0 train absolute_loss <loss>=0.258853881836\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/18/2020 14:30:24 INFO 140531487123264] Iter[25] Batch [500]#011Speed: 57847.72 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:24 INFO 140531487123264] #quality_metric: host=algo-1, epoch=25, batch=500 train rmse <loss>=0.508013906925\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:24 INFO 140531487123264] #quality_metric: host=algo-1, epoch=25, batch=500 train mse <loss>=0.258078129629\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:24 INFO 140531487123264] #quality_metric: host=algo-1, epoch=25, batch=500 train absolute_loss <loss>=0.34257899734\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:32 INFO 140531487123264] Iter[25] Batch [1000]#011Speed: 58543.57 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:32 INFO 140531487123264] #quality_metric: host=algo-1, epoch=25, batch=1000 train rmse <loss>=0.504544326463\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:32 INFO 140531487123264] #quality_metric: host=algo-1, epoch=25, batch=1000 train mse <loss>=0.254564977366\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:32 INFO 140531487123264] #quality_metric: host=algo-1, epoch=25, batch=1000 train absolute_loss <loss>=0.339904028101\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:30:37.845] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 52, \"duration\": 22277, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:37 INFO 140531487123264] #quality_metric: host=algo-1, epoch=25, train rmse <loss>=0.50146112403\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:37 INFO 140531487123264] #quality_metric: host=algo-1, epoch=25, train mse <loss>=0.251463258913\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:37 INFO 140531487123264] #quality_metric: host=algo-1, epoch=25, train absolute_loss <loss>=0.336573098966\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22279.694080352783, \"sum\": 22279.694080352783, \"min\": 22279.694080352783}}, \"EndTime\": 1597761037.845944, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761015.564357}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:37 INFO 140531487123264] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 33801, \"sum\": 33801.0, \"min\": 33801}, \"Total Records Seen\": {\"count\": 1, \"max\": 33787246, \"sum\": 33787246.0, \"min\": 33787246}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 27, \"sum\": 27.0, \"min\": 27}}, \"EndTime\": 1597761037.846155, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 25}, \"StartTime\": 1597761015.566221}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:37 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=58324.4651118 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:37 INFO 140531487123264] #quality_metric: host=algo-1, epoch=26, batch=0 train rmse <loss>=0.403979060622\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:37 INFO 140531487123264] #quality_metric: host=algo-1, epoch=26, batch=0 train mse <loss>=0.163199081421\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:37 INFO 140531487123264] #quality_metric: host=algo-1, epoch=26, batch=0 train absolute_loss <loss>=0.257165802002\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:46 INFO 140531487123264] Iter[26] Batch [500]#011Speed: 56591.41 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:46 INFO 140531487123264] #quality_metric: host=algo-1, epoch=26, batch=500 train rmse <loss>=0.504668288302\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:46 INFO 140531487123264] #quality_metric: host=algo-1, epoch=26, batch=500 train mse <loss>=0.254690081218\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:46 INFO 140531487123264] #quality_metric: host=algo-1, epoch=26, batch=500 train absolute_loss <loss>=0.340326471934\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:55 INFO 140531487123264] Iter[26] Batch [1000]#011Speed: 57962.33 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=26, batch=1000 train rmse <loss>=0.500262875159\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=26, batch=1000 train mse <loss>=0.250262944262\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:30:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=26, batch=1000 train absolute_loss <loss>=0.337137951861\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:31:00.474] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 54, \"duration\": 22625, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=26, train rmse <loss>=0.497039604949\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=26, train mse <loss>=0.247048368888\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=26, train absolute_loss <loss>=0.333812146642\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22627.275943756104, \"sum\": 22627.275943756104, \"min\": 22627.275943756104}}, \"EndTime\": 1597761060.47529, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761037.846015}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:00 INFO 140531487123264] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 35101, \"sum\": 35101.0, \"min\": 35101}, \"Total Records Seen\": {\"count\": 1, \"max\": 35086717, \"sum\": 35086717.0, \"min\": 35086717}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 28, \"sum\": 28.0, \"min\": 28}}, \"EndTime\": 1597761060.475488, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 26}, \"StartTime\": 1597761037.847986}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:00 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57428.4939578 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=27, batch=0 train rmse <loss>=0.391594032424\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=27, batch=0 train mse <loss>=0.15334588623\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:00 INFO 140531487123264] #quality_metric: host=algo-1, epoch=27, batch=0 train absolute_loss <loss>=0.252910461426\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:09 INFO 140531487123264] Iter[27] Batch [500]#011Speed: 57426.63 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:09 INFO 140531487123264] #quality_metric: host=algo-1, epoch=27, batch=500 train rmse <loss>=0.502791941694\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:09 INFO 140531487123264] #quality_metric: host=algo-1, epoch=27, batch=500 train mse <loss>=0.252799736632\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:09 INFO 140531487123264] #quality_metric: host=algo-1, epoch=27, batch=500 train absolute_loss <loss>=0.339696929475\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:17 INFO 140531487123264] Iter[27] Batch [1000]#011Speed: 58062.39 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=27, batch=1000 train rmse <loss>=0.497309378056\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=27, batch=1000 train mse <loss>=0.247316617503\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=27, batch=1000 train absolute_loss <loss>=0.335979524184\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:31:22.996] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 56, \"duration\": 22519, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:22 INFO 140531487123264] #quality_metric: host=algo-1, epoch=27, train rmse <loss>=0.49388472778\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:22 INFO 140531487123264] #quality_metric: host=algo-1, epoch=27, train mse <loss>=0.243922124334\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:22 INFO 140531487123264] #quality_metric: host=algo-1, epoch=27, train absolute_loss <loss>=0.332609291206\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22521.806955337524, \"sum\": 22521.806955337524, \"min\": 22521.806955337524}}, \"EndTime\": 1597761082.997548, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761060.475359}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:22 INFO 140531487123264] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 36401, \"sum\": 36401.0, \"min\": 36401}, \"Total Records Seen\": {\"count\": 1, \"max\": 36386188, \"sum\": 36386188.0, \"min\": 36386188}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 29, \"sum\": 29.0, \"min\": 29}}, \"EndTime\": 1597761082.997777, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 27}, \"StartTime\": 1597761060.475705}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:22 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57697.3304102 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:23 INFO 140531487123264] #quality_metric: host=algo-1, epoch=28, batch=0 train rmse <loss>=0.377052528992\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:23 INFO 140531487123264] #quality_metric: host=algo-1, epoch=28, batch=0 train mse <loss>=0.142168609619\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:23 INFO 140531487123264] #quality_metric: host=algo-1, epoch=28, batch=0 train absolute_loss <loss>=0.244644989014\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/18/2020 14:31:31 INFO 140531487123264] Iter[28] Batch [500]#011Speed: 57306.73 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=28, batch=500 train rmse <loss>=0.501517303537\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=28, batch=500 train mse <loss>=0.251519605747\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=28, batch=500 train absolute_loss <loss>=0.339695230968\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:40 INFO 140531487123264] Iter[28] Batch [1000]#011Speed: 57929.29 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=28, batch=1000 train rmse <loss>=0.494903843161\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=28, batch=1000 train mse <loss>=0.244929813976\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=28, batch=1000 train absolute_loss <loss>=0.335410552475\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:31:45.562] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 58, \"duration\": 22561, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=28, train rmse <loss>=0.491198277813\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=28, train mse <loss>=0.241275748127\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=28, train absolute_loss <loss>=0.331837022271\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22563.26699256897, \"sum\": 22563.26699256897, \"min\": 22563.26699256897}}, \"EndTime\": 1597761105.562865, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761082.997623}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:45 INFO 140531487123264] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 37701, \"sum\": 37701.0, \"min\": 37701}, \"Total Records Seen\": {\"count\": 1, \"max\": 37685659, \"sum\": 37685659.0, \"min\": 37685659}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 30, \"sum\": 30.0, \"min\": 30}}, \"EndTime\": 1597761105.563114, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 28}, \"StartTime\": 1597761082.999567}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:45 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57591.3291621 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=29, batch=0 train rmse <loss>=0.360830717599\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=29, batch=0 train mse <loss>=0.130198806763\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:45 INFO 140531487123264] #quality_metric: host=algo-1, epoch=29, batch=0 train absolute_loss <loss>=0.232724151611\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:54 INFO 140531487123264] Iter[29] Batch [500]#011Speed: 56498.60 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:54 INFO 140531487123264] #quality_metric: host=algo-1, epoch=29, batch=500 train rmse <loss>=0.499844780347\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:54 INFO 140531487123264] #quality_metric: host=algo-1, epoch=29, batch=500 train mse <loss>=0.24984480444\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:31:54 INFO 140531487123264] #quality_metric: host=algo-1, epoch=29, batch=500 train absolute_loss <loss>=0.339363154337\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:02 INFO 140531487123264] Iter[29] Batch [1000]#011Speed: 58517.78 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:02 INFO 140531487123264] #quality_metric: host=algo-1, epoch=29, batch=1000 train rmse <loss>=0.4921920287\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:02 INFO 140531487123264] #quality_metric: host=algo-1, epoch=29, batch=1000 train mse <loss>=0.242252993116\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:02 INFO 140531487123264] #quality_metric: host=algo-1, epoch=29, batch=1000 train absolute_loss <loss>=0.33436711523\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:32:08.199] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 60, \"duration\": 22632, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:08 INFO 140531487123264] #quality_metric: host=algo-1, epoch=29, train rmse <loss>=0.488239318584\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:08 INFO 140531487123264] #quality_metric: host=algo-1, epoch=29, train mse <loss>=0.238377632212\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:08 INFO 140531487123264] #quality_metric: host=algo-1, epoch=29, train absolute_loss <loss>=0.330604767444\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22634.802103042603, \"sum\": 22634.802103042603, \"min\": 22634.802103042603}}, \"EndTime\": 1597761128.199755, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761105.562936}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:08 INFO 140531487123264] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 39001, \"sum\": 39001.0, \"min\": 39001}, \"Total Records Seen\": {\"count\": 1, \"max\": 38985130, \"sum\": 38985130.0, \"min\": 38985130}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}}, \"EndTime\": 1597761128.199985, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 29}, \"StartTime\": 1597761105.564923}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:08 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57409.3791092 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:08 INFO 140531487123264] #quality_metric: host=algo-1, epoch=30, batch=0 train rmse <loss>=0.344605403195\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:08 INFO 140531487123264] #quality_metric: host=algo-1, epoch=30, batch=0 train mse <loss>=0.118752883911\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:08 INFO 140531487123264] #quality_metric: host=algo-1, epoch=30, batch=0 train absolute_loss <loss>=0.220451538086\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:17 INFO 140531487123264] Iter[30] Batch [500]#011Speed: 55675.67 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=30, batch=500 train rmse <loss>=0.49745404267\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=30, batch=500 train mse <loss>=0.247460524569\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=30, batch=500 train absolute_loss <loss>=0.338516148489\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:26 INFO 140531487123264] Iter[30] Batch [1000]#011Speed: 56792.08 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=30, batch=1000 train rmse <loss>=0.488982079717\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=30, batch=1000 train mse <loss>=0.239103474285\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=30, batch=1000 train absolute_loss <loss>=0.332716340407\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:32:31.302] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 62, \"duration\": 23099, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=30, train rmse <loss>=0.484907729118\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=30, train mse <loss>=0.235135505758\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=30, train absolute_loss <loss>=0.328871909274\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23101.494789123535, \"sum\": 23101.494789123535, \"min\": 23101.494789123535}}, \"EndTime\": 1597761151.303351, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761128.199826}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:31 INFO 140531487123264] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 40301, \"sum\": 40301.0, \"min\": 40301}, \"Total Records Seen\": {\"count\": 1, \"max\": 40284601, \"sum\": 40284601.0, \"min\": 40284601}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 32, \"sum\": 32.0, \"min\": 32}}, \"EndTime\": 1597761151.303595, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 30}, \"StartTime\": 1597761128.201824}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:31 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=56249.5295948 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=31, batch=0 train rmse <loss>=0.329906841191\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=31, batch=0 train mse <loss>=0.108838523865\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:31 INFO 140531487123264] #quality_metric: host=algo-1, epoch=31, batch=0 train absolute_loss <loss>=0.208788375854\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/18/2020 14:32:40 INFO 140531487123264] Iter[31] Batch [500]#011Speed: 55259.40 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=31, batch=500 train rmse <loss>=0.494632086542\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=31, batch=500 train mse <loss>=0.244660901037\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=31, batch=500 train absolute_loss <loss>=0.337313973037\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:49 INFO 140531487123264] Iter[31] Batch [1000]#011Speed: 56186.57 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:49 INFO 140531487123264] #quality_metric: host=algo-1, epoch=31, batch=1000 train rmse <loss>=0.48555300149\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:49 INFO 140531487123264] #quality_metric: host=algo-1, epoch=31, batch=1000 train mse <loss>=0.235761717256\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:49 INFO 140531487123264] #quality_metric: host=algo-1, epoch=31, batch=1000 train absolute_loss <loss>=0.330776628325\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:32:54.503] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 64, \"duration\": 23195, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:54 INFO 140531487123264] #quality_metric: host=algo-1, epoch=31, train rmse <loss>=0.48147886795\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:54 INFO 140531487123264] #quality_metric: host=algo-1, epoch=31, train mse <loss>=0.231821900283\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:54 INFO 140531487123264] #quality_metric: host=algo-1, epoch=31, train absolute_loss <loss>=0.326965518435\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23198.373079299927, \"sum\": 23198.373079299927, \"min\": 23198.373079299927}}, \"EndTime\": 1597761174.503827, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761151.303428}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:54 INFO 140531487123264] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 41601, \"sum\": 41601.0, \"min\": 41601}, \"Total Records Seen\": {\"count\": 1, \"max\": 41584072, \"sum\": 41584072.0, \"min\": 41584072}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 33, \"sum\": 33.0, \"min\": 33}}, \"EndTime\": 1597761174.50406, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 31}, \"StartTime\": 1597761151.305424}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:54 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=56014.6869326 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:54 INFO 140531487123264] #quality_metric: host=algo-1, epoch=32, batch=0 train rmse <loss>=0.317311025535\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:54 INFO 140531487123264] #quality_metric: host=algo-1, epoch=32, batch=0 train mse <loss>=0.100686286926\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:32:54 INFO 140531487123264] #quality_metric: host=algo-1, epoch=32, batch=0 train absolute_loss <loss>=0.199652053833\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:03 INFO 140531487123264] Iter[32] Batch [500]#011Speed: 55622.83 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:03 INFO 140531487123264] #quality_metric: host=algo-1, epoch=32, batch=500 train rmse <loss>=0.491785778047\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:03 INFO 140531487123264] #quality_metric: host=algo-1, epoch=32, batch=500 train mse <loss>=0.24185325149\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:03 INFO 140531487123264] #quality_metric: host=algo-1, epoch=32, batch=500 train absolute_loss <loss>=0.336094367387\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:12 INFO 140531487123264] Iter[32] Batch [1000]#011Speed: 56663.63 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:12 INFO 140531487123264] #quality_metric: host=algo-1, epoch=32, batch=1000 train rmse <loss>=0.482220382653\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:12 INFO 140531487123264] #quality_metric: host=algo-1, epoch=32, batch=1000 train mse <loss>=0.232536497446\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:12 INFO 140531487123264] #quality_metric: host=algo-1, epoch=32, batch=1000 train absolute_loss <loss>=0.328928594614\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:33:17.674] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 66, \"duration\": 23166, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=32, train rmse <loss>=0.478219166212\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=32, train mse <loss>=0.228693570932\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=32, train absolute_loss <loss>=0.325246310601\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23168.75910758972, \"sum\": 23168.75910758972, \"min\": 23168.75910758972}}, \"EndTime\": 1597761197.674672, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761174.503897}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:17 INFO 140531487123264] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 42901, \"sum\": 42901.0, \"min\": 42901}, \"Total Records Seen\": {\"count\": 1, \"max\": 42883543, \"sum\": 42883543.0, \"min\": 42883543}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 34, \"sum\": 34.0, \"min\": 34}}, \"EndTime\": 1597761197.674879, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 32}, \"StartTime\": 1597761174.505882}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:17 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=56086.3625588 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=33, batch=0 train rmse <loss>=0.306699387284\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=33, batch=0 train mse <loss>=0.0940645141602\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=33, batch=0 train absolute_loss <loss>=0.192430450439\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:26 INFO 140531487123264] Iter[33] Batch [500]#011Speed: 55558.25 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=33, batch=500 train rmse <loss>=0.48924282008\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=33, batch=500 train mse <loss>=0.239358537\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=33, batch=500 train absolute_loss <loss>=0.335213180116\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:35 INFO 140531487123264] Iter[33] Batch [1000]#011Speed: 56447.39 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:35 INFO 140531487123264] #quality_metric: host=algo-1, epoch=33, batch=1000 train rmse <loss>=0.479189012159\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:35 INFO 140531487123264] #quality_metric: host=algo-1, epoch=33, batch=1000 train mse <loss>=0.229622109374\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:35 INFO 140531487123264] #quality_metric: host=algo-1, epoch=33, batch=1000 train absolute_loss <loss>=0.327367106206\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:33:40.808] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 68, \"duration\": 23130, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=33, train rmse <loss>=0.475272433499\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=33, train mse <loss>=0.225883886044\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=33, train absolute_loss <loss>=0.323844549115\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23132.543802261353, \"sum\": 23132.543802261353, \"min\": 23132.543802261353}}, \"EndTime\": 1597761220.809298, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761197.674744}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:40 INFO 140531487123264] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 44201, \"sum\": 44201.0, \"min\": 44201}, \"Total Records Seen\": {\"count\": 1, \"max\": 44183014, \"sum\": 44183014.0, \"min\": 44183014}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 35, \"sum\": 35.0, \"min\": 35}}, \"EndTime\": 1597761220.809534, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 33}, \"StartTime\": 1597761197.676719}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:40 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=56174.1137629 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=34, batch=0 train rmse <loss>=0.297557667505\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=34, batch=0 train mse <loss>=0.0885405654907\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=34, batch=0 train absolute_loss <loss>=0.185232788086\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/18/2020 14:33:49 INFO 140531487123264] Iter[34] Batch [500]#011Speed: 55677.26 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:49 INFO 140531487123264] #quality_metric: host=algo-1, epoch=34, batch=500 train rmse <loss>=0.487220451492\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:49 INFO 140531487123264] #quality_metric: host=algo-1, epoch=34, batch=500 train mse <loss>=0.237383768352\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:49 INFO 140531487123264] #quality_metric: host=algo-1, epoch=34, batch=500 train absolute_loss <loss>=0.334883661875\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:58 INFO 140531487123264] Iter[34] Batch [1000]#011Speed: 56635.91 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:58 INFO 140531487123264] #quality_metric: host=algo-1, epoch=34, batch=1000 train rmse <loss>=0.476554065737\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:58 INFO 140531487123264] #quality_metric: host=algo-1, epoch=34, batch=1000 train mse <loss>=0.22710377757\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:33:58 INFO 140531487123264] #quality_metric: host=algo-1, epoch=34, batch=1000 train absolute_loss <loss>=0.326134932679\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:34:03.957] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 70, \"duration\": 23145, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:03 INFO 140531487123264] #quality_metric: host=algo-1, epoch=34, train rmse <loss>=0.472678214361\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:03 INFO 140531487123264] #quality_metric: host=algo-1, epoch=34, train mse <loss>=0.223424694331\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:03 INFO 140531487123264] #quality_metric: host=algo-1, epoch=34, train absolute_loss <loss>=0.322749276499\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 23148.03409576416, \"sum\": 23148.03409576416, \"min\": 23148.03409576416}}, \"EndTime\": 1597761243.957849, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761220.809372}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:03 INFO 140531487123264] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 45501, \"sum\": 45501.0, \"min\": 45501}, \"Total Records Seen\": {\"count\": 1, \"max\": 45482485, \"sum\": 45482485.0, \"min\": 45482485}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 36, \"sum\": 36.0, \"min\": 36}}, \"EndTime\": 1597761243.958091, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 34}, \"StartTime\": 1597761220.809782}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:03 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=56136.4900144 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:03 INFO 140531487123264] #quality_metric: host=algo-1, epoch=35, batch=0 train rmse <loss>=0.289277145286\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:03 INFO 140531487123264] #quality_metric: host=algo-1, epoch=35, batch=0 train mse <loss>=0.0836812667847\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:03 INFO 140531487123264] #quality_metric: host=algo-1, epoch=35, batch=0 train absolute_loss <loss>=0.178291595459\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:12 INFO 140531487123264] Iter[35] Batch [500]#011Speed: 56011.74 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:12 INFO 140531487123264] #quality_metric: host=algo-1, epoch=35, batch=500 train rmse <loss>=0.485825713588\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:12 INFO 140531487123264] #quality_metric: host=algo-1, epoch=35, batch=500 train mse <loss>=0.236026623983\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:12 INFO 140531487123264] #quality_metric: host=algo-1, epoch=35, batch=500 train absolute_loss <loss>=0.335152684926\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:21 INFO 140531487123264] Iter[35] Batch [1000]#011Speed: 58664.51 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:21 INFO 140531487123264] #quality_metric: host=algo-1, epoch=35, batch=1000 train rmse <loss>=0.474331338241\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:21 INFO 140531487123264] #quality_metric: host=algo-1, epoch=35, batch=1000 train mse <loss>=0.224990218438\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:21 INFO 140531487123264] #quality_metric: host=algo-1, epoch=35, batch=1000 train absolute_loss <loss>=0.325229810031\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:34:26.511] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 72, \"duration\": 22550, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=35, train rmse <loss>=0.470417170056\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=35, train mse <loss>=0.221292313884\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=35, train absolute_loss <loss>=0.32188875993\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22552.464962005615, \"sum\": 22552.464962005615, \"min\": 22552.464962005615}}, \"EndTime\": 1597761266.512395, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761243.957925}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:26 INFO 140531487123264] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 46801, \"sum\": 46801.0, \"min\": 46801}, \"Total Records Seen\": {\"count\": 1, \"max\": 46781956, \"sum\": 46781956.0, \"min\": 46781956}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 37, \"sum\": 37.0, \"min\": 37}}, \"EndTime\": 1597761266.512594, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 35}, \"StartTime\": 1597761243.959902}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:26 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57619.0541064 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=36, batch=0 train rmse <loss>=0.281596710125\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=36, batch=0 train mse <loss>=0.0792967071533\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=36, batch=0 train absolute_loss <loss>=0.173189804077\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:35 INFO 140531487123264] Iter[36] Batch [500]#011Speed: 58465.16 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:35 INFO 140531487123264] #quality_metric: host=algo-1, epoch=36, batch=500 train rmse <loss>=0.485068187723\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:35 INFO 140531487123264] #quality_metric: host=algo-1, epoch=36, batch=500 train mse <loss>=0.235291146741\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:35 INFO 140531487123264] #quality_metric: host=algo-1, epoch=36, batch=500 train absolute_loss <loss>=0.335989117377\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:43 INFO 140531487123264] Iter[36] Batch [1000]#011Speed: 58372.65 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:43 INFO 140531487123264] #quality_metric: host=algo-1, epoch=36, batch=1000 train rmse <loss>=0.472488615457\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:43 INFO 140531487123264] #quality_metric: host=algo-1, epoch=36, batch=1000 train mse <loss>=0.223245491737\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:43 INFO 140531487123264] #quality_metric: host=algo-1, epoch=36, batch=1000 train absolute_loss <loss>=0.324651946381\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:34:48.757] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 74, \"duration\": 22240, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:48 INFO 140531487123264] #quality_metric: host=algo-1, epoch=36, train rmse <loss>=0.468450975286\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:48 INFO 140531487123264] #quality_metric: host=algo-1, epoch=36, train mse <loss>=0.219446316247\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:48 INFO 140531487123264] #quality_metric: host=algo-1, epoch=36, train absolute_loss <loss>=0.321249136071\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22243.085145950317, \"sum\": 22243.085145950317, \"min\": 22243.085145950317}}, \"EndTime\": 1597761288.757559, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761266.512457}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:48 INFO 140531487123264] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 48101, \"sum\": 48101.0, \"min\": 48101}, \"Total Records Seen\": {\"count\": 1, \"max\": 48081427, \"sum\": 48081427.0, \"min\": 48081427}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 38, \"sum\": 38.0, \"min\": 38}}, \"EndTime\": 1597761288.757807, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 36}, \"StartTime\": 1597761266.514441}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:48 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=58420.2945631 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:48 INFO 140531487123264] #quality_metric: host=algo-1, epoch=37, batch=0 train rmse <loss>=0.275269601621\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:48 INFO 140531487123264] #quality_metric: host=algo-1, epoch=37, batch=0 train mse <loss>=0.0757733535767\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:48 INFO 140531487123264] #quality_metric: host=algo-1, epoch=37, batch=0 train absolute_loss <loss>=0.172020263672\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/18/2020 14:34:57 INFO 140531487123264] Iter[37] Batch [500]#011Speed: 57985.07 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:57 INFO 140531487123264] #quality_metric: host=algo-1, epoch=37, batch=500 train rmse <loss>=0.484882923555\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:57 INFO 140531487123264] #quality_metric: host=algo-1, epoch=37, batch=500 train mse <loss>=0.235111449556\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:34:57 INFO 140531487123264] #quality_metric: host=algo-1, epoch=37, batch=500 train absolute_loss <loss>=0.337282549555\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:06 INFO 140531487123264] Iter[37] Batch [1000]#011Speed: 57789.20 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:06 INFO 140531487123264] #quality_metric: host=algo-1, epoch=37, batch=1000 train rmse <loss>=0.470971794312\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:06 INFO 140531487123264] #quality_metric: host=algo-1, epoch=37, batch=1000 train mse <loss>=0.221814431037\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:06 INFO 140531487123264] #quality_metric: host=algo-1, epoch=37, batch=1000 train absolute_loss <loss>=0.324227319418\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:35:11.165] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 76, \"duration\": 22404, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:11 INFO 140531487123264] #quality_metric: host=algo-1, epoch=37, train rmse <loss>=0.466743368095\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:11 INFO 140531487123264] #quality_metric: host=algo-1, epoch=37, train mse <loss>=0.217849371661\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:11 INFO 140531487123264] #quality_metric: host=algo-1, epoch=37, train absolute_loss <loss>=0.320717910837\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22406.657934188843, \"sum\": 22406.657934188843, \"min\": 22406.657934188843}}, \"EndTime\": 1597761311.166287, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761288.757643}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:11 INFO 140531487123264] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 49401, \"sum\": 49401.0, \"min\": 49401}, \"Total Records Seen\": {\"count\": 1, \"max\": 49380898, \"sum\": 49380898.0, \"min\": 49380898}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 39, \"sum\": 39.0, \"min\": 39}}, \"EndTime\": 1597761311.166481, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 37}, \"StartTime\": 1597761288.759601}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:11 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57994.0014635 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:11 INFO 140531487123264] #quality_metric: host=algo-1, epoch=38, batch=0 train rmse <loss>=0.272417433243\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:11 INFO 140531487123264] #quality_metric: host=algo-1, epoch=38, batch=0 train mse <loss>=0.0742112579346\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:11 INFO 140531487123264] #quality_metric: host=algo-1, epoch=38, batch=0 train absolute_loss <loss>=0.177033294678\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:19 INFO 140531487123264] Iter[38] Batch [500]#011Speed: 57837.19 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:19 INFO 140531487123264] #quality_metric: host=algo-1, epoch=38, batch=500 train rmse <loss>=0.485152188749\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:19 INFO 140531487123264] #quality_metric: host=algo-1, epoch=38, batch=500 train mse <loss>=0.235372646248\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:19 INFO 140531487123264] #quality_metric: host=algo-1, epoch=38, batch=500 train absolute_loss <loss>=0.338836551628\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:28 INFO 140531487123264] Iter[38] Batch [1000]#011Speed: 58961.77 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:28 INFO 140531487123264] #quality_metric: host=algo-1, epoch=38, batch=1000 train rmse <loss>=0.469721566698\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:28 INFO 140531487123264] #quality_metric: host=algo-1, epoch=38, batch=1000 train mse <loss>=0.220638350221\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:28 INFO 140531487123264] #quality_metric: host=algo-1, epoch=38, batch=1000 train absolute_loss <loss>=0.323865878125\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:35:33.398] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 78, \"duration\": 22228, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:33 INFO 140531487123264] #quality_metric: host=algo-1, epoch=38, train rmse <loss>=0.465263091598\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:33 INFO 140531487123264] #quality_metric: host=algo-1, epoch=38, train mse <loss>=0.216469744404\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:33 INFO 140531487123264] #quality_metric: host=algo-1, epoch=38, train absolute_loss <loss>=0.320251760242\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22230.393886566162, \"sum\": 22230.393886566162, \"min\": 22230.393886566162}}, \"EndTime\": 1597761333.398813, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761311.166351}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:33 INFO 140531487123264] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 50701, \"sum\": 50701.0, \"min\": 50701}, \"Total Records Seen\": {\"count\": 1, \"max\": 50680369, \"sum\": 50680369.0, \"min\": 50680369}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 40, \"sum\": 40.0, \"min\": 40}}, \"EndTime\": 1597761333.399059, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 38}, \"StartTime\": 1597761311.168394}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:33 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=58453.7054729 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:33 INFO 140531487123264] #quality_metric: host=algo-1, epoch=39, batch=0 train rmse <loss>=0.275582421576\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:33 INFO 140531487123264] #quality_metric: host=algo-1, epoch=39, batch=0 train mse <loss>=0.0759456710815\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:33 INFO 140531487123264] #quality_metric: host=algo-1, epoch=39, batch=0 train absolute_loss <loss>=0.189324951172\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:42 INFO 140531487123264] Iter[39] Batch [500]#011Speed: 57918.92 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:42 INFO 140531487123264] #quality_metric: host=algo-1, epoch=39, batch=500 train rmse <loss>=0.485719039009\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:42 INFO 140531487123264] #quality_metric: host=algo-1, epoch=39, batch=500 train mse <loss>=0.235922984856\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:42 INFO 140531487123264] #quality_metric: host=algo-1, epoch=39, batch=500 train absolute_loss <loss>=0.340598127993\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:50 INFO 140531487123264] Iter[39] Batch [1000]#011Speed: 58333.67 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:50 INFO 140531487123264] #quality_metric: host=algo-1, epoch=39, batch=1000 train rmse <loss>=0.468677553488\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:50 INFO 140531487123264] #quality_metric: host=algo-1, epoch=39, batch=1000 train mse <loss>=0.219658649144\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:50 INFO 140531487123264] #quality_metric: host=algo-1, epoch=39, batch=1000 train absolute_loss <loss>=0.323611891999\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:35:55.684] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 80, \"duration\": 22283, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=39, train rmse <loss>=0.463977264457\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=39, train mse <loss>=0.215274901933\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=39, train absolute_loss <loss>=0.319881764092\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22285.99786758423, \"sum\": 22285.99786758423, \"min\": 22285.99786758423}}, \"EndTime\": 1597761355.685363, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761333.398881}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:55 INFO 140531487123264] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 52001, \"sum\": 52001.0, \"min\": 52001}, \"Total Records Seen\": {\"count\": 1, \"max\": 51979840, \"sum\": 51979840.0, \"min\": 51979840}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 41, \"sum\": 41.0, \"min\": 41}}, \"EndTime\": 1597761355.685559, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 39}, \"StartTime\": 1597761333.399332}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:55 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=58307.8966727 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=40, batch=0 train rmse <loss>=0.285349370072\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=40, batch=0 train mse <loss>=0.0814242630005\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:35:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=40, batch=0 train absolute_loss <loss>=0.207384780884\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/18/2020 14:36:04 INFO 140531487123264] Iter[40] Batch [500]#011Speed: 57457.14 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:04 INFO 140531487123264] #quality_metric: host=algo-1, epoch=40, batch=500 train rmse <loss>=0.486399607028\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:04 INFO 140531487123264] #quality_metric: host=algo-1, epoch=40, batch=500 train mse <loss>=0.236584577717\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:04 INFO 140531487123264] #quality_metric: host=algo-1, epoch=40, batch=500 train absolute_loss <loss>=0.342390380037\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:12 INFO 140531487123264] Iter[40] Batch [1000]#011Speed: 58560.13 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:12 INFO 140531487123264] #quality_metric: host=algo-1, epoch=40, batch=1000 train rmse <loss>=0.467779244736\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:12 INFO 140531487123264] #quality_metric: host=algo-1, epoch=40, batch=1000 train mse <loss>=0.218817421805\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:12 INFO 140531487123264] #quality_metric: host=algo-1, epoch=40, batch=1000 train absolute_loss <loss>=0.32348011949\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:36:18.112] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 82, \"duration\": 22423, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:18 INFO 140531487123264] #quality_metric: host=algo-1, epoch=40, train rmse <loss>=0.462849817494\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:18 INFO 140531487123264] #quality_metric: host=algo-1, epoch=40, train mse <loss>=0.214229953555\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:18 INFO 140531487123264] #quality_metric: host=algo-1, epoch=40, train absolute_loss <loss>=0.319606874202\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22425.812005996704, \"sum\": 22425.812005996704, \"min\": 22425.812005996704}}, \"EndTime\": 1597761378.113208, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761355.68543}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:18 INFO 140531487123264] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 53301, \"sum\": 53301.0, \"min\": 53301}, \"Total Records Seen\": {\"count\": 1, \"max\": 53279311, \"sum\": 53279311.0, \"min\": 53279311}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 42, \"sum\": 42.0, \"min\": 42}}, \"EndTime\": 1597761378.113462, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 40}, \"StartTime\": 1597761355.687364}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:18 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57944.2491198 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:18 INFO 140531487123264] #quality_metric: host=algo-1, epoch=41, batch=0 train rmse <loss>=0.298533402457\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:18 INFO 140531487123264] #quality_metric: host=algo-1, epoch=41, batch=0 train mse <loss>=0.0891221923828\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:18 INFO 140531487123264] #quality_metric: host=algo-1, epoch=41, batch=0 train absolute_loss <loss>=0.226391403198\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:26 INFO 140531487123264] Iter[41] Batch [500]#011Speed: 57335.85 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=41, batch=500 train rmse <loss>=0.487006882983\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=41, batch=500 train mse <loss>=0.237175704073\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=41, batch=500 train absolute_loss <loss>=0.34399984927\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:35 INFO 140531487123264] Iter[41] Batch [1000]#011Speed: 58641.55 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:35 INFO 140531487123264] #quality_metric: host=algo-1, epoch=41, batch=1000 train rmse <loss>=0.466971379396\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:35 INFO 140531487123264] #quality_metric: host=algo-1, epoch=41, batch=1000 train mse <loss>=0.218062269175\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:35 INFO 140531487123264] #quality_metric: host=algo-1, epoch=41, batch=1000 train absolute_loss <loss>=0.323407428235\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:36:40.451] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 84, \"duration\": 22334, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=41, train rmse <loss>=0.461849911004\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=41, train mse <loss>=0.213305340294\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=41, train absolute_loss <loss>=0.319423950618\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22336.925983428955, \"sum\": 22336.925983428955, \"min\": 22336.925983428955}}, \"EndTime\": 1597761400.452339, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761378.113293}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:40 INFO 140531487123264] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 54601, \"sum\": 54601.0, \"min\": 54601}, \"Total Records Seen\": {\"count\": 1, \"max\": 54578782, \"sum\": 54578782.0, \"min\": 54578782}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 43, \"sum\": 43.0, \"min\": 43}}, \"EndTime\": 1597761400.452533, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 41}, \"StartTime\": 1597761378.115385}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:40 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=58175.0116855 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=42, batch=0 train rmse <loss>=0.309112708909\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=42, batch=0 train mse <loss>=0.0955506668091\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=42, batch=0 train absolute_loss <loss>=0.241515869141\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:49 INFO 140531487123264] Iter[42] Batch [500]#011Speed: 57604.76 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:49 INFO 140531487123264] #quality_metric: host=algo-1, epoch=42, batch=500 train rmse <loss>=0.487383420408\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:49 INFO 140531487123264] #quality_metric: host=algo-1, epoch=42, batch=500 train mse <loss>=0.237542598488\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:49 INFO 140531487123264] #quality_metric: host=algo-1, epoch=42, batch=500 train absolute_loss <loss>=0.345362928044\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:57 INFO 140531487123264] Iter[42] Batch [1000]#011Speed: 58234.38 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:57 INFO 140531487123264] #quality_metric: host=algo-1, epoch=42, batch=1000 train rmse <loss>=0.466214206968\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:57 INFO 140531487123264] #quality_metric: host=algo-1, epoch=42, batch=1000 train mse <loss>=0.217355686778\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:36:57 INFO 140531487123264] #quality_metric: host=algo-1, epoch=42, batch=1000 train absolute_loss <loss>=0.323359788329\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:37:02.832] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 86, \"duration\": 22376, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:02 INFO 140531487123264] #quality_metric: host=algo-1, epoch=42, train rmse <loss>=0.460963310365\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:02 INFO 140531487123264] #quality_metric: host=algo-1, epoch=42, train mse <loss>=0.212487173503\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:02 INFO 140531487123264] #quality_metric: host=algo-1, epoch=42, train absolute_loss <loss>=0.319285134277\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22379.173040390015, \"sum\": 22379.173040390015, \"min\": 22379.173040390015}}, \"EndTime\": 1597761422.833532, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761400.452402}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:02 INFO 140531487123264] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 55901, \"sum\": 55901.0, \"min\": 55901}, \"Total Records Seen\": {\"count\": 1, \"max\": 55878253, \"sum\": 55878253.0, \"min\": 55878253}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 44, \"sum\": 44.0, \"min\": 44}}, \"EndTime\": 1597761422.833759, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 42}, \"StartTime\": 1597761400.454331}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:02 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=58065.1655097 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:02 INFO 140531487123264] #quality_metric: host=algo-1, epoch=43, batch=0 train rmse <loss>=0.311163143923\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:02 INFO 140531487123264] #quality_metric: host=algo-1, epoch=43, batch=0 train mse <loss>=0.0968225021362\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:02 INFO 140531487123264] #quality_metric: host=algo-1, epoch=43, batch=0 train absolute_loss <loss>=0.244109222412\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/18/2020 14:37:11 INFO 140531487123264] Iter[43] Batch [500]#011Speed: 58051.27 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:11 INFO 140531487123264] #quality_metric: host=algo-1, epoch=43, batch=500 train rmse <loss>=0.487429068983\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:11 INFO 140531487123264] #quality_metric: host=algo-1, epoch=43, batch=500 train mse <loss>=0.23758709729\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:11 INFO 140531487123264] #quality_metric: host=algo-1, epoch=43, batch=500 train absolute_loss <loss>=0.346233938312\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:20 INFO 140531487123264] Iter[43] Batch [1000]#011Speed: 57938.66 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:20 INFO 140531487123264] #quality_metric: host=algo-1, epoch=43, batch=1000 train rmse <loss>=0.465491177559\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:20 INFO 140531487123264] #quality_metric: host=algo-1, epoch=43, batch=1000 train mse <loss>=0.216682036386\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:20 INFO 140531487123264] #quality_metric: host=algo-1, epoch=43, batch=1000 train absolute_loss <loss>=0.323305969436\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:37:25.208] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 88, \"duration\": 22371, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:25 INFO 140531487123264] #quality_metric: host=algo-1, epoch=43, train rmse <loss>=0.460198695402\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:25 INFO 140531487123264] #quality_metric: host=algo-1, epoch=43, train mse <loss>=0.21178283925\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:25 INFO 140531487123264] #quality_metric: host=algo-1, epoch=43, train absolute_loss <loss>=0.319214856556\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22373.353958129883, \"sum\": 22373.353958129883, \"min\": 22373.353958129883}}, \"EndTime\": 1597761445.208976, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761422.833601}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:25 INFO 140531487123264] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 57201, \"sum\": 57201.0, \"min\": 57201}, \"Total Records Seen\": {\"count\": 1, \"max\": 57177724, \"sum\": 57177724.0, \"min\": 57177724}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}}, \"EndTime\": 1597761445.209219, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 43}, \"StartTime\": 1597761422.835591}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:25 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=58080.1089885 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:25 INFO 140531487123264] #quality_metric: host=algo-1, epoch=44, batch=0 train rmse <loss>=0.301667512784\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:25 INFO 140531487123264] #quality_metric: host=algo-1, epoch=44, batch=0 train mse <loss>=0.091003288269\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:25 INFO 140531487123264] #quality_metric: host=algo-1, epoch=44, batch=0 train absolute_loss <loss>=0.230964050293\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:33 INFO 140531487123264] Iter[44] Batch [500]#011Speed: 57336.27 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:33 INFO 140531487123264] #quality_metric: host=algo-1, epoch=44, batch=500 train rmse <loss>=0.487114275592\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:33 INFO 140531487123264] #quality_metric: host=algo-1, epoch=44, batch=500 train mse <loss>=0.237280317485\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:33 INFO 140531487123264] #quality_metric: host=algo-1, epoch=44, batch=500 train absolute_loss <loss>=0.346585281524\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:42 INFO 140531487123264] Iter[44] Batch [1000]#011Speed: 57857.20 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:42 INFO 140531487123264] #quality_metric: host=algo-1, epoch=44, batch=1000 train rmse <loss>=0.464813032283\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:42 INFO 140531487123264] #quality_metric: host=algo-1, epoch=44, batch=1000 train mse <loss>=0.21605115498\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:42 INFO 140531487123264] #quality_metric: host=algo-1, epoch=44, batch=1000 train absolute_loss <loss>=0.323310174094\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:37:47.677] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 90, \"duration\": 22464, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:47 INFO 140531487123264] #quality_metric: host=algo-1, epoch=44, train rmse <loss>=0.459586525319\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:47 INFO 140531487123264] #quality_metric: host=algo-1, epoch=44, train mse <loss>=0.211219774255\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:47 INFO 140531487123264] #quality_metric: host=algo-1, epoch=44, train absolute_loss <loss>=0.319303953458\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22466.40920639038, \"sum\": 22466.40920639038, \"min\": 22466.40920639038}}, \"EndTime\": 1597761467.67752, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761445.209047}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:47 INFO 140531487123264] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 58501, \"sum\": 58501.0, \"min\": 58501}, \"Total Records Seen\": {\"count\": 1, \"max\": 58477195, \"sum\": 58477195.0, \"min\": 58477195}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 46, \"sum\": 46.0, \"min\": 46}}, \"EndTime\": 1597761467.677712, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 44}, \"StartTime\": 1597761445.211082}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:47 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57839.7847709 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:47 INFO 140531487123264] #quality_metric: host=algo-1, epoch=45, batch=0 train rmse <loss>=0.282345927937\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:47 INFO 140531487123264] #quality_metric: host=algo-1, epoch=45, batch=0 train mse <loss>=0.0797192230225\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:47 INFO 140531487123264] #quality_metric: host=algo-1, epoch=45, batch=0 train absolute_loss <loss>=0.20450352478\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:56 INFO 140531487123264] Iter[45] Batch [500]#011Speed: 57645.78 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:56 INFO 140531487123264] #quality_metric: host=algo-1, epoch=45, batch=500 train rmse <loss>=0.486475204374\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:56 INFO 140531487123264] #quality_metric: host=algo-1, epoch=45, batch=500 train mse <loss>=0.236658124471\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:37:56 INFO 140531487123264] #quality_metric: host=algo-1, epoch=45, batch=500 train absolute_loss <loss>=0.346659587198\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:04 INFO 140531487123264] Iter[45] Batch [1000]#011Speed: 58256.18 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:04 INFO 140531487123264] #quality_metric: host=algo-1, epoch=45, batch=1000 train rmse <loss>=0.464216592144\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:04 INFO 140531487123264] #quality_metric: host=algo-1, epoch=45, batch=1000 train mse <loss>=0.215497044421\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:04 INFO 140531487123264] #quality_metric: host=algo-1, epoch=45, batch=1000 train absolute_loss <loss>=0.323512347074\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:38:10.127] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 92, \"duration\": 22446, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:10 INFO 140531487123264] #quality_metric: host=algo-1, epoch=45, train rmse <loss>=0.459169955379\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:10 INFO 140531487123264] #quality_metric: host=algo-1, epoch=45, train mse <loss>=0.210837047923\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:10 INFO 140531487123264] #quality_metric: host=algo-1, epoch=45, train absolute_loss <loss>=0.319706880575\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22448.90809059143, \"sum\": 22448.90809059143, \"min\": 22448.90809059143}}, \"EndTime\": 1597761490.128484, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761467.677583}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:10 INFO 140531487123264] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 59801, \"sum\": 59801.0, \"min\": 59801}, \"Total Records Seen\": {\"count\": 1, \"max\": 59776666, \"sum\": 59776666.0, \"min\": 59776666}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 47, \"sum\": 47.0, \"min\": 47}}, \"EndTime\": 1597761490.128723, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 45}, \"StartTime\": 1597761467.679544}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:10 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57884.7135849 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:10 INFO 140531487123264] #quality_metric: host=algo-1, epoch=46, batch=0 train rmse <loss>=0.260070882085\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:10 INFO 140531487123264] #quality_metric: host=algo-1, epoch=46, batch=0 train mse <loss>=0.0676368637085\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:10 INFO 140531487123264] #quality_metric: host=algo-1, epoch=46, batch=0 train absolute_loss <loss>=0.176934066772\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/18/2020 14:38:18 INFO 140531487123264] Iter[46] Batch [500]#011Speed: 57082.77 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:18 INFO 140531487123264] #quality_metric: host=algo-1, epoch=46, batch=500 train rmse <loss>=0.48559849168\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:18 INFO 140531487123264] #quality_metric: host=algo-1, epoch=46, batch=500 train mse <loss>=0.235805895122\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:18 INFO 140531487123264] #quality_metric: host=algo-1, epoch=46, batch=500 train absolute_loss <loss>=0.346539929967\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:27 INFO 140531487123264] Iter[46] Batch [1000]#011Speed: 58601.88 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:27 INFO 140531487123264] #quality_metric: host=algo-1, epoch=46, batch=1000 train rmse <loss>=0.463761500559\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:27 INFO 140531487123264] #quality_metric: host=algo-1, epoch=46, batch=1000 train mse <loss>=0.215074729401\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:27 INFO 140531487123264] #quality_metric: host=algo-1, epoch=46, batch=1000 train absolute_loss <loss>=0.323978753302\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:38:32.591] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 94, \"duration\": 22460, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:32 INFO 140531487123264] #quality_metric: host=algo-1, epoch=46, train rmse <loss>=0.458993579407\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:32 INFO 140531487123264] #quality_metric: host=algo-1, epoch=46, train mse <loss>=0.210675105937\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:32 INFO 140531487123264] #quality_metric: host=algo-1, epoch=46, train absolute_loss <loss>=0.320472185023\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22462.570190429688, \"sum\": 22462.570190429688, \"min\": 22462.570190429688}}, \"EndTime\": 1597761512.591572, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761490.128558}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:32 INFO 140531487123264] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 61101, \"sum\": 61101.0, \"min\": 61101}, \"Total Records Seen\": {\"count\": 1, \"max\": 61076137, \"sum\": 61076137.0, \"min\": 61076137}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 48, \"sum\": 48.0, \"min\": 48}}, \"EndTime\": 1597761512.591766, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 46}, \"StartTime\": 1597761490.12897}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:32 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57849.6232019 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:32 INFO 140531487123264] #quality_metric: host=algo-1, epoch=47, batch=0 train rmse <loss>=0.244176583289\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:32 INFO 140531487123264] #quality_metric: host=algo-1, epoch=47, batch=0 train mse <loss>=0.0596222038269\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:32 INFO 140531487123264] #quality_metric: host=algo-1, epoch=47, batch=0 train absolute_loss <loss>=0.161930999756\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:41 INFO 140531487123264] Iter[47] Batch [500]#011Speed: 57196.25 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:41 INFO 140531487123264] #quality_metric: host=algo-1, epoch=47, batch=500 train rmse <loss>=0.484599450628\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:41 INFO 140531487123264] #quality_metric: host=algo-1, epoch=47, batch=500 train mse <loss>=0.234836627549\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:41 INFO 140531487123264] #quality_metric: host=algo-1, epoch=47, batch=500 train absolute_loss <loss>=0.346362140161\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:49 INFO 140531487123264] Iter[47] Batch [1000]#011Speed: 58441.96 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:49 INFO 140531487123264] #quality_metric: host=algo-1, epoch=47, batch=1000 train rmse <loss>=0.463523354972\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:49 INFO 140531487123264] #quality_metric: host=algo-1, epoch=47, batch=1000 train mse <loss>=0.214853900605\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:49 INFO 140531487123264] #quality_metric: host=algo-1, epoch=47, batch=1000 train absolute_loss <loss>=0.324738639473\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:38:55.082] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 96, \"duration\": 22487, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=47, train rmse <loss>=0.459094927034\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=47, train mse <loss>=0.210768152029\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=47, train absolute_loss <loss>=0.32160679833\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22489.65096473694, \"sum\": 22489.65096473694, \"min\": 22489.65096473694}}, \"EndTime\": 1597761535.083301, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761512.591637}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:55 INFO 140531487123264] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 62401, \"sum\": 62401.0, \"min\": 62401}, \"Total Records Seen\": {\"count\": 1, \"max\": 62375608, \"sum\": 62375608.0, \"min\": 62375608}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 49, \"sum\": 49.0, \"min\": 49}}, \"EndTime\": 1597761535.083546, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 47}, \"StartTime\": 1597761512.593619}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:55 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57779.8492263 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=48, batch=0 train rmse <loss>=0.239317666302\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=48, batch=0 train mse <loss>=0.0572729454041\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:38:55 INFO 140531487123264] #quality_metric: host=algo-1, epoch=48, batch=0 train absolute_loss <loss>=0.160699264526\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:03 INFO 140531487123264] Iter[48] Batch [500]#011Speed: 57015.37 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:03 INFO 140531487123264] #quality_metric: host=algo-1, epoch=48, batch=500 train rmse <loss>=0.483600963887\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:03 INFO 140531487123264] #quality_metric: host=algo-1, epoch=48, batch=500 train mse <loss>=0.233869892273\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:03 INFO 140531487123264] #quality_metric: host=algo-1, epoch=48, batch=500 train absolute_loss <loss>=0.346076713699\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:12 INFO 140531487123264] Iter[48] Batch [1000]#011Speed: 57889.81 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:12 INFO 140531487123264] #quality_metric: host=algo-1, epoch=48, batch=1000 train rmse <loss>=0.463585159895\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:12 INFO 140531487123264] #quality_metric: host=algo-1, epoch=48, batch=1000 train mse <loss>=0.214911200475\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:12 INFO 140531487123264] #quality_metric: host=algo-1, epoch=48, batch=1000 train absolute_loss <loss>=0.325749277334\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:39:17.647] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 98, \"duration\": 22560, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=48, train rmse <loss>=0.459502075316\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=48, train mse <loss>=0.21114215722\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=48, train absolute_loss <loss>=0.32309649812\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22562.95108795166, \"sum\": 22562.95108795166, \"min\": 22562.95108795166}}, \"EndTime\": 1597761557.648528, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761535.083374}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:17 INFO 140531487123264] #progress_metric: host=algo-1, completed 98 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 63701, \"sum\": 63701.0, \"min\": 63701}, \"Total Records Seen\": {\"count\": 1, \"max\": 63675079, \"sum\": 63675079.0, \"min\": 63675079}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 50, \"sum\": 50.0, \"min\": 50}}, \"EndTime\": 1597761557.648801, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 48}, \"StartTime\": 1597761535.085544}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:17 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57592.0009959 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=49, batch=0 train rmse <loss>=0.240352422724\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=49, batch=0 train mse <loss>=0.0577692871094\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:17 INFO 140531487123264] #quality_metric: host=algo-1, epoch=49, batch=0 train absolute_loss <loss>=0.163699050903\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/18/2020 14:39:26 INFO 140531487123264] Iter[49] Batch [500]#011Speed: 57330.75 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=49, batch=500 train rmse <loss>=0.482715784832\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=49, batch=500 train mse <loss>=0.233014528926\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:26 INFO 140531487123264] #quality_metric: host=algo-1, epoch=49, batch=500 train absolute_loss <loss>=0.34579077654\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:35 INFO 140531487123264] Iter[49] Batch [1000]#011Speed: 57720.42 samples/sec\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:35 INFO 140531487123264] #quality_metric: host=algo-1, epoch=49, batch=1000 train rmse <loss>=0.464027720559\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:35 INFO 140531487123264] #quality_metric: host=algo-1, epoch=49, batch=1000 train mse <loss>=0.215321725447\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:35 INFO 140531487123264] #quality_metric: host=algo-1, epoch=49, batch=1000 train absolute_loss <loss>=0.327132111495\u001b[0m\n",
      "\u001b[34m[2020-08-18 14:39:40.205] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 100, \"duration\": 22552, \"num_examples\": 1300, \"num_bytes\": 93562744}\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=49, train rmse <loss>=0.460234867872\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=49, train mse <loss>=0.211816133605\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:40 INFO 140531487123264] #quality_metric: host=algo-1, epoch=49, train absolute_loss <loss>=0.324921415922\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:40 INFO 140531487123264] #quality_metric: host=algo-1, train rmse <loss>=0.460234867872\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:40 INFO 140531487123264] #quality_metric: host=algo-1, train mse <loss>=0.211816133605\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:40 INFO 140531487123264] #quality_metric: host=algo-1, train absolute_loss <loss>=0.324921415922\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22555.363178253174, \"sum\": 22555.363178253174, \"min\": 22555.363178253174}}, \"EndTime\": 1597761580.206055, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761557.648613}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:40 INFO 140531487123264] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 65001, \"sum\": 65001.0, \"min\": 65001}, \"Total Records Seen\": {\"count\": 1, \"max\": 64974550, \"sum\": 64974550.0, \"min\": 64974550}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 51, \"sum\": 51.0, \"min\": 51}}, \"EndTime\": 1597761580.206307, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 49}, \"StartTime\": 1597761557.650662}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:40 INFO 140531487123264] #throughput_metric: host=algo-1, train throughput=57611.4593306 records/second\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:40 WARNING 140531487123264] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:40 INFO 140531487123264] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 117.79308319091797, \"sum\": 117.79308319091797, \"min\": 117.79308319091797}}, \"EndTime\": 1597761580.324483, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761580.206135}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:41 INFO 140531487123264] Saved checkpoint to \"/tmp/tmpTQrZ4k/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[08/18/2020 14:39:41 INFO 140531487123264] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 1131790.0741100311, \"sum\": 1131790.0741100311, \"min\": 1131790.0741100311}, \"setuptime\": {\"count\": 1, \"max\": 72.1580982208252, \"sum\": 72.1580982208252, \"min\": 72.1580982208252}}, \"EndTime\": 1597761581.834982, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597761580.324599}\n",
      "\u001b[0m\n",
      "\n",
      "2020-08-18 14:39:43 Uploading - Uploading generated training model\n",
      "2020-08-18 14:40:25 Completed - Training job completed\n",
      "Training seconds: 1241\n",
      "Billable seconds: 1241\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "crole = get_execution_role()\n",
    "\n",
    "print(sagemaker.estimator.Estimator)\n",
    "fm = sagemaker.estimator.Estimator(container,\n",
    "                                   crole, \n",
    "                                   train_instance_count=1, \n",
    "                                   train_instance_type='ml.c4.xlarge',\n",
    "                                   output_path=output_prefix,\n",
    "                                   sagemaker_session=sagemaker.Session())\n",
    "\n",
    "\n",
    "\n",
    "fm.set_hyperparameters(\n",
    "                      feature_dim=nFeatures,\n",
    "                      predictor_type='regressor',\n",
    "                      mini_batch_size=1000,\n",
    "                      num_factors=64,\n",
    "                      epochs=50)\n",
    "\n",
    "fm.fit({'train': train_data})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "Using already existing model: factorization-machines-2020-08-18-14-17-35-803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "fm_predictor = fm.deploy(instance_type='ml.c4.xlarge', initial_instance_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "import sagemaker_utils\n",
    "from sagemaker_utils.query_serializer import serialize as fmserialize \n",
    "from sagemaker.predictor import  json_deserializer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy \n",
    "\n",
    "\n",
    "sagemaker_utils.query_serializer.nFeatures = nFeatures\n",
    "fm_predictor.content_type = sagemaker_utils.query_serializer.CONTENT_TYPE\n",
    "fm_predictor.serializer = fmserialize\n",
    "fm_predictor.deserializer = json_deserializer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "import numpy \n",
    "\n",
    "def get_score(raw_score):\n",
    "    score = 0 \n",
    "    if raw_score > 3: \n",
    "        score = 1 \n",
    "    return score \n",
    "\n",
    "\n",
    "y_pred = [] \n",
    "for i in range(0, 100): \n",
    "    X_test_arr = X_test_cold[i*100: (i+1)*100]\n",
    "    result = fm_predictor.predict(X_test_arr) \n",
    "    for p in result['predictions']: \n",
    "        y_pred.append(get_score(p['score']))\n",
    "        \n",
    "y_answer = [] \n",
    "for y in Y_test_cold[0:len(y_pred)]:\n",
    "    y_answer.append(get_score(y))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [88999, 10000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-dc94ac352884>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [88999, 10000]"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7242"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.mean(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
