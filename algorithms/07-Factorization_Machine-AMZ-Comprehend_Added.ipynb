{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-10 23:24:38--  https://tinyurl.com/y3gfnlx2\n",
      "Resolving tinyurl.com (tinyurl.com)... 104.20.138.65, 104.20.139.65, 172.67.1.225\n",
      "Connecting to tinyurl.com (tinyurl.com)|104.20.138.65|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://recommendation-demo-yianc.s3.us-east-1.amazonaws.com/amz-review/amz-review-apparel.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIATLORAEYMTX7JY4ER%2F20200810%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200810T152347Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=e6c35dc78526ddb7cd7e913fa63c5f8a5ad57a39ca556ab68fe010ed58051435 [following]\n",
      "--2020-08-10 23:24:39--  https://recommendation-demo-yianc.s3.us-east-1.amazonaws.com/amz-review/amz-review-apparel.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIATLORAEYMTX7JY4ER%2F20200810%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200810T152347Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=e6c35dc78526ddb7cd7e913fa63c5f8a5ad57a39ca556ab68fe010ed58051435\n",
      "Resolving recommendation-demo-yianc.s3.us-east-1.amazonaws.com (recommendation-demo-yianc.s3.us-east-1.amazonaws.com)... 52.216.97.142\n",
      "Connecting to recommendation-demo-yianc.s3.us-east-1.amazonaws.com (recommendation-demo-yianc.s3.us-east-1.amazonaws.com)|52.216.97.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 621522774 (593M) [text/csv]\n",
      "Saving to: ‘amz-review-apparel.csv’\n",
      "\n",
      "amz-review-apparel. 100%[===================>] 592.73M  1.43MB/s    in 7m 18s  \n",
      "\n",
      "2020-08-10 23:31:57 (1.35 MB/s) - ‘amz-review-apparel.csv’ saved [621522774/621522774]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O amz-review-apparel.csv https://tinyurl.com/y3gfnlx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>cnt</th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id.1</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28563435</td>\n",
       "      <td>13</td>\n",
       "      <td>US</td>\n",
       "      <td>28563435</td>\n",
       "      <td>R2M9YYZ4DLZRMN</td>\n",
       "      <td>B003OQTQ0W</td>\n",
       "      <td>97286984</td>\n",
       "      <td>Carhartt Men's Two-Tone Trifold Wallet</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Outstanding Wallet</td>\n",
       "      <td>I have owned a lot of wallets over the years a...</td>\n",
       "      <td>2013-07-11</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28563435</td>\n",
       "      <td>13</td>\n",
       "      <td>US</td>\n",
       "      <td>28563435</td>\n",
       "      <td>R2DIHSYWNP3FPJ</td>\n",
       "      <td>B0093O17U6</td>\n",
       "      <td>765210786</td>\n",
       "      <td>IH Camouflage Trucker Cap in Mossy Oak Break-U...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Great cap</td>\n",
       "      <td>This is a very nice hat,but i have got another...</td>\n",
       "      <td>2013-05-11</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28563435</td>\n",
       "      <td>13</td>\n",
       "      <td>US</td>\n",
       "      <td>28563435</td>\n",
       "      <td>R36XY86RBEESP6</td>\n",
       "      <td>B0051I6MYY</td>\n",
       "      <td>268391293</td>\n",
       "      <td>IH 5 Panel Trucker Cap with Liquid Metal Logo</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Great hat!!!</td>\n",
       "      <td>This is a great hat and is very well made!! I ...</td>\n",
       "      <td>2013-04-13</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28563435</td>\n",
       "      <td>13</td>\n",
       "      <td>US</td>\n",
       "      <td>28563435</td>\n",
       "      <td>R2X9GLV67VACAN</td>\n",
       "      <td>B005F29FKO</td>\n",
       "      <td>506334102</td>\n",
       "      <td>Carhartt Men's Relaxed Straight Denim Five Poc...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Great pants</td>\n",
       "      <td>I have always been a Wrangler man most of my l...</td>\n",
       "      <td>2012-12-08</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28563435</td>\n",
       "      <td>13</td>\n",
       "      <td>US</td>\n",
       "      <td>28563435</td>\n",
       "      <td>RS4RG84BX2KK5</td>\n",
       "      <td>B004QF0THY</td>\n",
       "      <td>206343191</td>\n",
       "      <td>Dickies Men's 2 Pack Wool Blend Boot Crew Socks</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Very Great socks!!</td>\n",
       "      <td>Wool is the only socks i wear and the only thi...</td>\n",
       "      <td>2012-12-08</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  cnt marketplace  customer_id.1       review_id  product_id  \\\n",
       "0     28563435   13          US       28563435  R2M9YYZ4DLZRMN  B003OQTQ0W   \n",
       "1     28563435   13          US       28563435  R2DIHSYWNP3FPJ  B0093O17U6   \n",
       "2     28563435   13          US       28563435  R36XY86RBEESP6  B0051I6MYY   \n",
       "3     28563435   13          US       28563435  R2X9GLV67VACAN  B005F29FKO   \n",
       "4     28563435   13          US       28563435   RS4RG84BX2KK5  B004QF0THY   \n",
       "\n",
       "   product_parent                                      product_title  \\\n",
       "0        97286984             Carhartt Men's Two-Tone Trifold Wallet   \n",
       "1       765210786  IH Camouflage Trucker Cap in Mossy Oak Break-U...   \n",
       "2       268391293      IH 5 Panel Trucker Cap with Liquid Metal Logo   \n",
       "3       506334102  Carhartt Men's Relaxed Straight Denim Five Poc...   \n",
       "4       206343191    Dickies Men's 2 Pack Wool Blend Boot Crew Socks   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            5              0            0    N                 Y   \n",
       "1            5              0            0    N                 Y   \n",
       "2            5              1            1    N                 Y   \n",
       "3            5              0            0    N                 Y   \n",
       "4            5              0            0    N                 Y   \n",
       "\n",
       "      review_headline                                        review_body  \\\n",
       "0  Outstanding Wallet  I have owned a lot of wallets over the years a...   \n",
       "1           Great cap  This is a very nice hat,but i have got another...   \n",
       "2        Great hat!!!  This is a great hat and is very well made!! I ...   \n",
       "3         Great pants  I have always been a Wrangler man most of my l...   \n",
       "4  Very Great socks!!  Wool is the only socks i wear and the only thi...   \n",
       "\n",
       "  review_date  year  \n",
       "0  2013-07-11  2013  \n",
       "1  2013-05-11  2013  \n",
       "2  2013-04-13  2013  \n",
       "3  2012-12-08  2012  \n",
       "4  2012-12-08  2012  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "user_item = './amz-review-apparel.csv'\n",
    "\n",
    "user_item_df = pd.read_csv(user_item)\n",
    "user_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from preprocessing.amz_datareader import AMZComprehendDataReader\n",
    "from preprocessing.factorization_machine_transformer import  FactorizationMachineTransformer\n",
    "\n",
    "\n",
    "user_item = './amz-review-apparel.csv'\n",
    "comprehend_item_data = './item-topics.csv'\n",
    "reader = AMZComprehendDataReader()\n",
    "user_item  = reader.read_user_item_rating(user_item)\n",
    "users = {}\n",
    "items = reader.read_item_data(comprehend_item_data)\n",
    "train_user_item = user_item[:int(len(user_item)*0.8)]\n",
    "test_user_item = user_item[int(len(user_item)*0.8):]\n",
    "transformer = FactorizationMachineTransformer(users, items, train_user_item)\n",
    "X_train, Y_train, _, _, nFeatures = transformer.get_feature_vectors(users, items, train_user_item)\n",
    "X_test, Y_test, X_test_cold, Y_test_cold, testnFeature = transformer.get_feature_vectors(users, items, test_user_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1299471, 980914)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.BytesIO object at 0x7fbc9316ffc0>\n",
      "Output: s3://recommendation-demo-yianc/sagemaker/fm-amz-comprehend/output\n"
     ]
    }
   ],
   "source": [
    "bucket = 'recommendation-demo-yianc'\n",
    "prefix = 'sagemaker/fm-amz-comprehend'\n",
    "train_key      = 'train.protobuf'\n",
    "train_prefix   = '{}/{}'.format(prefix, 'train')\n",
    "test_key       = 'test.protobuf'\n",
    "test_prefix    = '{}/{}/'.format(prefix, 'test')\n",
    "output_prefix  = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "\n",
    "def writeDatasetToProtobuf(X, Y, bucket, prefix, key):\n",
    "    import io,boto3\n",
    "    import sagemaker.amazon.common as smac\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_spmatrix_to_sparse_tensor(buf, X, Y)\n",
    "    buf.seek(0)\n",
    "    print(buf)\n",
    "    obj = '{}/{}'.format(prefix, key)\n",
    "    boto3.resource('s3').Bucket(bucket).Object(obj).upload_fileobj(buf)\n",
    "    return 's3://{}/{}'.format(bucket,obj)\n",
    " \n",
    "    \n",
    "train_data = writeDatasetToProtobuf(X_train, Y_train, bucket, train_prefix, train_key)    \n",
    "  \n",
    "print('Output: {}'.format(output_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://recommendation-demo-yianc/sagemaker/fm-amz-comprehend/train/train.protobuf'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'382416733822.dkr.ecr.us-east-1.amazonaws.com/factorization-machines:latest'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3 \n",
    "import sagemaker \n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "container = get_image_uri(region, 'factorization-machines', 'latest')\n",
    "container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sagemaker.estimator.Estimator'>\n",
      "2020-08-16 06:16:13 Starting - Starting the training job...\n",
      "2020-08-16 06:16:16 Starting - Launching requested ML instances.........\n",
      "2020-08-16 06:17:56 Starting - Preparing the instances for training......\n",
      "2020-08-16 06:19:00 Downloading - Downloading input data...\n",
      "2020-08-16 06:19:42 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python2.7/site-packages/pandas/util/nosetester.py:13: DeprecationWarning: Importing from numpy.testing.nosetester is deprecated, import from numpy.testing instead.\n",
      "  from numpy.testing import nosetester\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:19:44 INFO 140645090101056] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': 1, u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:19:44 INFO 140645090101056] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'epochs': u'50', u'feature_dim': u'980914', u'mini_batch_size': u'1000', u'predictor_type': u'regressor', u'num_factors': u'64'}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:19:44 INFO 140645090101056] Final configuration: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': u'50', u'feature_dim': u'980914', u'num_factors': u'64', u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'predictor_type': u'regressor', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:19:44 WARNING 140645090101056] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:19:44 INFO 140645090101056] Using default worker.\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:19:45.002] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 6, \"num_examples\": 1, \"num_bytes\": 72008}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:19:45 INFO 140645090101056] nvidia-smi took: 0.0252211093903 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:19:45 INFO 140645090101056] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:19:45 INFO 140645090101056] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:19:45 INFO 140645090101056] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 37.05310821533203, \"sum\": 37.05310821533203, \"min\": 37.05310821533203}}, \"EndTime\": 1597558785.037176, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597558784.99487}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1597558785.037358, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597558785.037323}\n",
      "\u001b[0m\n",
      "\u001b[34m[06:19:45] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.203343.0/AL2012/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[06:19:45] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.203343.0/AL2012/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:19:47 INFO 140645090101056] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=4.3650757976\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:19:47 INFO 140645090101056] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=19.0538867188\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:19:47 INFO 140645090101056] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=4.18247949219\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:19:56 INFO 140645090101056] Iter[0] Batch [500]#011Speed: 54988.56 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:19:56 INFO 140645090101056] #quality_metric: host=algo-1, epoch=0, batch=500 train rmse <loss>=1.36165083269\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:19:56 INFO 140645090101056] #quality_metric: host=algo-1, epoch=0, batch=500 train mse <loss>=1.85409299017\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:19:56 INFO 140645090101056] #quality_metric: host=algo-1, epoch=0, batch=500 train absolute_loss <loss>=1.05452175544\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:05 INFO 140645090101056] Iter[0] Batch [1000]#011Speed: 57281.79 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:05 INFO 140645090101056] #quality_metric: host=algo-1, epoch=0, batch=1000 train rmse <loss>=1.25031386795\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:05 INFO 140645090101056] #quality_metric: host=algo-1, epoch=0, batch=1000 train mse <loss>=1.56328476839\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:05 INFO 140645090101056] #quality_metric: host=algo-1, epoch=0, batch=1000 train absolute_loss <loss>=0.980482451691\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:20:10.598] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 23762, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=1.22977702124\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=0, train mse <loss>=1.51235152198\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=0.967748424213\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 50, \"sum\": 50.0, \"min\": 50}, \"update.time\": {\"count\": 1, \"max\": 25561.66982650757, \"sum\": 25561.66982650757, \"min\": 25561.66982650757}}, \"EndTime\": 1597558810.599274, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597558785.037249}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:10 INFO 140645090101056] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1301, \"sum\": 1301.0, \"min\": 1301}, \"Total Records Seen\": {\"count\": 1, \"max\": 1300471, \"sum\": 1300471.0, \"min\": 1300471}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1597558810.599501, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 0}, \"StartTime\": 1597558785.037573}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:10 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=50835.9920417 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=1.24326157377\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=1.54569934082\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=0.995204101563\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:19 INFO 140645090101056] Iter[1] Batch [500]#011Speed: 57633.76 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:19 INFO 140645090101056] #quality_metric: host=algo-1, epoch=1, batch=500 train rmse <loss>=1.13876979397\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:19 INFO 140645090101056] #quality_metric: host=algo-1, epoch=1, batch=500 train mse <loss>=1.29679664365\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:19 INFO 140645090101056] #quality_metric: host=algo-1, epoch=1, batch=500 train absolute_loss <loss>=0.912475657815\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/16/2020 06:20:27 INFO 140645090101056] Iter[1] Batch [1000]#011Speed: 58129.59 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:27 INFO 140645090101056] #quality_metric: host=algo-1, epoch=1, batch=1000 train rmse <loss>=1.1218446303\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:27 INFO 140645090101056] #quality_metric: host=algo-1, epoch=1, batch=1000 train mse <loss>=1.25853537454\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:27 INFO 140645090101056] #quality_metric: host=algo-1, epoch=1, batch=1000 train absolute_loss <loss>=0.896873247907\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:20:33.024] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 22422, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:33 INFO 140645090101056] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=1.12382486489\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:33 INFO 140645090101056] #quality_metric: host=algo-1, epoch=1, train mse <loss>=1.26298232694\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:33 INFO 140645090101056] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=0.896766318359\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22424.907207489014, \"sum\": 22424.907207489014, \"min\": 22424.907207489014}}, \"EndTime\": 1597558833.025655, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597558810.599355}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:33 INFO 140645090101056] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2601, \"sum\": 2601.0, \"min\": 2601}, \"Total Records Seen\": {\"count\": 1, \"max\": 2599942, \"sum\": 2599942.0, \"min\": 2599942}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1597558833.025866, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 1}, \"StartTime\": 1597558810.600719}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:33 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=57946.75581 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:33 INFO 140645090101056] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=1.22534095223\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:33 INFO 140645090101056] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=1.50146044922\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:33 INFO 140645090101056] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=0.981154602051\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:41 INFO 140645090101056] Iter[2] Batch [500]#011Speed: 57989.41 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:41 INFO 140645090101056] #quality_metric: host=algo-1, epoch=2, batch=500 train rmse <loss>=1.10089159316\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:41 INFO 140645090101056] #quality_metric: host=algo-1, epoch=2, batch=500 train mse <loss>=1.21196229989\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:41 INFO 140645090101056] #quality_metric: host=algo-1, epoch=2, batch=500 train absolute_loss <loss>=0.87395161642\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:50 INFO 140645090101056] Iter[2] Batch [1000]#011Speed: 58316.04 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:50 INFO 140645090101056] #quality_metric: host=algo-1, epoch=2, batch=1000 train rmse <loss>=1.08155538545\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:50 INFO 140645090101056] #quality_metric: host=algo-1, epoch=2, batch=1000 train mse <loss>=1.16976205179\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:50 INFO 140645090101056] #quality_metric: host=algo-1, epoch=2, batch=1000 train absolute_loss <loss>=0.855013087316\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:20:55.444] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 22417, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=1.08220602236\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=2, train mse <loss>=1.17116987483\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=0.853677808697\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22419.070959091187, \"sum\": 22419.070959091187, \"min\": 22419.070959091187}}, \"EndTime\": 1597558855.445189, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597558833.025733}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:55 INFO 140645090101056] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3901, \"sum\": 3901.0, \"min\": 3901}, \"Total Records Seen\": {\"count\": 1, \"max\": 3899413, \"sum\": 3899413.0, \"min\": 3899413}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1597558855.445398, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 2}, \"StartTime\": 1597558833.026089}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:55 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=57961.8344084 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=1.190277334\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=3, batch=0 train mse <loss>=1.41676013184\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:20:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=3, batch=0 train absolute_loss <loss>=0.946620117188\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:04 INFO 140645090101056] Iter[3] Batch [500]#011Speed: 57755.13 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:04 INFO 140645090101056] #quality_metric: host=algo-1, epoch=3, batch=500 train rmse <loss>=1.04959792016\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:04 INFO 140645090101056] #quality_metric: host=algo-1, epoch=3, batch=500 train mse <loss>=1.101655794\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:04 INFO 140645090101056] #quality_metric: host=algo-1, epoch=3, batch=500 train absolute_loss <loss>=0.823366962973\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:12 INFO 140645090101056] Iter[3] Batch [1000]#011Speed: 59209.07 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:12 INFO 140645090101056] #quality_metric: host=algo-1, epoch=3, batch=1000 train rmse <loss>=1.02981954979\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:12 INFO 140645090101056] #quality_metric: host=algo-1, epoch=3, batch=1000 train mse <loss>=1.06052830513\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:12 INFO 140645090101056] #quality_metric: host=algo-1, epoch=3, batch=1000 train absolute_loss <loss>=0.803293343802\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:21:17.649] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 22202, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=1.02990150025\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=3, train mse <loss>=1.06069710022\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=3, train absolute_loss <loss>=0.801498585158\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22204.7438621521, \"sum\": 22204.7438621521, \"min\": 22204.7438621521}}, \"EndTime\": 1597558877.650432, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597558855.445265}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:17 INFO 140645090101056] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5201, \"sum\": 5201.0, \"min\": 5201}, \"Total Records Seen\": {\"count\": 1, \"max\": 5198884, \"sum\": 5198884.0, \"min\": 5198884}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1597558877.650664, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 3}, \"StartTime\": 1597558855.44566}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:17 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58521.2327125 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=1.14626079858\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=4, batch=0 train mse <loss>=1.31391381836\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=4, batch=0 train absolute_loss <loss>=0.903055419922\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/16/2020 06:21:26 INFO 140645090101056] Iter[4] Batch [500]#011Speed: 57646.12 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:26 INFO 140645090101056] #quality_metric: host=algo-1, epoch=4, batch=500 train rmse <loss>=0.995162035204\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:26 INFO 140645090101056] #quality_metric: host=algo-1, epoch=4, batch=500 train mse <loss>=0.990347476312\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:26 INFO 140645090101056] #quality_metric: host=algo-1, epoch=4, batch=500 train absolute_loss <loss>=0.770380065796\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:34 INFO 140645090101056] Iter[4] Batch [1000]#011Speed: 59323.23 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:34 INFO 140645090101056] #quality_metric: host=algo-1, epoch=4, batch=1000 train rmse <loss>=0.975908947893\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:34 INFO 140645090101056] #quality_metric: host=algo-1, epoch=4, batch=1000 train mse <loss>=0.952398274577\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:34 INFO 140645090101056] #quality_metric: host=algo-1, epoch=4, batch=1000 train absolute_loss <loss>=0.750889548562\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:21:39.827] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 22173, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:39 INFO 140645090101056] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=0.975680758354\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:39 INFO 140645090101056] #quality_metric: host=algo-1, epoch=4, train mse <loss>=0.951952942223\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:39 INFO 140645090101056] #quality_metric: host=algo-1, epoch=4, train absolute_loss <loss>=0.748970962102\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22175.517797470093, \"sum\": 22175.517797470093, \"min\": 22175.517797470093}}, \"EndTime\": 1597558899.827551, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597558877.650525}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:39 INFO 140645090101056] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6501, \"sum\": 6501.0, \"min\": 6501}, \"Total Records Seen\": {\"count\": 1, \"max\": 6498355, \"sum\": 6498355.0, \"min\": 6498355}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1597558899.82776, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 4}, \"StartTime\": 1597558877.652006}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:39 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58598.456694 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:39 INFO 140645090101056] #quality_metric: host=algo-1, epoch=5, batch=0 train rmse <loss>=1.09726994982\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:39 INFO 140645090101056] #quality_metric: host=algo-1, epoch=5, batch=0 train mse <loss>=1.20400134277\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:39 INFO 140645090101056] #quality_metric: host=algo-1, epoch=5, batch=0 train absolute_loss <loss>=0.853022460938\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:48 INFO 140645090101056] Iter[5] Batch [500]#011Speed: 58171.91 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:48 INFO 140645090101056] #quality_metric: host=algo-1, epoch=5, batch=500 train rmse <loss>=0.94354260313\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:48 INFO 140645090101056] #quality_metric: host=algo-1, epoch=5, batch=500 train mse <loss>=0.890272643921\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:48 INFO 140645090101056] #quality_metric: host=algo-1, epoch=5, batch=500 train absolute_loss <loss>=0.719447330071\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:56 INFO 140645090101056] Iter[5] Batch [1000]#011Speed: 58593.56 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:56 INFO 140645090101056] #quality_metric: host=algo-1, epoch=5, batch=1000 train rmse <loss>=0.925093257716\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:56 INFO 140645090101056] #quality_metric: host=algo-1, epoch=5, batch=1000 train mse <loss>=0.855797535472\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:21:56 INFO 140645090101056] #quality_metric: host=algo-1, epoch=5, batch=1000 train absolute_loss <loss>=0.701555119502\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:22:02.177] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 22346, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:02 INFO 140645090101056] #quality_metric: host=algo-1, epoch=5, train rmse <loss>=0.924567642522\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:02 INFO 140645090101056] #quality_metric: host=algo-1, epoch=5, train mse <loss>=0.854825325599\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:02 INFO 140645090101056] #quality_metric: host=algo-1, epoch=5, train absolute_loss <loss>=0.69965896752\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22348.47593307495, \"sum\": 22348.47593307495, \"min\": 22348.47593307495}}, \"EndTime\": 1597558922.17765, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597558899.827621}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:02 INFO 140645090101056] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7801, \"sum\": 7801.0, \"min\": 7801}, \"Total Records Seen\": {\"count\": 1, \"max\": 7797826, \"sum\": 7797826.0, \"min\": 7797826}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1597558922.177887, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 5}, \"StartTime\": 1597558899.829146}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:02 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58144.8653755 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:02 INFO 140645090101056] #quality_metric: host=algo-1, epoch=6, batch=0 train rmse <loss>=1.04554474718\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:02 INFO 140645090101056] #quality_metric: host=algo-1, epoch=6, batch=0 train mse <loss>=1.09316381836\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:02 INFO 140645090101056] #quality_metric: host=algo-1, epoch=6, batch=0 train absolute_loss <loss>=0.798100952148\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:10 INFO 140645090101056] Iter[6] Batch [500]#011Speed: 57650.92 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=6, batch=500 train rmse <loss>=0.896864481043\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=6, batch=500 train mse <loss>=0.804365897356\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=6, batch=500 train absolute_loss <loss>=0.673601582601\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:19 INFO 140645090101056] Iter[6] Batch [1000]#011Speed: 58538.90 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:19 INFO 140645090101056] #quality_metric: host=algo-1, epoch=6, batch=1000 train rmse <loss>=0.879242419233\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:19 INFO 140645090101056] #quality_metric: host=algo-1, epoch=6, batch=1000 train mse <loss>=0.773067231779\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:19 INFO 140645090101056] #quality_metric: host=algo-1, epoch=6, batch=1000 train absolute_loss <loss>=0.657454469176\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:22:24.574] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 22395, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:24 INFO 140645090101056] #quality_metric: host=algo-1, epoch=6, train rmse <loss>=0.878372232826\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:24 INFO 140645090101056] #quality_metric: host=algo-1, epoch=6, train mse <loss>=0.7715377794\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:24 INFO 140645090101056] #quality_metric: host=algo-1, epoch=6, train absolute_loss <loss>=0.655572558265\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22397.403955459595, \"sum\": 22397.403955459595, \"min\": 22397.403955459595}}, \"EndTime\": 1597558944.57555, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597558922.177752}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:24 INFO 140645090101056] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 9101, \"sum\": 9101.0, \"min\": 9101}, \"Total Records Seen\": {\"count\": 1, \"max\": 9097297, \"sum\": 9097297.0, \"min\": 9097297}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1597558944.575802, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 6}, \"StartTime\": 1597558922.178112}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:24 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58017.7266848 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:24 INFO 140645090101056] #quality_metric: host=algo-1, epoch=7, batch=0 train rmse <loss>=0.993209211886\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:24 INFO 140645090101056] #quality_metric: host=algo-1, epoch=7, batch=0 train mse <loss>=0.986464538574\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:24 INFO 140645090101056] #quality_metric: host=algo-1, epoch=7, batch=0 train absolute_loss <loss>=0.739305358887\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/16/2020 06:22:33 INFO 140645090101056] Iter[7] Batch [500]#011Speed: 58023.89 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:33 INFO 140645090101056] #quality_metric: host=algo-1, epoch=7, batch=500 train rmse <loss>=0.854954356345\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:33 INFO 140645090101056] #quality_metric: host=algo-1, epoch=7, batch=500 train mse <loss>=0.730946951434\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:33 INFO 140645090101056] #quality_metric: host=algo-1, epoch=7, batch=500 train absolute_loss <loss>=0.633379722793\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:41 INFO 140645090101056] Iter[7] Batch [1000]#011Speed: 58473.51 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:41 INFO 140645090101056] #quality_metric: host=algo-1, epoch=7, batch=1000 train rmse <loss>=0.838173955122\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:41 INFO 140645090101056] #quality_metric: host=algo-1, epoch=7, batch=1000 train mse <loss>=0.702535579045\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:41 INFO 140645090101056] #quality_metric: host=algo-1, epoch=7, batch=1000 train absolute_loss <loss>=0.618795413784\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:22:46.853] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 22275, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=7, train rmse <loss>=0.836937637013\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=7, train mse <loss>=0.700464608248\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=7, train absolute_loss <loss>=0.61689306751\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22277.842044830322, \"sum\": 22277.842044830322, \"min\": 22277.842044830322}}, \"EndTime\": 1597558966.853965, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597558944.575632}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:46 INFO 140645090101056] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 10401, \"sum\": 10401.0, \"min\": 10401}, \"Total Records Seen\": {\"count\": 1, \"max\": 10396768, \"sum\": 10396768.0, \"min\": 10396768}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1597558966.854172, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 7}, \"StartTime\": 1597558944.576092}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:46 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58329.2007703 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=8, batch=0 train rmse <loss>=0.942016853328\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=8, batch=0 train mse <loss>=0.887395751953\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=8, batch=0 train absolute_loss <loss>=0.682314331055\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:55 INFO 140645090101056] Iter[8] Batch [500]#011Speed: 57661.09 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=8, batch=500 train rmse <loss>=0.816765130758\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=8, batch=500 train mse <loss>=0.667105278822\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:22:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=8, batch=500 train absolute_loss <loss>=0.597761856414\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:04 INFO 140645090101056] Iter[8] Batch [1000]#011Speed: 58500.37 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:04 INFO 140645090101056] #quality_metric: host=algo-1, epoch=8, batch=1000 train rmse <loss>=0.800956068161\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:04 INFO 140645090101056] #quality_metric: host=algo-1, epoch=8, batch=1000 train mse <loss>=0.641530623124\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:04 INFO 140645090101056] #quality_metric: host=algo-1, epoch=8, batch=1000 train absolute_loss <loss>=0.584537582352\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:23:09.147] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 22291, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:09 INFO 140645090101056] #quality_metric: host=algo-1, epoch=8, train rmse <loss>=0.79939620925\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:09 INFO 140645090101056] #quality_metric: host=algo-1, epoch=8, train mse <loss>=0.639034299363\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:09 INFO 140645090101056] #quality_metric: host=algo-1, epoch=8, train absolute_loss <loss>=0.582525063054\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22293.63512992859, \"sum\": 22293.63512992859, \"min\": 22293.63512992859}}, \"EndTime\": 1597558989.148078, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597558966.85404}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:09 INFO 140645090101056] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 11701, \"sum\": 11701.0, \"min\": 11701}, \"Total Records Seen\": {\"count\": 1, \"max\": 11696239, \"sum\": 11696239.0, \"min\": 11696239}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1597558989.148291, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 8}, \"StartTime\": 1597558966.854413}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:09 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58287.9539107 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:09 INFO 140645090101056] #quality_metric: host=algo-1, epoch=9, batch=0 train rmse <loss>=0.89317634152\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:09 INFO 140645090101056] #quality_metric: host=algo-1, epoch=9, batch=0 train mse <loss>=0.797763977051\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:09 INFO 140645090101056] #quality_metric: host=algo-1, epoch=9, batch=0 train absolute_loss <loss>=0.628723937988\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:17 INFO 140645090101056] Iter[9] Batch [500]#011Speed: 57645.18 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=9, batch=500 train rmse <loss>=0.781377288003\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=9, batch=500 train mse <loss>=0.610550466206\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=9, batch=500 train absolute_loss <loss>=0.565271857043\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:26 INFO 140645090101056] Iter[9] Batch [1000]#011Speed: 58448.58 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:26 INFO 140645090101056] #quality_metric: host=algo-1, epoch=9, batch=1000 train rmse <loss>=0.766767657489\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:26 INFO 140645090101056] #quality_metric: host=algo-1, epoch=9, batch=1000 train mse <loss>=0.587932640571\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:26 INFO 140645090101056] #quality_metric: host=algo-1, epoch=9, batch=1000 train absolute_loss <loss>=0.553321442961\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:23:31.503] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 22352, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:31 INFO 140645090101056] #quality_metric: host=algo-1, epoch=9, train rmse <loss>=0.764980002363\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:31 INFO 140645090101056] #quality_metric: host=algo-1, epoch=9, train mse <loss>=0.585194404015\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:31 INFO 140645090101056] #quality_metric: host=algo-1, epoch=9, train absolute_loss <loss>=0.551227467205\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22354.132890701294, \"sum\": 22354.132890701294, \"min\": 22354.132890701294}}, \"EndTime\": 1597559011.503877, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597558989.148155}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:31 INFO 140645090101056] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 13001, \"sum\": 13001.0, \"min\": 13001}, \"Total Records Seen\": {\"count\": 1, \"max\": 12995710, \"sum\": 12995710.0, \"min\": 12995710}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1597559011.504112, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 9}, \"StartTime\": 1597558989.149712}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:31 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58130.1229105 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:31 INFO 140645090101056] #quality_metric: host=algo-1, epoch=10, batch=0 train rmse <loss>=0.847157219177\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:31 INFO 140645090101056] #quality_metric: host=algo-1, epoch=10, batch=0 train mse <loss>=0.717675354004\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:31 INFO 140645090101056] #quality_metric: host=algo-1, epoch=10, batch=0 train absolute_loss <loss>=0.576922912598\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/16/2020 06:23:40 INFO 140645090101056] Iter[10] Batch [500]#011Speed: 58176.83 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:40 INFO 140645090101056] #quality_metric: host=algo-1, epoch=10, batch=500 train rmse <loss>=0.748333549645\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:40 INFO 140645090101056] #quality_metric: host=algo-1, epoch=10, batch=500 train mse <loss>=0.560003101524\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:40 INFO 140645090101056] #quality_metric: host=algo-1, epoch=10, batch=500 train absolute_loss <loss>=0.535135433174\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:48 INFO 140645090101056] Iter[10] Batch [1000]#011Speed: 58818.78 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:48 INFO 140645090101056] #quality_metric: host=algo-1, epoch=10, batch=1000 train rmse <loss>=0.735161376282\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:48 INFO 140645090101056] #quality_metric: host=algo-1, epoch=10, batch=1000 train mse <loss>=0.540462249177\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:48 INFO 140645090101056] #quality_metric: host=algo-1, epoch=10, batch=1000 train absolute_loss <loss>=0.524877513935\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:23:53.750] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 22243, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:53 INFO 140645090101056] #quality_metric: host=algo-1, epoch=10, train rmse <loss>=0.733262074956\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:53 INFO 140645090101056] #quality_metric: host=algo-1, epoch=10, train mse <loss>=0.537673270569\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:53 INFO 140645090101056] #quality_metric: host=algo-1, epoch=10, train absolute_loss <loss>=0.522829591088\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22245.51010131836, \"sum\": 22245.51010131836, \"min\": 22245.51010131836}}, \"EndTime\": 1597559033.751102, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559011.503954}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:53 INFO 140645090101056] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 14301, \"sum\": 14301.0, \"min\": 14301}, \"Total Records Seen\": {\"count\": 1, \"max\": 14295181, \"sum\": 14295181.0, \"min\": 14295181}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}}, \"EndTime\": 1597559033.751298, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 10}, \"StartTime\": 1597559011.505564}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:53 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58414.1229334 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:53 INFO 140645090101056] #quality_metric: host=algo-1, epoch=11, batch=0 train rmse <loss>=0.803876829211\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:53 INFO 140645090101056] #quality_metric: host=algo-1, epoch=11, batch=0 train mse <loss>=0.646217956543\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:23:53 INFO 140645090101056] #quality_metric: host=algo-1, epoch=11, batch=0 train absolute_loss <loss>=0.534432739258\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:02 INFO 140645090101056] Iter[11] Batch [500]#011Speed: 58322.02 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:02 INFO 140645090101056] #quality_metric: host=algo-1, epoch=11, batch=500 train rmse <loss>=0.717508374655\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:02 INFO 140645090101056] #quality_metric: host=algo-1, epoch=11, batch=500 train mse <loss>=0.5148182677\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:02 INFO 140645090101056] #quality_metric: host=algo-1, epoch=11, batch=500 train absolute_loss <loss>=0.50755954077\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:10 INFO 140645090101056] Iter[11] Batch [1000]#011Speed: 59126.59 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=11, batch=1000 train rmse <loss>=0.705955287282\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=11, batch=1000 train mse <loss>=0.498372867641\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=11, batch=1000 train absolute_loss <loss>=0.499052062287\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:24:15.893] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 22139, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:15 INFO 140645090101056] #quality_metric: host=algo-1, epoch=11, train rmse <loss>=0.704058670344\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:15 INFO 140645090101056] #quality_metric: host=algo-1, epoch=11, train mse <loss>=0.495698611286\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:15 INFO 140645090101056] #quality_metric: host=algo-1, epoch=11, train absolute_loss <loss>=0.497107770339\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22141.61515235901, \"sum\": 22141.61515235901, \"min\": 22141.61515235901}}, \"EndTime\": 1597559055.894432, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559033.751171}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:15 INFO 140645090101056] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 15601, \"sum\": 15601.0, \"min\": 15601}, \"Total Records Seen\": {\"count\": 1, \"max\": 15594652, \"sum\": 15594652.0, \"min\": 15594652}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1597559055.894671, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 11}, \"StartTime\": 1597559033.752786}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:15 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58688.1120814 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:15 INFO 140645090101056] #quality_metric: host=algo-1, epoch=12, batch=0 train rmse <loss>=0.763309876638\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:15 INFO 140645090101056] #quality_metric: host=algo-1, epoch=12, batch=0 train mse <loss>=0.582641967773\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:15 INFO 140645090101056] #quality_metric: host=algo-1, epoch=12, batch=0 train absolute_loss <loss>=0.492844726563\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:24 INFO 140645090101056] Iter[12] Batch [500]#011Speed: 57646.89 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:24 INFO 140645090101056] #quality_metric: host=algo-1, epoch=12, batch=500 train rmse <loss>=0.688904198433\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:24 INFO 140645090101056] #quality_metric: host=algo-1, epoch=12, batch=500 train mse <loss>=0.474588994618\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:24 INFO 140645090101056] #quality_metric: host=algo-1, epoch=12, batch=500 train absolute_loss <loss>=0.482360150853\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:33 INFO 140645090101056] Iter[12] Batch [1000]#011Speed: 58856.01 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:33 INFO 140645090101056] #quality_metric: host=algo-1, epoch=12, batch=1000 train rmse <loss>=0.679089235229\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:33 INFO 140645090101056] #quality_metric: host=algo-1, epoch=12, batch=1000 train mse <loss>=0.461162189404\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:33 INFO 140645090101056] #quality_metric: host=algo-1, epoch=12, batch=1000 train absolute_loss <loss>=0.4754183224\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:24:38.057] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 22159, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:38 INFO 140645090101056] #quality_metric: host=algo-1, epoch=12, train rmse <loss>=0.677311200046\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:38 INFO 140645090101056] #quality_metric: host=algo-1, epoch=12, train mse <loss>=0.458750461707\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:38 INFO 140645090101056] #quality_metric: host=algo-1, epoch=12, train absolute_loss <loss>=0.473629338215\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22161.877870559692, \"sum\": 22161.877870559692, \"min\": 22161.877870559692}}, \"EndTime\": 1597559078.058098, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559055.894492}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:38 INFO 140645090101056] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 16901, \"sum\": 16901.0, \"min\": 16901}, \"Total Records Seen\": {\"count\": 1, \"max\": 16894123, \"sum\": 16894123.0, \"min\": 16894123}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 14, \"sum\": 14.0, \"min\": 14}}, \"EndTime\": 1597559078.058332, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 12}, \"StartTime\": 1597559055.89619}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:38 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58634.4396158 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:38 INFO 140645090101056] #quality_metric: host=algo-1, epoch=13, batch=0 train rmse <loss>=0.726330734204\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:38 INFO 140645090101056] #quality_metric: host=algo-1, epoch=13, batch=0 train mse <loss>=0.527556335449\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:38 INFO 140645090101056] #quality_metric: host=algo-1, epoch=13, batch=0 train absolute_loss <loss>=0.452205078125\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/16/2020 06:24:46 INFO 140645090101056] Iter[13] Batch [500]#011Speed: 58061.06 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=13, batch=500 train rmse <loss>=0.662615156686\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=13, batch=500 train mse <loss>=0.43905884587\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=13, batch=500 train absolute_loss <loss>=0.459650241875\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:55 INFO 140645090101056] Iter[13] Batch [1000]#011Speed: 58620.64 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=13, batch=1000 train rmse <loss>=0.654654414427\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=13, batch=1000 train mse <loss>=0.428572402329\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:24:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=13, batch=1000 train absolute_loss <loss>=0.454499358277\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:25:00.367] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 22305, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:00 INFO 140645090101056] #quality_metric: host=algo-1, epoch=13, train rmse <loss>=0.653146848109\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:00 INFO 140645090101056] #quality_metric: host=algo-1, epoch=13, train mse <loss>=0.426600805195\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:00 INFO 140645090101056] #quality_metric: host=algo-1, epoch=13, train absolute_loss <loss>=0.453189027499\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22308.106184005737, \"sum\": 22308.106184005737, \"min\": 22308.106184005737}}, \"EndTime\": 1597559100.367995, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559078.058177}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:00 INFO 140645090101056] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 18201, \"sum\": 18201.0, \"min\": 18201}, \"Total Records Seen\": {\"count\": 1, \"max\": 18193594, \"sum\": 18193594.0, \"min\": 18193594}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1597559100.36826, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 13}, \"StartTime\": 1597559078.059856}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:00 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58249.8174655 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:00 INFO 140645090101056] #quality_metric: host=algo-1, epoch=14, batch=0 train rmse <loss>=0.694788975136\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:00 INFO 140645090101056] #quality_metric: host=algo-1, epoch=14, batch=0 train mse <loss>=0.482731719971\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:00 INFO 140645090101056] #quality_metric: host=algo-1, epoch=14, batch=0 train absolute_loss <loss>=0.424412841797\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:09 INFO 140645090101056] Iter[14] Batch [500]#011Speed: 57267.08 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:09 INFO 140645090101056] #quality_metric: host=algo-1, epoch=14, batch=500 train rmse <loss>=0.639314373836\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:09 INFO 140645090101056] #quality_metric: host=algo-1, epoch=14, batch=500 train mse <loss>=0.408722868594\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:09 INFO 140645090101056] #quality_metric: host=algo-1, epoch=14, batch=500 train absolute_loss <loss>=0.440752863779\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:17 INFO 140645090101056] Iter[14] Batch [1000]#011Speed: 58665.38 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=14, batch=1000 train rmse <loss>=0.633491916791\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=14, batch=1000 train mse <loss>=0.40131200864\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=14, batch=1000 train absolute_loss <loss>=0.437977592872\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:25:22.764] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 22393, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:22 INFO 140645090101056] #quality_metric: host=algo-1, epoch=14, train rmse <loss>=0.632120057426\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:22 INFO 140645090101056] #quality_metric: host=algo-1, epoch=14, train mse <loss>=0.399575767001\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:22 INFO 140645090101056] #quality_metric: host=algo-1, epoch=14, train absolute_loss <loss>=0.43718887031\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22395.265817642212, \"sum\": 22395.265817642212, \"min\": 22395.265817642212}}, \"EndTime\": 1597559122.765262, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559100.368098}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:22 INFO 140645090101056] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 19501, \"sum\": 19501.0, \"min\": 19501}, \"Total Records Seen\": {\"count\": 1, \"max\": 19493065, \"sum\": 19493065.0, \"min\": 19493065}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 16, \"sum\": 16.0, \"min\": 16}}, \"EndTime\": 1597559122.765469, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 14}, \"StartTime\": 1597559100.369968}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:22 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58023.3478469 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:22 INFO 140645090101056] #quality_metric: host=algo-1, epoch=15, batch=0 train rmse <loss>=0.653781163365\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:22 INFO 140645090101056] #quality_metric: host=algo-1, epoch=15, batch=0 train mse <loss>=0.42742980957\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:22 INFO 140645090101056] #quality_metric: host=algo-1, epoch=15, batch=0 train absolute_loss <loss>=0.399422393799\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:31 INFO 140645090101056] Iter[15] Batch [500]#011Speed: 58145.40 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:31 INFO 140645090101056] #quality_metric: host=algo-1, epoch=15, batch=500 train rmse <loss>=0.620281179263\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:31 INFO 140645090101056] #quality_metric: host=algo-1, epoch=15, batch=500 train mse <loss>=0.384748741348\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:31 INFO 140645090101056] #quality_metric: host=algo-1, epoch=15, batch=500 train absolute_loss <loss>=0.427594445387\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:39 INFO 140645090101056] Iter[15] Batch [1000]#011Speed: 58859.02 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:39 INFO 140645090101056] #quality_metric: host=algo-1, epoch=15, batch=1000 train rmse <loss>=0.615617034603\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:39 INFO 140645090101056] #quality_metric: host=algo-1, epoch=15, batch=1000 train mse <loss>=0.378984333294\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:39 INFO 140645090101056] #quality_metric: host=algo-1, epoch=15, batch=1000 train absolute_loss <loss>=0.425740555221\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:25:44.994] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 22225, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:44 INFO 140645090101056] #quality_metric: host=algo-1, epoch=15, train rmse <loss>=0.613802752953\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:44 INFO 140645090101056] #quality_metric: host=algo-1, epoch=15, train mse <loss>=0.376753819533\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:44 INFO 140645090101056] #quality_metric: host=algo-1, epoch=15, train absolute_loss <loss>=0.424336091778\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22227.626085281372, \"sum\": 22227.626085281372, \"min\": 22227.626085281372}}, \"EndTime\": 1597559144.994759, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559122.765337}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:44 INFO 140645090101056] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 20801, \"sum\": 20801.0, \"min\": 20801}, \"Total Records Seen\": {\"count\": 1, \"max\": 20792536, \"sum\": 20792536.0, \"min\": 20792536}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 17, \"sum\": 17.0, \"min\": 17}}, \"EndTime\": 1597559144.994986, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 15}, \"StartTime\": 1597559122.767106}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:44 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58461.0266897 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:45 INFO 140645090101056] #quality_metric: host=algo-1, epoch=16, batch=0 train rmse <loss>=0.623676773085\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:45 INFO 140645090101056] #quality_metric: host=algo-1, epoch=16, batch=0 train mse <loss>=0.388972717285\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:45 INFO 140645090101056] #quality_metric: host=algo-1, epoch=16, batch=0 train absolute_loss <loss>=0.391819732666\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:53 INFO 140645090101056] Iter[16] Batch [500]#011Speed: 57690.64 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:53 INFO 140645090101056] #quality_metric: host=algo-1, epoch=16, batch=500 train rmse <loss>=0.602014533104\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:53 INFO 140645090101056] #quality_metric: host=algo-1, epoch=16, batch=500 train mse <loss>=0.362421498068\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:25:53 INFO 140645090101056] #quality_metric: host=algo-1, epoch=16, batch=500 train absolute_loss <loss>=0.414161432019\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/16/2020 06:26:02 INFO 140645090101056] Iter[16] Batch [1000]#011Speed: 58698.40 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:02 INFO 140645090101056] #quality_metric: host=algo-1, epoch=16, batch=1000 train rmse <loss>=0.597994883427\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:02 INFO 140645090101056] #quality_metric: host=algo-1, epoch=16, batch=1000 train mse <loss>=0.357597880605\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:02 INFO 140645090101056] #quality_metric: host=algo-1, epoch=16, batch=1000 train absolute_loss <loss>=0.412406789347\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:26:07.282] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 34, \"duration\": 22284, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:07 INFO 140645090101056] #quality_metric: host=algo-1, epoch=16, train rmse <loss>=0.596040071833\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:07 INFO 140645090101056] #quality_metric: host=algo-1, epoch=16, train mse <loss>=0.355263767231\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:07 INFO 140645090101056] #quality_metric: host=algo-1, epoch=16, train absolute_loss <loss>=0.410703936556\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22286.471128463745, \"sum\": 22286.471128463745, \"min\": 22286.471128463745}}, \"EndTime\": 1597559167.283103, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559144.994852}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:07 INFO 140645090101056] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 22101, \"sum\": 22101.0, \"min\": 22101}, \"Total Records Seen\": {\"count\": 1, \"max\": 22092007, \"sum\": 22092007.0, \"min\": 22092007}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 18, \"sum\": 18.0, \"min\": 18}}, \"EndTime\": 1597559167.283308, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 16}, \"StartTime\": 1597559144.996604}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:07 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58306.7084048 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:07 INFO 140645090101056] #quality_metric: host=algo-1, epoch=17, batch=0 train rmse <loss>=0.594545725021\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:07 INFO 140645090101056] #quality_metric: host=algo-1, epoch=17, batch=0 train mse <loss>=0.353484619141\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:07 INFO 140645090101056] #quality_metric: host=algo-1, epoch=17, batch=0 train absolute_loss <loss>=0.372927215576\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:15 INFO 140645090101056] Iter[17] Batch [500]#011Speed: 57913.38 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:15 INFO 140645090101056] #quality_metric: host=algo-1, epoch=17, batch=500 train rmse <loss>=0.584783858226\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:15 INFO 140645090101056] #quality_metric: host=algo-1, epoch=17, batch=500 train mse <loss>=0.341972160842\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:15 INFO 140645090101056] #quality_metric: host=algo-1, epoch=17, batch=500 train absolute_loss <loss>=0.400873529674\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:24 INFO 140645090101056] Iter[17] Batch [1000]#011Speed: 58287.21 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:24 INFO 140645090101056] #quality_metric: host=algo-1, epoch=17, batch=1000 train rmse <loss>=0.581575707842\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:24 INFO 140645090101056] #quality_metric: host=algo-1, epoch=17, batch=1000 train mse <loss>=0.338230303952\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:24 INFO 140645090101056] #quality_metric: host=algo-1, epoch=17, batch=1000 train absolute_loss <loss>=0.399511359795\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:26:29.584] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 36, \"duration\": 22297, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:29 INFO 140645090101056] #quality_metric: host=algo-1, epoch=17, train rmse <loss>=0.579630707841\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:29 INFO 140645090101056] #quality_metric: host=algo-1, epoch=17, train mse <loss>=0.335971757472\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:29 INFO 140645090101056] #quality_metric: host=algo-1, epoch=17, train absolute_loss <loss>=0.397723772395\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22299.787998199463, \"sum\": 22299.787998199463, \"min\": 22299.787998199463}}, \"EndTime\": 1597559189.584733, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559167.283172}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:29 INFO 140645090101056] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 23401, \"sum\": 23401.0, \"min\": 23401}, \"Total Records Seen\": {\"count\": 1, \"max\": 23391478, \"sum\": 23391478.0, \"min\": 23391478}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 19, \"sum\": 19.0, \"min\": 19}}, \"EndTime\": 1597559189.584923, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 17}, \"StartTime\": 1597559167.284917}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:29 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58271.9575616 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:29 INFO 140645090101056] #quality_metric: host=algo-1, epoch=18, batch=0 train rmse <loss>=0.566757703462\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:29 INFO 140645090101056] #quality_metric: host=algo-1, epoch=18, batch=0 train mse <loss>=0.321214294434\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:29 INFO 140645090101056] #quality_metric: host=algo-1, epoch=18, batch=0 train absolute_loss <loss>=0.35095501709\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:38 INFO 140645090101056] Iter[18] Batch [500]#011Speed: 58263.90 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:38 INFO 140645090101056] #quality_metric: host=algo-1, epoch=18, batch=500 train rmse <loss>=0.569297471949\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:38 INFO 140645090101056] #quality_metric: host=algo-1, epoch=18, batch=500 train mse <loss>=0.324099611568\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:38 INFO 140645090101056] #quality_metric: host=algo-1, epoch=18, batch=500 train absolute_loss <loss>=0.388991832436\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:46 INFO 140645090101056] Iter[18] Batch [1000]#011Speed: 58820.37 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=18, batch=1000 train rmse <loss>=0.566866333608\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=18, batch=1000 train mse <loss>=0.321337440178\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=18, batch=1000 train absolute_loss <loss>=0.388078057075\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:26:51.763] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 38, \"duration\": 22175, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:51 INFO 140645090101056] #quality_metric: host=algo-1, epoch=18, train rmse <loss>=0.564959945827\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:51 INFO 140645090101056] #quality_metric: host=algo-1, epoch=18, train mse <loss>=0.319179740389\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:51 INFO 140645090101056] #quality_metric: host=algo-1, epoch=18, train absolute_loss <loss>=0.38624218757\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22177.35505104065, \"sum\": 22177.35505104065, \"min\": 22177.35505104065}}, \"EndTime\": 1597559211.763947, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559189.584795}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:51 INFO 140645090101056] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 24701, \"sum\": 24701.0, \"min\": 24701}, \"Total Records Seen\": {\"count\": 1, \"max\": 24690949, \"sum\": 24690949.0, \"min\": 24690949}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}}, \"EndTime\": 1597559211.764187, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 18}, \"StartTime\": 1597559189.586561}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:51 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58593.4554897 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:51 INFO 140645090101056] #quality_metric: host=algo-1, epoch=19, batch=0 train rmse <loss>=0.542631921154\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:51 INFO 140645090101056] #quality_metric: host=algo-1, epoch=19, batch=0 train mse <loss>=0.294449401855\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:26:51 INFO 140645090101056] #quality_metric: host=algo-1, epoch=19, batch=0 train absolute_loss <loss>=0.333481933594\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/16/2020 06:27:00 INFO 140645090101056] Iter[19] Batch [500]#011Speed: 57273.62 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:00 INFO 140645090101056] #quality_metric: host=algo-1, epoch=19, batch=500 train rmse <loss>=0.556009864561\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:00 INFO 140645090101056] #quality_metric: host=algo-1, epoch=19, batch=500 train mse <loss>=0.309146969489\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:00 INFO 140645090101056] #quality_metric: host=algo-1, epoch=19, batch=500 train absolute_loss <loss>=0.379247585152\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:09 INFO 140645090101056] Iter[19] Batch [1000]#011Speed: 58221.33 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:09 INFO 140645090101056] #quality_metric: host=algo-1, epoch=19, batch=1000 train rmse <loss>=0.554080917273\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:09 INFO 140645090101056] #quality_metric: host=algo-1, epoch=19, batch=1000 train mse <loss>=0.307005662886\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:09 INFO 140645090101056] #quality_metric: host=algo-1, epoch=19, batch=1000 train absolute_loss <loss>=0.378572768571\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:27:14.185] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 40, \"duration\": 22417, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:14 INFO 140645090101056] #quality_metric: host=algo-1, epoch=19, train rmse <loss>=0.552154273173\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:14 INFO 140645090101056] #quality_metric: host=algo-1, epoch=19, train mse <loss>=0.304874341384\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:14 INFO 140645090101056] #quality_metric: host=algo-1, epoch=19, train absolute_loss <loss>=0.376620622277\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22420.209884643555, \"sum\": 22420.209884643555, \"min\": 22420.209884643555}}, \"EndTime\": 1597559234.186124, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559211.764019}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:14 INFO 140645090101056] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 26001, \"sum\": 26001.0, \"min\": 26001}, \"Total Records Seen\": {\"count\": 1, \"max\": 25990420, \"sum\": 25990420.0, \"min\": 25990420}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 21, \"sum\": 21.0, \"min\": 21}}, \"EndTime\": 1597559234.186353, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 19}, \"StartTime\": 1597559211.765881}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:14 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=57958.7914355 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:14 INFO 140645090101056] #quality_metric: host=algo-1, epoch=20, batch=0 train rmse <loss>=0.521221317078\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:14 INFO 140645090101056] #quality_metric: host=algo-1, epoch=20, batch=0 train mse <loss>=0.271671661377\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:14 INFO 140645090101056] #quality_metric: host=algo-1, epoch=20, batch=0 train absolute_loss <loss>=0.321651062012\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:22 INFO 140645090101056] Iter[20] Batch [500]#011Speed: 57686.89 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:22 INFO 140645090101056] #quality_metric: host=algo-1, epoch=20, batch=500 train rmse <loss>=0.544876564484\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:22 INFO 140645090101056] #quality_metric: host=algo-1, epoch=20, batch=500 train mse <loss>=0.296890470524\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:22 INFO 140645090101056] #quality_metric: host=algo-1, epoch=20, batch=500 train absolute_loss <loss>=0.371533737822\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:31 INFO 140645090101056] Iter[20] Batch [1000]#011Speed: 58953.10 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:31 INFO 140645090101056] #quality_metric: host=algo-1, epoch=20, batch=1000 train rmse <loss>=0.543025055248\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:31 INFO 140645090101056] #quality_metric: host=algo-1, epoch=20, batch=1000 train mse <loss>=0.294876210627\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:31 INFO 140645090101056] #quality_metric: host=algo-1, epoch=20, batch=1000 train absolute_loss <loss>=0.370627162023\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:27:36.504] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 42, \"duration\": 22314, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:36 INFO 140645090101056] #quality_metric: host=algo-1, epoch=20, train rmse <loss>=0.540982482073\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:36 INFO 140645090101056] #quality_metric: host=algo-1, epoch=20, train mse <loss>=0.29266204591\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:36 INFO 140645090101056] #quality_metric: host=algo-1, epoch=20, train absolute_loss <loss>=0.368502312833\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22316.552877426147, \"sum\": 22316.552877426147, \"min\": 22316.552877426147}}, \"EndTime\": 1597559256.504643, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559234.186191}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:36 INFO 140645090101056] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 27301, \"sum\": 27301.0, \"min\": 27301}, \"Total Records Seen\": {\"count\": 1, \"max\": 27289891, \"sum\": 27289891.0, \"min\": 27289891}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}}, \"EndTime\": 1597559256.504889, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 20}, \"StartTime\": 1597559234.188058}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:36 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58227.986557 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:36 INFO 140645090101056] #quality_metric: host=algo-1, epoch=21, batch=0 train rmse <loss>=0.499204277103\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:36 INFO 140645090101056] #quality_metric: host=algo-1, epoch=21, batch=0 train mse <loss>=0.249204910278\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:36 INFO 140645090101056] #quality_metric: host=algo-1, epoch=21, batch=0 train absolute_loss <loss>=0.308406066895\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:45 INFO 140645090101056] Iter[21] Batch [500]#011Speed: 57640.18 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:45 INFO 140645090101056] #quality_metric: host=algo-1, epoch=21, batch=500 train rmse <loss>=0.535201726724\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:45 INFO 140645090101056] #quality_metric: host=algo-1, epoch=21, batch=500 train mse <loss>=0.286440888289\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:45 INFO 140645090101056] #quality_metric: host=algo-1, epoch=21, batch=500 train absolute_loss <loss>=0.364804620891\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:53 INFO 140645090101056] Iter[21] Batch [1000]#011Speed: 58289.82 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:53 INFO 140645090101056] #quality_metric: host=algo-1, epoch=21, batch=1000 train rmse <loss>=0.533167643625\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:53 INFO 140645090101056] #quality_metric: host=algo-1, epoch=21, batch=1000 train mse <loss>=0.284267736208\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:53 INFO 140645090101056] #quality_metric: host=algo-1, epoch=21, batch=1000 train absolute_loss <loss>=0.363468636908\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:27:59.031] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 44, \"duration\": 22523, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:59 INFO 140645090101056] #quality_metric: host=algo-1, epoch=21, train rmse <loss>=0.530948553878\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:59 INFO 140645090101056] #quality_metric: host=algo-1, epoch=21, train mse <loss>=0.281906366865\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:59 INFO 140645090101056] #quality_metric: host=algo-1, epoch=21, train absolute_loss <loss>=0.361114068193\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22525.332927703857, \"sum\": 22525.332927703857, \"min\": 22525.332927703857}}, \"EndTime\": 1597559279.031931, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559256.504715}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:59 INFO 140645090101056] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 28601, \"sum\": 28601.0, \"min\": 28601}, \"Total Records Seen\": {\"count\": 1, \"max\": 28589362, \"sum\": 28589362.0, \"min\": 28589362}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 23, \"sum\": 23.0, \"min\": 23}}, \"EndTime\": 1597559279.032142, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 21}, \"StartTime\": 1597559256.506568}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:59 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=57688.4223351 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:59 INFO 140645090101056] #quality_metric: host=algo-1, epoch=22, batch=0 train rmse <loss>=0.477992698965\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:59 INFO 140645090101056] #quality_metric: host=algo-1, epoch=22, batch=0 train mse <loss>=0.228477020264\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:27:59 INFO 140645090101056] #quality_metric: host=algo-1, epoch=22, batch=0 train absolute_loss <loss>=0.294677246094\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:07 INFO 140645090101056] Iter[22] Batch [500]#011Speed: 57796.43 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:07 INFO 140645090101056] #quality_metric: host=algo-1, epoch=22, batch=500 train rmse <loss>=0.526451909589\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:07 INFO 140645090101056] #quality_metric: host=algo-1, epoch=22, batch=500 train mse <loss>=0.27715161311\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:07 INFO 140645090101056] #quality_metric: host=algo-1, epoch=22, batch=500 train absolute_loss <loss>=0.358336393223\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/16/2020 06:28:16 INFO 140645090101056] Iter[22] Batch [1000]#011Speed: 58801.41 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:16 INFO 140645090101056] #quality_metric: host=algo-1, epoch=22, batch=1000 train rmse <loss>=0.524190906846\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:16 INFO 140645090101056] #quality_metric: host=algo-1, epoch=22, batch=1000 train mse <loss>=0.27477610682\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:16 INFO 140645090101056] #quality_metric: host=algo-1, epoch=22, batch=1000 train absolute_loss <loss>=0.356660813933\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:28:21.352] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 46, \"duration\": 22316, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:21 INFO 140645090101056] #quality_metric: host=algo-1, epoch=22, train rmse <loss>=0.52177221877\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:21 INFO 140645090101056] #quality_metric: host=algo-1, epoch=22, train mse <loss>=0.27224624828\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:21 INFO 140645090101056] #quality_metric: host=algo-1, epoch=22, train absolute_loss <loss>=0.354034790074\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22318.526029586792, \"sum\": 22318.526029586792, \"min\": 22318.526029586792}}, \"EndTime\": 1597559301.352525, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559279.032001}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:21 INFO 140645090101056] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 29901, \"sum\": 29901.0, \"min\": 29901}, \"Total Records Seen\": {\"count\": 1, \"max\": 29888833, \"sum\": 29888833.0, \"min\": 29888833}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 24, \"sum\": 24.0, \"min\": 24}}, \"EndTime\": 1597559301.352722, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 22}, \"StartTime\": 1597559279.033968}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:21 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58223.0060939 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:21 INFO 140645090101056] #quality_metric: host=algo-1, epoch=23, batch=0 train rmse <loss>=0.458957362902\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:21 INFO 140645090101056] #quality_metric: host=algo-1, epoch=23, batch=0 train mse <loss>=0.210641860962\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:21 INFO 140645090101056] #quality_metric: host=algo-1, epoch=23, batch=0 train absolute_loss <loss>=0.283420410156\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:30 INFO 140645090101056] Iter[23] Batch [500]#011Speed: 57318.78 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:30 INFO 140645090101056] #quality_metric: host=algo-1, epoch=23, batch=500 train rmse <loss>=0.518621754925\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:30 INFO 140645090101056] #quality_metric: host=algo-1, epoch=23, batch=500 train mse <loss>=0.268968524682\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:30 INFO 140645090101056] #quality_metric: host=algo-1, epoch=23, batch=500 train absolute_loss <loss>=0.352173065764\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:38 INFO 140645090101056] Iter[23] Batch [1000]#011Speed: 58455.90 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:38 INFO 140645090101056] #quality_metric: host=algo-1, epoch=23, batch=1000 train rmse <loss>=0.516113295595\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:38 INFO 140645090101056] #quality_metric: host=algo-1, epoch=23, batch=1000 train mse <loss>=0.26637293389\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:38 INFO 140645090101056] #quality_metric: host=algo-1, epoch=23, batch=1000 train absolute_loss <loss>=0.350288792308\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:28:43.667] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 48, \"duration\": 22312, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:43 INFO 140645090101056] #quality_metric: host=algo-1, epoch=23, train rmse <loss>=0.513490096357\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:43 INFO 140645090101056] #quality_metric: host=algo-1, epoch=23, train mse <loss>=0.263672079057\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:43 INFO 140645090101056] #quality_metric: host=algo-1, epoch=23, train absolute_loss <loss>=0.347431485725\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22314.71085548401, \"sum\": 22314.71085548401, \"min\": 22314.71085548401}}, \"EndTime\": 1597559323.667686, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559301.35259}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:43 INFO 140645090101056] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 31201, \"sum\": 31201.0, \"min\": 31201}, \"Total Records Seen\": {\"count\": 1, \"max\": 31188304, \"sum\": 31188304.0, \"min\": 31188304}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 25, \"sum\": 25.0, \"min\": 25}}, \"EndTime\": 1597559323.66794, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 23}, \"StartTime\": 1597559301.352943}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:43 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58232.7768657 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:43 INFO 140645090101056] #quality_metric: host=algo-1, epoch=24, batch=0 train rmse <loss>=0.442262530212\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:43 INFO 140645090101056] #quality_metric: host=algo-1, epoch=24, batch=0 train mse <loss>=0.19559614563\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:43 INFO 140645090101056] #quality_metric: host=algo-1, epoch=24, batch=0 train absolute_loss <loss>=0.275045928955\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:52 INFO 140645090101056] Iter[24] Batch [500]#011Speed: 58259.08 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:52 INFO 140645090101056] #quality_metric: host=algo-1, epoch=24, batch=500 train rmse <loss>=0.51195823859\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:52 INFO 140645090101056] #quality_metric: host=algo-1, epoch=24, batch=500 train mse <loss>=0.26210123806\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:28:52 INFO 140645090101056] #quality_metric: host=algo-1, epoch=24, batch=500 train absolute_loss <loss>=0.34674428432\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:00 INFO 140645090101056] Iter[24] Batch [1000]#011Speed: 58960.38 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:00 INFO 140645090101056] #quality_metric: host=algo-1, epoch=24, batch=1000 train rmse <loss>=0.509109058626\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:00 INFO 140645090101056] #quality_metric: host=algo-1, epoch=24, batch=1000 train mse <loss>=0.259192033575\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:00 INFO 140645090101056] #quality_metric: host=algo-1, epoch=24, batch=1000 train absolute_loss <loss>=0.344658209436\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:29:05.800] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 50, \"duration\": 22130, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:05 INFO 140645090101056] #quality_metric: host=algo-1, epoch=24, train rmse <loss>=0.506301402387\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:05 INFO 140645090101056] #quality_metric: host=algo-1, epoch=24, train mse <loss>=0.256341110059\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:05 INFO 140645090101056] #quality_metric: host=algo-1, epoch=24, train absolute_loss <loss>=0.341691226525\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22132.418870925903, \"sum\": 22132.418870925903, \"min\": 22132.418870925903}}, \"EndTime\": 1597559345.800618, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559323.667756}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:05 INFO 140645090101056] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 32501, \"sum\": 32501.0, \"min\": 32501}, \"Total Records Seen\": {\"count\": 1, \"max\": 32487775, \"sum\": 32487775.0, \"min\": 32487775}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 26, \"sum\": 26.0, \"min\": 26}}, \"EndTime\": 1597559345.80081, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 24}, \"StartTime\": 1597559323.668171}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:05 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58712.6022721 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:05 INFO 140645090101056] #quality_metric: host=algo-1, epoch=25, batch=0 train rmse <loss>=0.426863768669\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:05 INFO 140645090101056] #quality_metric: host=algo-1, epoch=25, batch=0 train mse <loss>=0.182212677002\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:05 INFO 140645090101056] #quality_metric: host=algo-1, epoch=25, batch=0 train absolute_loss <loss>=0.267612335205\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/16/2020 06:29:14 INFO 140645090101056] Iter[25] Batch [500]#011Speed: 58333.82 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:14 INFO 140645090101056] #quality_metric: host=algo-1, epoch=25, batch=500 train rmse <loss>=0.506760862921\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:14 INFO 140645090101056] #quality_metric: host=algo-1, epoch=25, batch=500 train mse <loss>=0.256806572189\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:14 INFO 140645090101056] #quality_metric: host=algo-1, epoch=25, batch=500 train absolute_loss <loss>=0.342514145446\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:22 INFO 140645090101056] Iter[25] Batch [1000]#011Speed: 58917.58 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:22 INFO 140645090101056] #quality_metric: host=algo-1, epoch=25, batch=1000 train rmse <loss>=0.503392568124\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:22 INFO 140645090101056] #quality_metric: host=algo-1, epoch=25, batch=1000 train mse <loss>=0.253404077642\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:22 INFO 140645090101056] #quality_metric: host=algo-1, epoch=25, batch=1000 train absolute_loss <loss>=0.340224378786\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:29:27.976] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 52, \"duration\": 22174, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:27 INFO 140645090101056] #quality_metric: host=algo-1, epoch=25, train rmse <loss>=0.500461301448\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:27 INFO 140645090101056] #quality_metric: host=algo-1, epoch=25, train mse <loss>=0.250461514247\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:27 INFO 140645090101056] #quality_metric: host=algo-1, epoch=25, train absolute_loss <loss>=0.337272714034\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22176.593780517578, \"sum\": 22176.593780517578, \"min\": 22176.593780517578}}, \"EndTime\": 1597559367.977643, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559345.800683}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:27 INFO 140645090101056] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 33801, \"sum\": 33801.0, \"min\": 33801}, \"Total Records Seen\": {\"count\": 1, \"max\": 33787246, \"sum\": 33787246.0, \"min\": 33787246}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 27, \"sum\": 27.0, \"min\": 27}}, \"EndTime\": 1597559367.977862, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 25}, \"StartTime\": 1597559345.801019}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:27 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58595.4762792 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:28 INFO 140645090101056] #quality_metric: host=algo-1, epoch=26, batch=0 train rmse <loss>=0.41083825367\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:28 INFO 140645090101056] #quality_metric: host=algo-1, epoch=26, batch=0 train mse <loss>=0.168788070679\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:28 INFO 140645090101056] #quality_metric: host=algo-1, epoch=26, batch=0 train absolute_loss <loss>=0.25819128418\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:36 INFO 140645090101056] Iter[26] Batch [500]#011Speed: 58150.46 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:36 INFO 140645090101056] #quality_metric: host=algo-1, epoch=26, batch=500 train rmse <loss>=0.503162830659\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:36 INFO 140645090101056] #quality_metric: host=algo-1, epoch=26, batch=500 train mse <loss>=0.253172834157\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:36 INFO 140645090101056] #quality_metric: host=algo-1, epoch=26, batch=500 train absolute_loss <loss>=0.339965669613\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:45 INFO 140645090101056] Iter[26] Batch [1000]#011Speed: 58860.13 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:45 INFO 140645090101056] #quality_metric: host=algo-1, epoch=26, batch=1000 train rmse <loss>=0.499096273482\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:45 INFO 140645090101056] #quality_metric: host=algo-1, epoch=26, batch=1000 train mse <loss>=0.249097090204\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:45 INFO 140645090101056] #quality_metric: host=algo-1, epoch=26, batch=1000 train absolute_loss <loss>=0.337295330707\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:29:50.205] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 54, \"duration\": 22224, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:50 INFO 140645090101056] #quality_metric: host=algo-1, epoch=26, train rmse <loss>=0.496119699142\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:50 INFO 140645090101056] #quality_metric: host=algo-1, epoch=26, train mse <loss>=0.246134755877\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:50 INFO 140645090101056] #quality_metric: host=algo-1, epoch=26, train absolute_loss <loss>=0.334496993948\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22226.2761592865, \"sum\": 22226.2761592865, \"min\": 22226.2761592865}}, \"EndTime\": 1597559390.205781, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559367.977704}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:50 INFO 140645090101056] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 35101, \"sum\": 35101.0, \"min\": 35101}, \"Total Records Seen\": {\"count\": 1, \"max\": 35086717, \"sum\": 35086717.0, \"min\": 35086717}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 28, \"sum\": 28.0, \"min\": 28}}, \"EndTime\": 1597559390.206011, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 26}, \"StartTime\": 1597559367.97947}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:50 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58464.4907527 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:50 INFO 140645090101056] #quality_metric: host=algo-1, epoch=27, batch=0 train rmse <loss>=0.393691304994\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:50 INFO 140645090101056] #quality_metric: host=algo-1, epoch=27, batch=0 train mse <loss>=0.154992843628\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:50 INFO 140645090101056] #quality_metric: host=algo-1, epoch=27, batch=0 train absolute_loss <loss>=0.246508911133\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:58 INFO 140645090101056] Iter[27] Batch [500]#011Speed: 57608.64 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:58 INFO 140645090101056] #quality_metric: host=algo-1, epoch=27, batch=500 train rmse <loss>=0.500883874731\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:58 INFO 140645090101056] #quality_metric: host=algo-1, epoch=27, batch=500 train mse <loss>=0.250884655966\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:29:58 INFO 140645090101056] #quality_metric: host=algo-1, epoch=27, batch=500 train absolute_loss <loss>=0.339093185699\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:07 INFO 140645090101056] Iter[27] Batch [1000]#011Speed: 58867.31 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:07 INFO 140645090101056] #quality_metric: host=algo-1, epoch=27, batch=1000 train rmse <loss>=0.496049877384\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:07 INFO 140645090101056] #quality_metric: host=algo-1, epoch=27, batch=1000 train mse <loss>=0.246065480852\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:07 INFO 140645090101056] #quality_metric: host=algo-1, epoch=27, batch=1000 train absolute_loss <loss>=0.335947990974\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:30:12.523] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 56, \"duration\": 22313, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:12 INFO 140645090101056] #quality_metric: host=algo-1, epoch=27, train rmse <loss>=0.493018223908\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:12 INFO 140645090101056] #quality_metric: host=algo-1, epoch=27, train mse <loss>=0.243066969106\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:12 INFO 140645090101056] #quality_metric: host=algo-1, epoch=27, train absolute_loss <loss>=0.33327088251\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22315.871000289917, \"sum\": 22315.871000289917, \"min\": 22315.871000289917}}, \"EndTime\": 1597559412.523639, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559390.205859}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:12 INFO 140645090101056] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 36401, \"sum\": 36401.0, \"min\": 36401}, \"Total Records Seen\": {\"count\": 1, \"max\": 36386188, \"sum\": 36386188.0, \"min\": 36386188}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 29, \"sum\": 29.0, \"min\": 29}}, \"EndTime\": 1597559412.523877, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 27}, \"StartTime\": 1597559390.207742}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:12 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58229.7887404 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:12 INFO 140645090101056] #quality_metric: host=algo-1, epoch=28, batch=0 train rmse <loss>=0.376237216872\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:12 INFO 140645090101056] #quality_metric: host=algo-1, epoch=28, batch=0 train mse <loss>=0.141554443359\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:12 INFO 140645090101056] #quality_metric: host=algo-1, epoch=28, batch=0 train absolute_loss <loss>=0.234256698608\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/16/2020 06:30:21 INFO 140645090101056] Iter[28] Batch [500]#011Speed: 58126.63 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:21 INFO 140645090101056] #quality_metric: host=algo-1, epoch=28, batch=500 train rmse <loss>=0.499133596084\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:21 INFO 140645090101056] #quality_metric: host=algo-1, epoch=28, batch=500 train mse <loss>=0.249134346739\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:21 INFO 140645090101056] #quality_metric: host=algo-1, epoch=28, batch=500 train absolute_loss <loss>=0.338936885537\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:29 INFO 140645090101056] Iter[28] Batch [1000]#011Speed: 58026.50 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:29 INFO 140645090101056] #quality_metric: host=algo-1, epoch=28, batch=1000 train rmse <loss>=0.493553993725\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:29 INFO 140645090101056] #quality_metric: host=algo-1, epoch=28, batch=1000 train mse <loss>=0.243595544722\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:29 INFO 140645090101056] #quality_metric: host=algo-1, epoch=28, batch=1000 train absolute_loss <loss>=0.335347072178\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:30:34.825] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 58, \"duration\": 22299, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:34 INFO 140645090101056] #quality_metric: host=algo-1, epoch=28, train rmse <loss>=0.490353443469\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:34 INFO 140645090101056] #quality_metric: host=algo-1, epoch=28, train mse <loss>=0.240446499522\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:34 INFO 140645090101056] #quality_metric: host=algo-1, epoch=28, train absolute_loss <loss>=0.332608030888\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22302.08110809326, \"sum\": 22302.08110809326, \"min\": 22302.08110809326}}, \"EndTime\": 1597559434.826258, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559412.523704}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:34 INFO 140645090101056] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 37701, \"sum\": 37701.0, \"min\": 37701}, \"Total Records Seen\": {\"count\": 1, \"max\": 37685659, \"sum\": 37685659.0, \"min\": 37685659}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 30, \"sum\": 30.0, \"min\": 30}}, \"EndTime\": 1597559434.826451, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 28}, \"StartTime\": 1597559412.524146}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:34 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58265.9293494 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:34 INFO 140645090101056] #quality_metric: host=algo-1, epoch=29, batch=0 train rmse <loss>=0.359161345287\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:34 INFO 140645090101056] #quality_metric: host=algo-1, epoch=29, batch=0 train mse <loss>=0.128996871948\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:34 INFO 140645090101056] #quality_metric: host=algo-1, epoch=29, batch=0 train absolute_loss <loss>=0.221636428833\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:43 INFO 140645090101056] Iter[29] Batch [500]#011Speed: 58410.90 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:43 INFO 140645090101056] #quality_metric: host=algo-1, epoch=29, batch=500 train rmse <loss>=0.497033928797\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:43 INFO 140645090101056] #quality_metric: host=algo-1, epoch=29, batch=500 train mse <loss>=0.247042726376\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:43 INFO 140645090101056] #quality_metric: host=algo-1, epoch=29, batch=500 train absolute_loss <loss>=0.338566930897\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:51 INFO 140645090101056] Iter[29] Batch [1000]#011Speed: 58769.83 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:51 INFO 140645090101056] #quality_metric: host=algo-1, epoch=29, batch=1000 train rmse <loss>=0.490797767819\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:51 INFO 140645090101056] #quality_metric: host=algo-1, epoch=29, batch=1000 train mse <loss>=0.240882448896\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:51 INFO 140645090101056] #quality_metric: host=algo-1, epoch=29, batch=1000 train absolute_loss <loss>=0.334479575783\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:30:56.997] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 60, \"duration\": 22169, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:56 INFO 140645090101056] #quality_metric: host=algo-1, epoch=29, train rmse <loss>=0.487385216292\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:56 INFO 140645090101056] #quality_metric: host=algo-1, epoch=29, train mse <loss>=0.23754434906\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:56 INFO 140645090101056] #quality_metric: host=algo-1, epoch=29, train absolute_loss <loss>=0.33154970743\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22171.799898147583, \"sum\": 22171.799898147583, \"min\": 22171.799898147583}}, \"EndTime\": 1597559456.998489, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559434.826323}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:56 INFO 140645090101056] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 39001, \"sum\": 39001.0, \"min\": 39001}, \"Total Records Seen\": {\"count\": 1, \"max\": 38985130, \"sum\": 38985130.0, \"min\": 38985130}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}}, \"EndTime\": 1597559456.998686, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 29}, \"StartTime\": 1597559434.826659}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:56 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58608.2858326 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:57 INFO 140645090101056] #quality_metric: host=algo-1, epoch=30, batch=0 train rmse <loss>=0.343463181567\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:57 INFO 140645090101056] #quality_metric: host=algo-1, epoch=30, batch=0 train mse <loss>=0.117966957092\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:30:57 INFO 140645090101056] #quality_metric: host=algo-1, epoch=30, batch=0 train absolute_loss <loss>=0.210787612915\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:05 INFO 140645090101056] Iter[30] Batch [500]#011Speed: 57507.81 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:05 INFO 140645090101056] #quality_metric: host=algo-1, epoch=30, batch=500 train rmse <loss>=0.494337041465\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:05 INFO 140645090101056] #quality_metric: host=algo-1, epoch=30, batch=500 train mse <loss>=0.244369110564\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:05 INFO 140645090101056] #quality_metric: host=algo-1, epoch=30, batch=500 train absolute_loss <loss>=0.337590660963\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:14 INFO 140645090101056] Iter[30] Batch [1000]#011Speed: 58839.66 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:14 INFO 140645090101056] #quality_metric: host=algo-1, epoch=30, batch=1000 train rmse <loss>=0.487583822804\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:14 INFO 140645090101056] #quality_metric: host=algo-1, epoch=30, batch=1000 train mse <loss>=0.23773798426\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:14 INFO 140645090101056] #quality_metric: host=algo-1, epoch=30, batch=1000 train absolute_loss <loss>=0.333035059835\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:31:19.277] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 62, \"duration\": 22277, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:19 INFO 140645090101056] #quality_metric: host=algo-1, epoch=30, train rmse <loss>=0.484030775034\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:19 INFO 140645090101056] #quality_metric: host=algo-1, epoch=30, train mse <loss>=0.23428579118\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:19 INFO 140645090101056] #quality_metric: host=algo-1, epoch=30, train absolute_loss <loss>=0.329946305882\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22279.271125793457, \"sum\": 22279.271125793457, \"min\": 22279.271125793457}}, \"EndTime\": 1597559479.278211, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559456.998551}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:19 INFO 140645090101056] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 40301, \"sum\": 40301.0, \"min\": 40301}, \"Total Records Seen\": {\"count\": 1, \"max\": 40284601, \"sum\": 40284601.0, \"min\": 40284601}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 32, \"sum\": 32.0, \"min\": 32}}, \"EndTime\": 1597559479.278443, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 30}, \"StartTime\": 1597559456.998909}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:19 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58325.4387708 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:19 INFO 140645090101056] #quality_metric: host=algo-1, epoch=31, batch=0 train rmse <loss>=0.329723505883\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:19 INFO 140645090101056] #quality_metric: host=algo-1, epoch=31, batch=0 train mse <loss>=0.108717590332\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:19 INFO 140645090101056] #quality_metric: host=algo-1, epoch=31, batch=0 train absolute_loss <loss>=0.203523193359\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/16/2020 06:31:27 INFO 140645090101056] Iter[31] Batch [500]#011Speed: 58175.29 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:27 INFO 140645090101056] #quality_metric: host=algo-1, epoch=31, batch=500 train rmse <loss>=0.491349512472\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:27 INFO 140645090101056] #quality_metric: host=algo-1, epoch=31, batch=500 train mse <loss>=0.241424343406\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:27 INFO 140645090101056] #quality_metric: host=algo-1, epoch=31, batch=500 train absolute_loss <loss>=0.336294802302\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:36 INFO 140645090101056] Iter[31] Batch [1000]#011Speed: 58942.48 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:36 INFO 140645090101056] #quality_metric: host=algo-1, epoch=31, batch=1000 train rmse <loss>=0.484187812501\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:36 INFO 140645090101056] #quality_metric: host=algo-1, epoch=31, batch=1000 train mse <loss>=0.234437837774\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:36 INFO 140645090101056] #quality_metric: host=algo-1, epoch=31, batch=1000 train absolute_loss <loss>=0.331278714099\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:31:41.470] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 64, \"duration\": 22188, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:41 INFO 140645090101056] #quality_metric: host=algo-1, epoch=31, train rmse <loss>=0.480590089706\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:41 INFO 140645090101056] #quality_metric: host=algo-1, epoch=31, train mse <loss>=0.230966834324\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:41 INFO 140645090101056] #quality_metric: host=algo-1, epoch=31, train absolute_loss <loss>=0.328144075458\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22190.67096710205, \"sum\": 22190.67096710205, \"min\": 22190.67096710205}}, \"EndTime\": 1597559501.47084, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559479.278285}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:41 INFO 140645090101056] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 41601, \"sum\": 41601.0, \"min\": 41601}, \"Total Records Seen\": {\"count\": 1, \"max\": 41584072, \"sum\": 41584072.0, \"min\": 41584072}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 33, \"sum\": 33.0, \"min\": 33}}, \"EndTime\": 1597559501.471085, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 31}, \"StartTime\": 1597559479.280136}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:41 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58558.2903834 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:41 INFO 140645090101056] #quality_metric: host=algo-1, epoch=32, batch=0 train rmse <loss>=0.31796104778\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:41 INFO 140645090101056] #quality_metric: host=algo-1, epoch=32, batch=0 train mse <loss>=0.101099227905\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:41 INFO 140645090101056] #quality_metric: host=algo-1, epoch=32, batch=0 train absolute_loss <loss>=0.198231903076\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:50 INFO 140645090101056] Iter[32] Batch [500]#011Speed: 58322.60 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:50 INFO 140645090101056] #quality_metric: host=algo-1, epoch=32, batch=500 train rmse <loss>=0.488480504567\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:50 INFO 140645090101056] #quality_metric: host=algo-1, epoch=32, batch=500 train mse <loss>=0.238613203342\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:50 INFO 140645090101056] #quality_metric: host=algo-1, epoch=32, batch=500 train absolute_loss <loss>=0.335154487777\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:58 INFO 140645090101056] Iter[32] Batch [1000]#011Speed: 58556.54 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:58 INFO 140645090101056] #quality_metric: host=algo-1, epoch=32, batch=1000 train rmse <loss>=0.480927372167\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:58 INFO 140645090101056] #quality_metric: host=algo-1, epoch=32, batch=1000 train mse <loss>=0.231291137299\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:31:58 INFO 140645090101056] #quality_metric: host=algo-1, epoch=32, batch=1000 train absolute_loss <loss>=0.329611680358\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:32:03.652] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 66, \"duration\": 22179, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:03 INFO 140645090101056] #quality_metric: host=algo-1, epoch=32, train rmse <loss>=0.477341720583\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:03 INFO 140645090101056] #quality_metric: host=algo-1, epoch=32, train mse <loss>=0.227855118209\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:03 INFO 140645090101056] #quality_metric: host=algo-1, epoch=32, train absolute_loss <loss>=0.326519599328\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22181.70189857483, \"sum\": 22181.70189857483, \"min\": 22181.70189857483}}, \"EndTime\": 1597559523.653126, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559501.470912}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:03 INFO 140645090101056] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 42901, \"sum\": 42901.0, \"min\": 42901}, \"Total Records Seen\": {\"count\": 1, \"max\": 42883543, \"sum\": 42883543.0, \"min\": 42883543}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 34, \"sum\": 34.0, \"min\": 34}}, \"EndTime\": 1597559523.653358, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 32}, \"StartTime\": 1597559501.47136}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:03 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58581.9116944 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:03 INFO 140645090101056] #quality_metric: host=algo-1, epoch=33, batch=0 train rmse <loss>=0.307840754573\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:03 INFO 140645090101056] #quality_metric: host=algo-1, epoch=33, batch=0 train mse <loss>=0.0947659301758\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:03 INFO 140645090101056] #quality_metric: host=algo-1, epoch=33, batch=0 train absolute_loss <loss>=0.192815551758\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:12 INFO 140645090101056] Iter[33] Batch [500]#011Speed: 57740.65 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:12 INFO 140645090101056] #quality_metric: host=algo-1, epoch=33, batch=500 train rmse <loss>=0.486052395719\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:12 INFO 140645090101056] #quality_metric: host=algo-1, epoch=33, batch=500 train mse <loss>=0.236246931384\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:12 INFO 140645090101056] #quality_metric: host=algo-1, epoch=33, batch=500 train absolute_loss <loss>=0.334505501601\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:20 INFO 140645090101056] Iter[33] Batch [1000]#011Speed: 58458.64 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:20 INFO 140645090101056] #quality_metric: host=algo-1, epoch=33, batch=1000 train rmse <loss>=0.478003417206\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:20 INFO 140645090101056] #quality_metric: host=algo-1, epoch=33, batch=1000 train mse <loss>=0.228487266861\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:20 INFO 140645090101056] #quality_metric: host=algo-1, epoch=33, batch=1000 train absolute_loss <loss>=0.328247395183\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:32:25.952] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 68, \"duration\": 22296, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:25 INFO 140645090101056] #quality_metric: host=algo-1, epoch=33, train rmse <loss>=0.474425084876\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:25 INFO 140645090101056] #quality_metric: host=algo-1, epoch=33, train mse <loss>=0.22507916116\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:25 INFO 140645090101056] #quality_metric: host=algo-1, epoch=33, train absolute_loss <loss>=0.325193657356\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22297.992944717407, \"sum\": 22297.992944717407, \"min\": 22297.992944717407}}, \"EndTime\": 1597559545.95312, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559523.653192}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:25 INFO 140645090101056] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 44201, \"sum\": 44201.0, \"min\": 44201}, \"Total Records Seen\": {\"count\": 1, \"max\": 44183014, \"sum\": 44183014.0, \"min\": 44183014}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 35, \"sum\": 35.0, \"min\": 35}}, \"EndTime\": 1597559545.953322, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 33}, \"StartTime\": 1597559523.6551}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:25 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58276.6192707 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:25 INFO 140645090101056] #quality_metric: host=algo-1, epoch=34, batch=0 train rmse <loss>=0.298796043519\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:25 INFO 140645090101056] #quality_metric: host=algo-1, epoch=34, batch=0 train mse <loss>=0.0892790756226\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:25 INFO 140645090101056] #quality_metric: host=algo-1, epoch=34, batch=0 train absolute_loss <loss>=0.187391983032\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/16/2020 06:32:34 INFO 140645090101056] Iter[34] Batch [500]#011Speed: 58504.32 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:34 INFO 140645090101056] #quality_metric: host=algo-1, epoch=34, batch=500 train rmse <loss>=0.484261401931\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:34 INFO 140645090101056] #quality_metric: host=algo-1, epoch=34, batch=500 train mse <loss>=0.234509105401\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:34 INFO 140645090101056] #quality_metric: host=algo-1, epoch=34, batch=500 train absolute_loss <loss>=0.334507479182\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:43 INFO 140645090101056] Iter[34] Batch [1000]#011Speed: 58537.79 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:43 INFO 140645090101056] #quality_metric: host=algo-1, epoch=34, batch=1000 train rmse <loss>=0.475494165333\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:43 INFO 140645090101056] #quality_metric: host=algo-1, epoch=34, batch=1000 train mse <loss>=0.226094701266\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:43 INFO 140645090101056] #quality_metric: host=algo-1, epoch=34, batch=1000 train absolute_loss <loss>=0.327240378427\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:32:48.143] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 70, \"duration\": 22186, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:48 INFO 140645090101056] #quality_metric: host=algo-1, epoch=34, train rmse <loss>=0.471863250714\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:48 INFO 140645090101056] #quality_metric: host=algo-1, epoch=34, train mse <loss>=0.222654927374\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:48 INFO 140645090101056] #quality_metric: host=algo-1, epoch=34, train absolute_loss <loss>=0.324136095323\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22188.507080078125, \"sum\": 22188.507080078125, \"min\": 22188.507080078125}}, \"EndTime\": 1597559568.143642, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559545.95319}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:48 INFO 140645090101056] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 45501, \"sum\": 45501.0, \"min\": 45501}, \"Total Records Seen\": {\"count\": 1, \"max\": 45482485, \"sum\": 45482485.0, \"min\": 45482485}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 36, \"sum\": 36.0, \"min\": 36}}, \"EndTime\": 1597559568.143839, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 34}, \"StartTime\": 1597559545.955107}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:48 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58564.1810251 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:48 INFO 140645090101056] #quality_metric: host=algo-1, epoch=35, batch=0 train rmse <loss>=0.290229919317\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:48 INFO 140645090101056] #quality_metric: host=algo-1, epoch=35, batch=0 train mse <loss>=0.0842334060669\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:48 INFO 140645090101056] #quality_metric: host=algo-1, epoch=35, batch=0 train absolute_loss <loss>=0.181954772949\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:56 INFO 140645090101056] Iter[35] Batch [500]#011Speed: 57761.17 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:56 INFO 140645090101056] #quality_metric: host=algo-1, epoch=35, batch=500 train rmse <loss>=0.483177374306\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:56 INFO 140645090101056] #quality_metric: host=algo-1, epoch=35, batch=500 train mse <loss>=0.233460375042\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:32:56 INFO 140645090101056] #quality_metric: host=algo-1, epoch=35, batch=500 train absolute_loss <loss>=0.335178121997\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:05 INFO 140645090101056] Iter[35] Batch [1000]#011Speed: 58247.84 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:05 INFO 140645090101056] #quality_metric: host=algo-1, epoch=35, batch=1000 train rmse <loss>=0.473388748692\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:05 INFO 140645090101056] #quality_metric: host=algo-1, epoch=35, batch=1000 train mse <loss>=0.224096907388\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:05 INFO 140645090101056] #quality_metric: host=algo-1, epoch=35, batch=1000 train absolute_loss <loss>=0.326611068924\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:33:10.496] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 72, \"duration\": 22349, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=35, train rmse <loss>=0.469618052577\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=35, train mse <loss>=0.220541115306\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=35, train absolute_loss <loss>=0.323310791333\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22351.015090942383, \"sum\": 22351.015090942383, \"min\": 22351.015090942383}}, \"EndTime\": 1597559590.496661, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559568.14371}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:10 INFO 140645090101056] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 46801, \"sum\": 46801.0, \"min\": 46801}, \"Total Records Seen\": {\"count\": 1, \"max\": 46781956, \"sum\": 46781956.0, \"min\": 46781956}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 37, \"sum\": 37.0, \"min\": 37}}, \"EndTime\": 1597559590.496897, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 35}, \"StartTime\": 1597559568.14562}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:10 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58138.2451316 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=36, batch=0 train rmse <loss>=0.281896446749\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=36, batch=0 train mse <loss>=0.0794656066895\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=36, batch=0 train absolute_loss <loss>=0.176709091187\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:19 INFO 140645090101056] Iter[36] Batch [500]#011Speed: 58176.83 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:19 INFO 140645090101056] #quality_metric: host=algo-1, epoch=36, batch=500 train rmse <loss>=0.482770144304\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:19 INFO 140645090101056] #quality_metric: host=algo-1, epoch=36, batch=500 train mse <loss>=0.233067012231\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:19 INFO 140645090101056] #quality_metric: host=algo-1, epoch=36, batch=500 train absolute_loss <loss>=0.33644136754\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:27 INFO 140645090101056] Iter[36] Batch [1000]#011Speed: 58629.14 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:27 INFO 140645090101056] #quality_metric: host=algo-1, epoch=36, batch=1000 train rmse <loss>=0.471629439359\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:27 INFO 140645090101056] #quality_metric: host=algo-1, epoch=36, batch=1000 train mse <loss>=0.22243432807\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:27 INFO 140645090101056] #quality_metric: host=algo-1, epoch=36, batch=1000 train absolute_loss <loss>=0.326201484398\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:33:32.697] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 74, \"duration\": 22197, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:32 INFO 140645090101056] #quality_metric: host=algo-1, epoch=36, train rmse <loss>=0.467637836939\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:32 INFO 140645090101056] #quality_metric: host=algo-1, epoch=36, train mse <loss>=0.218685146537\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:32 INFO 140645090101056] #quality_metric: host=algo-1, epoch=36, train absolute_loss <loss>=0.322642502148\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22199.42307472229, \"sum\": 22199.42307472229, \"min\": 22199.42307472229}}, \"EndTime\": 1597559612.698174, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559590.496733}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:32 INFO 140645090101056] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 48101, \"sum\": 48101.0, \"min\": 48101}, \"Total Records Seen\": {\"count\": 1, \"max\": 48081427, \"sum\": 48081427.0, \"min\": 48081427}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 38, \"sum\": 38.0, \"min\": 38}}, \"EndTime\": 1597559612.698377, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 36}, \"StartTime\": 1597559590.498724}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:32 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58535.3701933 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:32 INFO 140645090101056] #quality_metric: host=algo-1, epoch=37, batch=0 train rmse <loss>=0.274386161282\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:32 INFO 140645090101056] #quality_metric: host=algo-1, epoch=37, batch=0 train mse <loss>=0.0752877655029\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:32 INFO 140645090101056] #quality_metric: host=algo-1, epoch=37, batch=0 train absolute_loss <loss>=0.172230102539\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/16/2020 06:33:41 INFO 140645090101056] Iter[37] Batch [500]#011Speed: 57615.67 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:41 INFO 140645090101056] #quality_metric: host=algo-1, epoch=37, batch=500 train rmse <loss>=0.482947582768\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:41 INFO 140645090101056] #quality_metric: host=algo-1, epoch=37, batch=500 train mse <loss>=0.233238367701\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:41 INFO 140645090101056] #quality_metric: host=algo-1, epoch=37, batch=500 train absolute_loss <loss>=0.338210884231\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:50 INFO 140645090101056] Iter[37] Batch [1000]#011Speed: 57897.75 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:50 INFO 140645090101056] #quality_metric: host=algo-1, epoch=37, batch=1000 train rmse <loss>=0.470148350872\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:50 INFO 140645090101056] #quality_metric: host=algo-1, epoch=37, batch=1000 train mse <loss>=0.221039471827\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:50 INFO 140645090101056] #quality_metric: host=algo-1, epoch=37, batch=1000 train absolute_loss <loss>=0.325903983224\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:33:55.063] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 76, \"duration\": 22362, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=37, train rmse <loss>=0.465882386274\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=37, train mse <loss>=0.21704639784\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=37, train absolute_loss <loss>=0.322091614662\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22363.960027694702, \"sum\": 22363.960027694702, \"min\": 22363.960027694702}}, \"EndTime\": 1597559635.064132, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559612.698241}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:55 INFO 140645090101056] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 49401, \"sum\": 49401.0, \"min\": 49401}, \"Total Records Seen\": {\"count\": 1, \"max\": 49380898, \"sum\": 49380898.0, \"min\": 49380898}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 39, \"sum\": 39.0, \"min\": 39}}, \"EndTime\": 1597559635.064382, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 37}, \"StartTime\": 1597559612.700138}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:55 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58104.5284905 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=38, batch=0 train rmse <loss>=0.269180435758\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=38, batch=0 train mse <loss>=0.0724581069946\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:33:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=38, batch=0 train absolute_loss <loss>=0.170619628906\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:03 INFO 140645090101056] Iter[38] Batch [500]#011Speed: 57982.67 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:03 INFO 140645090101056] #quality_metric: host=algo-1, epoch=38, batch=500 train rmse <loss>=0.483582231209\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:03 INFO 140645090101056] #quality_metric: host=algo-1, epoch=38, batch=500 train mse <loss>=0.233851774341\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:03 INFO 140645090101056] #quality_metric: host=algo-1, epoch=38, batch=500 train absolute_loss <loss>=0.340353064684\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:12 INFO 140645090101056] Iter[38] Batch [1000]#011Speed: 59524.72 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:12 INFO 140645090101056] #quality_metric: host=algo-1, epoch=38, batch=1000 train rmse <loss>=0.46888669746\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:12 INFO 140645090101056] #quality_metric: host=algo-1, epoch=38, batch=1000 train mse <loss>=0.219854735055\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:12 INFO 140645090101056] #quality_metric: host=algo-1, epoch=38, batch=1000 train absolute_loss <loss>=0.325637665008\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:34:17.134] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 78, \"duration\": 22066, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=38, train rmse <loss>=0.464323910448\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=38, train mse <loss>=0.215596693814\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=38, train absolute_loss <loss>=0.321573293316\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22068.742036819458, \"sum\": 22068.742036819458, \"min\": 22068.742036819458}}, \"EndTime\": 1597559657.134917, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559635.064212}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:17 INFO 140645090101056] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 50701, \"sum\": 50701.0, \"min\": 50701}, \"Total Records Seen\": {\"count\": 1, \"max\": 50680369, \"sum\": 50680369.0, \"min\": 50680369}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 40, \"sum\": 40.0, \"min\": 40}}, \"EndTime\": 1597559657.135153, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 38}, \"StartTime\": 1597559635.066147}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:17 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58881.8804228 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=39, batch=0 train rmse <loss>=0.267744146146\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=39, batch=0 train mse <loss>=0.0716869277954\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=39, batch=0 train absolute_loss <loss>=0.175502670288\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:25 INFO 140645090101056] Iter[39] Batch [500]#011Speed: 58216.79 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:25 INFO 140645090101056] #quality_metric: host=algo-1, epoch=39, batch=500 train rmse <loss>=0.484519466226\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:25 INFO 140645090101056] #quality_metric: host=algo-1, epoch=39, batch=500 train mse <loss>=0.234759113152\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:25 INFO 140645090101056] #quality_metric: host=algo-1, epoch=39, batch=500 train absolute_loss <loss>=0.342702325269\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:34 INFO 140645090101056] Iter[39] Batch [1000]#011Speed: 59129.91 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:34 INFO 140645090101056] #quality_metric: host=algo-1, epoch=39, batch=1000 train rmse <loss>=0.467795706381\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:34 INFO 140645090101056] #quality_metric: host=algo-1, epoch=39, batch=1000 train mse <loss>=0.218832822908\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:34 INFO 140645090101056] #quality_metric: host=algo-1, epoch=39, batch=1000 train absolute_loss <loss>=0.325412317571\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:34:39.204] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 80, \"duration\": 22065, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:39 INFO 140645090101056] #quality_metric: host=algo-1, epoch=39, train rmse <loss>=0.462938949015\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:39 INFO 140645090101056] #quality_metric: host=algo-1, epoch=39, train mse <loss>=0.214312470515\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:39 INFO 140645090101056] #quality_metric: host=algo-1, epoch=39, train absolute_loss <loss>=0.321081378479\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22067.901134490967, \"sum\": 22067.901134490967, \"min\": 22067.901134490967}}, \"EndTime\": 1597559679.204864, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559657.134985}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:39 INFO 140645090101056] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 52001, \"sum\": 52001.0, \"min\": 52001}, \"Total Records Seen\": {\"count\": 1, \"max\": 51979840, \"sum\": 51979840.0, \"min\": 51979840}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 41, \"sum\": 41.0, \"min\": 41}}, \"EndTime\": 1597559679.205063, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 39}, \"StartTime\": 1597559657.136935}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:39 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58884.2341489 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:39 INFO 140645090101056] #quality_metric: host=algo-1, epoch=40, batch=0 train rmse <loss>=0.269967900947\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:39 INFO 140645090101056] #quality_metric: host=algo-1, epoch=40, batch=0 train mse <loss>=0.0728826675415\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:39 INFO 140645090101056] #quality_metric: host=algo-1, epoch=40, batch=0 train absolute_loss <loss>=0.184662185669\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/16/2020 06:34:47 INFO 140645090101056] Iter[40] Batch [500]#011Speed: 58643.44 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:47 INFO 140645090101056] #quality_metric: host=algo-1, epoch=40, batch=500 train rmse <loss>=0.485585516291\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:47 INFO 140645090101056] #quality_metric: host=algo-1, epoch=40, batch=500 train mse <loss>=0.235793293631\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:47 INFO 140645090101056] #quality_metric: host=algo-1, epoch=40, batch=500 train absolute_loss <loss>=0.344965590791\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:56 INFO 140645090101056] Iter[40] Batch [1000]#011Speed: 58277.90 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:56 INFO 140645090101056] #quality_metric: host=algo-1, epoch=40, batch=1000 train rmse <loss>=0.466831195768\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:56 INFO 140645090101056] #quality_metric: host=algo-1, epoch=40, batch=1000 train mse <loss>=0.217931365342\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:34:56 INFO 140645090101056] #quality_metric: host=algo-1, epoch=40, batch=1000 train absolute_loss <loss>=0.325197882303\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:35:01.524] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 82, \"duration\": 22316, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:01 INFO 140645090101056] #quality_metric: host=algo-1, epoch=40, train rmse <loss>=0.46170533761\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:01 INFO 140645090101056] #quality_metric: host=algo-1, epoch=40, train mse <loss>=0.213171818777\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:01 INFO 140645090101056] #quality_metric: host=algo-1, epoch=40, train absolute_loss <loss>=0.32060338481\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22318.447828292847, \"sum\": 22318.447828292847, \"min\": 22318.447828292847}}, \"EndTime\": 1597559701.525319, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559679.204934}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:01 INFO 140645090101056] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 53301, \"sum\": 53301.0, \"min\": 53301}, \"Total Records Seen\": {\"count\": 1, \"max\": 53279311, \"sum\": 53279311.0, \"min\": 53279311}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 42, \"sum\": 42.0, \"min\": 42}}, \"EndTime\": 1597559701.525539, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 40}, \"StartTime\": 1597559679.206842}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:01 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58223.1286203 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:01 INFO 140645090101056] #quality_metric: host=algo-1, epoch=41, batch=0 train rmse <loss>=0.273353767872\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:01 INFO 140645090101056] #quality_metric: host=algo-1, epoch=41, batch=0 train mse <loss>=0.0747222824097\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:01 INFO 140645090101056] #quality_metric: host=algo-1, epoch=41, batch=0 train absolute_loss <loss>=0.193382644653\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:10 INFO 140645090101056] Iter[41] Batch [500]#011Speed: 57581.54 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=41, batch=500 train rmse <loss>=0.486615931409\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=41, batch=500 train mse <loss>=0.236795064702\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=41, batch=500 train absolute_loss <loss>=0.347018333633\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:18 INFO 140645090101056] Iter[41] Batch [1000]#011Speed: 58830.18 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:18 INFO 140645090101056] #quality_metric: host=algo-1, epoch=41, batch=1000 train rmse <loss>=0.465956365416\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:18 INFO 140645090101056] #quality_metric: host=algo-1, epoch=41, batch=1000 train mse <loss>=0.217115334472\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:18 INFO 140645090101056] #quality_metric: host=algo-1, epoch=41, batch=1000 train absolute_loss <loss>=0.324936252666\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:35:23.834] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 84, \"duration\": 22305, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:23 INFO 140645090101056] #quality_metric: host=algo-1, epoch=41, train rmse <loss>=0.46060972844\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:23 INFO 140645090101056] #quality_metric: host=algo-1, epoch=41, train mse <loss>=0.212161321933\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:23 INFO 140645090101056] #quality_metric: host=algo-1, epoch=41, train absolute_loss <loss>=0.320113648905\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22307.71803855896, \"sum\": 22307.71803855896, \"min\": 22307.71803855896}}, \"EndTime\": 1597559723.835039, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559701.525383}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:23 INFO 140645090101056] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 54601, \"sum\": 54601.0, \"min\": 54601}, \"Total Records Seen\": {\"count\": 1, \"max\": 54578782, \"sum\": 54578782.0, \"min\": 54578782}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 43, \"sum\": 43.0, \"min\": 43}}, \"EndTime\": 1597559723.83524, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 41}, \"StartTime\": 1597559701.527294}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:23 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58251.2219347 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:23 INFO 140645090101056] #quality_metric: host=algo-1, epoch=42, batch=0 train rmse <loss>=0.273999158092\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:23 INFO 140645090101056] #quality_metric: host=algo-1, epoch=42, batch=0 train mse <loss>=0.0750755386353\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:23 INFO 140645090101056] #quality_metric: host=algo-1, epoch=42, batch=0 train absolute_loss <loss>=0.196481674194\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:32 INFO 140645090101056] Iter[42] Batch [500]#011Speed: 57481.33 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:32 INFO 140645090101056] #quality_metric: host=algo-1, epoch=42, batch=500 train rmse <loss>=0.487488595572\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:32 INFO 140645090101056] #quality_metric: host=algo-1, epoch=42, batch=500 train mse <loss>=0.237645130812\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:32 INFO 140645090101056] #quality_metric: host=algo-1, epoch=42, batch=500 train absolute_loss <loss>=0.348845140408\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:41 INFO 140645090101056] Iter[42] Batch [1000]#011Speed: 58485.65 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:41 INFO 140645090101056] #quality_metric: host=algo-1, epoch=42, batch=1000 train rmse <loss>=0.465147961146\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:41 INFO 140645090101056] #quality_metric: host=algo-1, epoch=42, batch=1000 train mse <loss>=0.216362625758\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:41 INFO 140645090101056] #quality_metric: host=algo-1, epoch=42, batch=1000 train absolute_loss <loss>=0.324616591965\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:35:46.215] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 86, \"duration\": 22377, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=42, train rmse <loss>=0.459655299589\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=42, train mse <loss>=0.211282994441\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=42, train absolute_loss <loss>=0.319655584071\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22379.311084747314, \"sum\": 22379.311084747314, \"min\": 22379.311084747314}}, \"EndTime\": 1597559746.216396, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559723.835104}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:46 INFO 140645090101056] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 55901, \"sum\": 55901.0, \"min\": 55901}, \"Total Records Seen\": {\"count\": 1, \"max\": 55878253, \"sum\": 55878253.0, \"min\": 55878253}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 44, \"sum\": 44.0, \"min\": 44}}, \"EndTime\": 1597559746.216684, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 42}, \"StartTime\": 1597559723.837054}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:46 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58064.4906328 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=43, batch=0 train rmse <loss>=0.268763356431\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=43, batch=0 train mse <loss>=0.0722337417603\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=43, batch=0 train absolute_loss <loss>=0.189258255005\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:54 INFO 140645090101056] Iter[43] Batch [500]#011Speed: 57694.54 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:54 INFO 140645090101056] #quality_metric: host=algo-1, epoch=43, batch=500 train rmse <loss>=0.488140367299\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:54 INFO 140645090101056] #quality_metric: host=algo-1, epoch=43, batch=500 train mse <loss>=0.238281018187\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:35:54 INFO 140645090101056] #quality_metric: host=algo-1, epoch=43, batch=500 train absolute_loss <loss>=0.350266176083\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/16/2020 06:36:03 INFO 140645090101056] Iter[43] Batch [1000]#011Speed: 57792.84 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:03 INFO 140645090101056] #quality_metric: host=algo-1, epoch=43, batch=1000 train rmse <loss>=0.464398268196\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:03 INFO 140645090101056] #quality_metric: host=algo-1, epoch=43, batch=1000 train mse <loss>=0.215665751504\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:03 INFO 140645090101056] #quality_metric: host=algo-1, epoch=43, batch=1000 train absolute_loss <loss>=0.324249615375\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:36:08.617] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 88, \"duration\": 22397, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:08 INFO 140645090101056] #quality_metric: host=algo-1, epoch=43, train rmse <loss>=0.458861478595\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:08 INFO 140645090101056] #quality_metric: host=algo-1, epoch=43, train mse <loss>=0.210553856539\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:08 INFO 140645090101056] #quality_metric: host=algo-1, epoch=43, train absolute_loss <loss>=0.319315767717\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22399.938106536865, \"sum\": 22399.938106536865, \"min\": 22399.938106536865}}, \"EndTime\": 1597559768.618555, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559746.216473}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:08 INFO 140645090101056] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 57201, \"sum\": 57201.0, \"min\": 57201}, \"Total Records Seen\": {\"count\": 1, \"max\": 57177724, \"sum\": 57177724.0, \"min\": 57177724}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}}, \"EndTime\": 1597559768.618808, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 43}, \"StartTime\": 1597559746.218585}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:08 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58011.2279756 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:08 INFO 140645090101056] #quality_metric: host=algo-1, epoch=44, batch=0 train rmse <loss>=0.257328588228\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:08 INFO 140645090101056] #quality_metric: host=algo-1, epoch=44, batch=0 train mse <loss>=0.0662180023193\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:08 INFO 140645090101056] #quality_metric: host=algo-1, epoch=44, batch=0 train absolute_loss <loss>=0.171925430298\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:17 INFO 140645090101056] Iter[44] Batch [500]#011Speed: 57802.41 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=44, batch=500 train rmse <loss>=0.488564964706\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=44, batch=500 train mse <loss>=0.238695724739\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=44, batch=500 train absolute_loss <loss>=0.351306163826\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:25 INFO 140645090101056] Iter[44] Batch [1000]#011Speed: 58463.50 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:25 INFO 140645090101056] #quality_metric: host=algo-1, epoch=44, batch=1000 train rmse <loss>=0.463714539994\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:25 INFO 140645090101056] #quality_metric: host=algo-1, epoch=44, batch=1000 train mse <loss>=0.215031174602\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:25 INFO 140645090101056] #quality_metric: host=algo-1, epoch=44, batch=1000 train absolute_loss <loss>=0.323934829346\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:36:30.984] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 90, \"duration\": 22361, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:30 INFO 140645090101056] #quality_metric: host=algo-1, epoch=44, train rmse <loss>=0.458257593748\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:30 INFO 140645090101056] #quality_metric: host=algo-1, epoch=44, train mse <loss>=0.210000022228\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:30 INFO 140645090101056] #quality_metric: host=algo-1, epoch=44, train absolute_loss <loss>=0.319190777388\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22364.150047302246, \"sum\": 22364.150047302246, \"min\": 22364.150047302246}}, \"EndTime\": 1597559790.984785, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559768.618632}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:30 INFO 140645090101056] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 58501, \"sum\": 58501.0, \"min\": 58501}, \"Total Records Seen\": {\"count\": 1, \"max\": 58477195, \"sum\": 58477195.0, \"min\": 58477195}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 46, \"sum\": 46.0, \"min\": 46}}, \"EndTime\": 1597559790.984978, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 44}, \"StartTime\": 1597559768.620609}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:30 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58104.2608972 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:31 INFO 140645090101056] #quality_metric: host=algo-1, epoch=45, batch=0 train rmse <loss>=0.243229040327\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:31 INFO 140645090101056] #quality_metric: host=algo-1, epoch=45, batch=0 train mse <loss>=0.0591603660583\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:31 INFO 140645090101056] #quality_metric: host=algo-1, epoch=45, batch=0 train absolute_loss <loss>=0.153195922852\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:39 INFO 140645090101056] Iter[45] Batch [500]#011Speed: 58007.52 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:39 INFO 140645090101056] #quality_metric: host=algo-1, epoch=45, batch=500 train rmse <loss>=0.48880168713\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:39 INFO 140645090101056] #quality_metric: host=algo-1, epoch=45, batch=500 train mse <loss>=0.238927089341\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:39 INFO 140645090101056] #quality_metric: host=algo-1, epoch=45, batch=500 train absolute_loss <loss>=0.352209723162\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:48 INFO 140645090101056] Iter[45] Batch [1000]#011Speed: 58875.59 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:48 INFO 140645090101056] #quality_metric: host=algo-1, epoch=45, batch=1000 train rmse <loss>=0.463120996746\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:48 INFO 140645090101056] #quality_metric: host=algo-1, epoch=45, batch=1000 train mse <loss>=0.214481057627\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:48 INFO 140645090101056] #quality_metric: host=algo-1, epoch=45, batch=1000 train absolute_loss <loss>=0.323829079551\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:36:53.178] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 92, \"duration\": 22190, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:53 INFO 140645090101056] #quality_metric: host=algo-1, epoch=45, train rmse <loss>=0.457876389172\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:53 INFO 140645090101056] #quality_metric: host=algo-1, epoch=45, train mse <loss>=0.209650787761\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:53 INFO 140645090101056] #quality_metric: host=algo-1, epoch=45, train absolute_loss <loss>=0.319381254953\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22192.22593307495, \"sum\": 22192.22593307495, \"min\": 22192.22593307495}}, \"EndTime\": 1597559813.179105, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559790.98485}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:53 INFO 140645090101056] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 59801, \"sum\": 59801.0, \"min\": 59801}, \"Total Records Seen\": {\"count\": 1, \"max\": 59776666, \"sum\": 59776666.0, \"min\": 59776666}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 47, \"sum\": 47.0, \"min\": 47}}, \"EndTime\": 1597559813.179342, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 45}, \"StartTime\": 1597559790.986848}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:53 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58554.1873917 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:53 INFO 140645090101056] #quality_metric: host=algo-1, epoch=46, batch=0 train rmse <loss>=0.232614711233\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:53 INFO 140645090101056] #quality_metric: host=algo-1, epoch=46, batch=0 train mse <loss>=0.0541096038818\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:36:53 INFO 140645090101056] #quality_metric: host=algo-1, epoch=46, batch=0 train absolute_loss <loss>=0.14196472168\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/16/2020 06:37:01 INFO 140645090101056] Iter[46] Batch [500]#011Speed: 58180.96 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:01 INFO 140645090101056] #quality_metric: host=algo-1, epoch=46, batch=500 train rmse <loss>=0.488921020951\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:01 INFO 140645090101056] #quality_metric: host=algo-1, epoch=46, batch=500 train mse <loss>=0.239043764727\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:01 INFO 140645090101056] #quality_metric: host=algo-1, epoch=46, batch=500 train absolute_loss <loss>=0.352921813417\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:10 INFO 140645090101056] Iter[46] Batch [1000]#011Speed: 58225.74 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=46, batch=1000 train rmse <loss>=0.462663797989\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=46, batch=1000 train mse <loss>=0.214057789969\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:10 INFO 140645090101056] #quality_metric: host=algo-1, epoch=46, batch=1000 train absolute_loss <loss>=0.323893335043\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:37:15.455] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 94, \"duration\": 22272, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:15 INFO 140645090101056] #quality_metric: host=algo-1, epoch=46, train rmse <loss>=0.457751871173\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:15 INFO 140645090101056] #quality_metric: host=algo-1, epoch=46, train mse <loss>=0.209536775563\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:15 INFO 140645090101056] #quality_metric: host=algo-1, epoch=46, train absolute_loss <loss>=0.319898569254\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22274.608850479126, \"sum\": 22274.608850479126, \"min\": 22274.608850479126}}, \"EndTime\": 1597559835.45588, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559813.179182}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:15 INFO 140645090101056] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 61101, \"sum\": 61101.0, \"min\": 61101}, \"Total Records Seen\": {\"count\": 1, \"max\": 61076137, \"sum\": 61076137.0, \"min\": 61076137}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 48, \"sum\": 48.0, \"min\": 48}}, \"EndTime\": 1597559835.456126, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 46}, \"StartTime\": 1597559813.181238}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:15 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58337.6328573 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:15 INFO 140645090101056] #quality_metric: host=algo-1, epoch=47, batch=0 train rmse <loss>=0.229601162624\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:15 INFO 140645090101056] #quality_metric: host=algo-1, epoch=47, batch=0 train mse <loss>=0.0527166938782\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:15 INFO 140645090101056] #quality_metric: host=algo-1, epoch=47, batch=0 train absolute_loss <loss>=0.144021606445\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:24 INFO 140645090101056] Iter[47] Batch [500]#011Speed: 57745.97 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:24 INFO 140645090101056] #quality_metric: host=algo-1, epoch=47, batch=500 train rmse <loss>=0.489010409012\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:24 INFO 140645090101056] #quality_metric: host=algo-1, epoch=47, batch=500 train mse <loss>=0.239131180122\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:24 INFO 140645090101056] #quality_metric: host=algo-1, epoch=47, batch=500 train absolute_loss <loss>=0.353457723835\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:32 INFO 140645090101056] Iter[47] Batch [1000]#011Speed: 58600.56 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:32 INFO 140645090101056] #quality_metric: host=algo-1, epoch=47, batch=1000 train rmse <loss>=0.462413654537\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:32 INFO 140645090101056] #quality_metric: host=algo-1, epoch=47, batch=1000 train mse <loss>=0.213826387903\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:32 INFO 140645090101056] #quality_metric: host=algo-1, epoch=47, batch=1000 train absolute_loss <loss>=0.324148731975\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:37:37.784] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 96, \"duration\": 22326, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:37 INFO 140645090101056] #quality_metric: host=algo-1, epoch=47, train rmse <loss>=0.457919377767\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:37 INFO 140645090101056] #quality_metric: host=algo-1, epoch=47, train mse <loss>=0.209690156535\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:37 INFO 140645090101056] #quality_metric: host=algo-1, epoch=47, train absolute_loss <loss>=0.320764111821\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22328.550100326538, \"sum\": 22328.550100326538, \"min\": 22328.550100326538}}, \"EndTime\": 1597559857.78497, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559835.455962}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:37 INFO 140645090101056] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 62401, \"sum\": 62401.0, \"min\": 62401}, \"Total Records Seen\": {\"count\": 1, \"max\": 62375608, \"sum\": 62375608.0, \"min\": 62375608}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 49, \"sum\": 49.0, \"min\": 49}}, \"EndTime\": 1597559857.785204, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 47}, \"StartTime\": 1597559835.456386}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:37 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58196.6779806 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:37 INFO 140645090101056] #quality_metric: host=algo-1, epoch=48, batch=0 train rmse <loss>=0.231459560809\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:37 INFO 140645090101056] #quality_metric: host=algo-1, epoch=48, batch=0 train mse <loss>=0.0535735282898\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:37 INFO 140645090101056] #quality_metric: host=algo-1, epoch=48, batch=0 train absolute_loss <loss>=0.149857177734\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:46 INFO 140645090101056] Iter[48] Batch [500]#011Speed: 57197.60 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=48, batch=500 train rmse <loss>=0.489163616821\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=48, batch=500 train mse <loss>=0.239281044022\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:46 INFO 140645090101056] #quality_metric: host=algo-1, epoch=48, batch=500 train absolute_loss <loss>=0.354022722865\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:55 INFO 140645090101056] Iter[48] Batch [1000]#011Speed: 58598.55 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=48, batch=1000 train rmse <loss>=0.462462629828\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=48, batch=1000 train mse <loss>=0.213871683988\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:37:55 INFO 140645090101056] #quality_metric: host=algo-1, epoch=48, batch=1000 train absolute_loss <loss>=0.324774037898\u001b[0m\n",
      "\u001b[34m[2020-08-16 06:38:00.209] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 98, \"duration\": 22422, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:00 INFO 140645090101056] #quality_metric: host=algo-1, epoch=48, train rmse <loss>=0.458416104635\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:00 INFO 140645090101056] #quality_metric: host=algo-1, epoch=48, train mse <loss>=0.210145324989\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:00 INFO 140645090101056] #quality_metric: host=algo-1, epoch=48, train absolute_loss <loss>=0.322096309251\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22424.837112426758, \"sum\": 22424.837112426758, \"min\": 22424.837112426758}}, \"EndTime\": 1597559880.210369, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559857.785043}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:00 INFO 140645090101056] #progress_metric: host=algo-1, completed 98 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 63701, \"sum\": 63701.0, \"min\": 63701}, \"Total Records Seen\": {\"count\": 1, \"max\": 63675079, \"sum\": 63675079.0, \"min\": 63675079}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 50, \"sum\": 50.0, \"min\": 50}}, \"EndTime\": 1597559880.210606, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 48}, \"StartTime\": 1597559857.785473}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:00 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=57946.7243903 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:00 INFO 140645090101056] #quality_metric: host=algo-1, epoch=49, batch=0 train rmse <loss>=0.230596263718\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:00 INFO 140645090101056] #quality_metric: host=algo-1, epoch=49, batch=0 train mse <loss>=0.0531746368408\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:00 INFO 140645090101056] #quality_metric: host=algo-1, epoch=49, batch=0 train absolute_loss <loss>=0.149725982666\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:08 INFO 140645090101056] Iter[49] Batch [500]#011Speed: 57554.71 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:08 INFO 140645090101056] #quality_metric: host=algo-1, epoch=49, batch=500 train rmse <loss>=0.489469042914\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:08 INFO 140645090101056] #quality_metric: host=algo-1, epoch=49, batch=500 train mse <loss>=0.239579943971\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:08 INFO 140645090101056] #quality_metric: host=algo-1, epoch=49, batch=500 train absolute_loss <loss>=0.354699327663\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/16/2020 06:38:17 INFO 140645090101056] Iter[49] Batch [1000]#011Speed: 58624.21 samples/sec\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=49, batch=1000 train rmse <loss>=0.462911639492\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=49, batch=1000 train mse <loss>=0.214287185978\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:17 INFO 140645090101056] #quality_metric: host=algo-1, epoch=49, batch=1000 train absolute_loss <loss>=0.325885896544\u001b[0m\n",
      "\n",
      "2020-08-16 06:38:29 Uploading - Uploading generated training model\u001b[34m[2020-08-16 06:38:22.567] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 100, \"duration\": 22354, \"num_examples\": 1300, \"num_bytes\": 93562644}\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:22 INFO 140645090101056] #quality_metric: host=algo-1, epoch=49, train rmse <loss>=0.459275917033\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:22 INFO 140645090101056] #quality_metric: host=algo-1, epoch=49, train mse <loss>=0.210934367966\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:22 INFO 140645090101056] #quality_metric: host=algo-1, epoch=49, train absolute_loss <loss>=0.323952562538\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:22 INFO 140645090101056] #quality_metric: host=algo-1, train rmse <loss>=0.459275917033\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:22 INFO 140645090101056] #quality_metric: host=algo-1, train mse <loss>=0.210934367966\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:22 INFO 140645090101056] #quality_metric: host=algo-1, train absolute_loss <loss>=0.323952562538\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 22357.808113098145, \"sum\": 22357.808113098145, \"min\": 22357.808113098145}}, \"EndTime\": 1597559902.56872, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559880.210446}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:22 INFO 140645090101056] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1300, \"sum\": 1300.0, \"min\": 1300}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Total Batches Seen\": {\"count\": 1, \"max\": 65001, \"sum\": 65001.0, \"min\": 65001}, \"Total Records Seen\": {\"count\": 1, \"max\": 64974550, \"sum\": 64974550.0, \"min\": 64974550}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1299471, \"sum\": 1299471.0, \"min\": 1299471}, \"Reset Count\": {\"count\": 1, \"max\": 51, \"sum\": 51.0, \"min\": 51}}, \"EndTime\": 1597559902.568953, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 49}, \"StartTime\": 1597559880.210878}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:22 INFO 140645090101056] #throughput_metric: host=algo-1, train throughput=58120.5427361 records/second\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:22 WARNING 140645090101056] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:22 INFO 140645090101056] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 118.97778511047363, \"sum\": 118.97778511047363, \"min\": 118.97778511047363}}, \"EndTime\": 1597559902.688266, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559902.568802}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:23 INFO 140645090101056] Saved checkpoint to \"/tmp/tmp3Nr9zv/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[08/16/2020 06:38:24 INFO 140645090101056] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 1119336.415052414, \"sum\": 1119336.415052414, \"min\": 1119336.415052414}, \"setuptime\": {\"count\": 1, \"max\": 48.31409454345703, \"sum\": 48.31409454345703, \"min\": 48.31409454345703}}, \"EndTime\": 1597559904.276985, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1597559902.688385}\n",
      "\u001b[0m\n",
      "\n",
      "2020-08-16 06:39:07 Completed - Training job completed\n",
      "Training seconds: 1207\n",
      "Billable seconds: 1207\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "crole = get_execution_role()\n",
    "\n",
    "print(sagemaker.estimator.Estimator)\n",
    "fm = sagemaker.estimator.Estimator(container,\n",
    "                                   crole, \n",
    "                                   train_instance_count=1, \n",
    "                                   train_instance_type='ml.c4.xlarge',\n",
    "                                   output_path=output_prefix,\n",
    "                                   sagemaker_session=sagemaker.Session())\n",
    "\n",
    "\n",
    "\n",
    "fm.set_hyperparameters(\n",
    "                      feature_dim=nFeatures,\n",
    "                      predictor_type='regressor',\n",
    "                      mini_batch_size=1000,\n",
    "                      num_factors=64,\n",
    "                      epochs=50)\n",
    "\n",
    "fm.fit({'train': train_data})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "fm_predictor = fm.deploy(instance_type='ml.c4.xlarge', initial_instance_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "import sagemaker_utils\n",
    "from sagemaker_utils.query_serializer import serialize as fmserialize \n",
    "from sagemaker.predictor import  json_deserializer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy \n",
    "\n",
    "\n",
    "sagemaker_utils.query_serializer.nFeatures = nFeatures\n",
    "fm_predictor.content_type = sagemaker_utils.query_serializer.CONTENT_TYPE\n",
    "fm_predictor.serializer = fmserialize\n",
    "fm_predictor.deserializer = json_deserializer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n",
      "(100, 980914)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "import numpy \n",
    "\n",
    "\n",
    "y_pred = [] \n",
    "for i in range(0, 100): \n",
    "    X_test_arr = X_test_cold[i*100: (i+1)*100]\n",
    "    print(X_test_arr.shape)\n",
    "\n",
    "    result = fm_predictor.predict(X_test_arr) \n",
    "\n",
    "    for p in result['predictions']: \n",
    "        score = 1 \n",
    "        if p['score'] > 3: \n",
    "            score = 2 \n",
    "        elif p['score'] <3: \n",
    "            score = 0 \n",
    "        y_pred.append(score)\n",
    "        \n",
    "y_answer = [] \n",
    "for y in Y_test_cold[0:10000]:\n",
    "    score = 1 \n",
    "    if y > 3: \n",
    "        score = 2 \n",
    "    elif y <3: \n",
    "        score = 0 \n",
    "    y_answer.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = numpy.sqrt(numpy.mean((numpy.asarray(y_pred)-numpy.asarray(y_answer))**2))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7242"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.mean(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
